{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXtM17W9kr52"
      },
      "source": [
        "# **PollenNER** — извлечения сущностей для анализа сообщений Пыльца Club\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Заказчик\n",
        "\n",
        "[Пыльца Club](https://pollen.club/) — краудсорсинговый сервис для людей с пыльцевой аллергией. Платформа объединяет тысячи пользователей, информируя их о текущем уровне аллергенов в воздухе и рисках для здоровья. Данные о концентрации пыльцевых частиц и прогнозах доступны через веб-интерфейс и мобильное приложение, что помогает планировать активность и корректировать терапию.\n",
        "\n",
        "\n",
        "\n",
        "## Исполнитель\n",
        "\n",
        "\n",
        "\n",
        "[Мельник Даниил](https://github.com/DanielNRU/)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Описание проекта\n",
        "\n",
        "\n",
        "\n",
        "Цель — создать и обучить NLP-систему, способную извлекать из пользовательских сообщений ключевую информацию о:\n",
        "\n",
        "\n",
        "\n",
        "* **Топонимах**\n",
        "\n",
        "* **Симптомах**\n",
        "\n",
        "* **Медицинских препаратах**\n",
        "\n",
        "* **Аллергенах**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Задачи\n",
        "\n",
        "\n",
        "\n",
        "1. **Подготовка и разметка данных**\n",
        "\n",
        "\n",
        "\n",
        " * Загрузка исторических сообщений пользователей\n",
        "\n",
        " * Очистка и нормализация текста\n",
        "\n",
        " * Аннотирование сущностей в Label Studio\n",
        "\n",
        " * Формирование тренировочной и тестовой выборок\n",
        "\n",
        "\n",
        "\n",
        "2. **Разработка NER-модуля**\n",
        "\n",
        "\n",
        "\n",
        " * Использование предобученной модели **DeepPavlov/rubert-base-cased**\n",
        "\n",
        " * Активное обучение для оптимального расширения аннотаций\n",
        "\n",
        " * Оценка неопределённости для отбора самых информативных примеров\n",
        "\n",
        " * PEFT и LoRA для экономии ресурсов при тонкой настройке\n",
        "\n",
        "\n",
        "\n",
        "3. **Построение RE-модуля**\n",
        "\n",
        "\n",
        "\n",
        " * Модель для классификации отношений между сущностями\n",
        "\n",
        " * Балансировка классов, оптимизация метрик качества\n",
        "\n",
        " * Интеграция в единый пайплайн с NER-модулем\n",
        "\n",
        "\n",
        "\n",
        "4. **Тестирование и внедрение**\n",
        "\n",
        "\n",
        "\n",
        " * Валидация на тестовой выборке\n",
        "\n",
        " * Анализ ошибок и доработка сложных кейсов\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Технологический стек\n",
        "\n",
        "\n",
        "\n",
        "* **Языки и библиотеки**: Python, Pandas, NumPy, scikit-learn\n",
        "\n",
        "* **ML-фреймворки**: PyTorch, Transformers (Hugging Face), PEFT (LoRA)\n",
        "\n",
        "* **Разметка**: Label Studio\n",
        "\n",
        "* **Подходы**: Active Learning, Parameter-Efficient Fine-Tuning\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWRORxG3uHU8"
      },
      "source": [
        "## Импорты библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7jsWDDntzgf"
      },
      "outputs": [],
      "source": [
        "# Стандартные библиотеки Python\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Научные вычисления и обработка данных\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import multiprocessing\n",
        "from joblib import parallel_backend\n",
        "\n",
        "# Hugging Face и трансформеры\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForTokenClassification,\n",
        "    EarlyStoppingCallback,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Внешние API и сервисы\n",
        "import requests\n",
        "from label_studio_sdk.client import LabelStudio\n",
        "from dotenv import load_dotenv\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9mQVwTSuXw8"
      },
      "source": [
        "## Настройка окружения и константы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fT3StR0u1NF"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "RANDOM_STATE = 42\n",
        "LABEL_CONFIG = '''<View>\n",
        "  <Labels name=\"label\" toName=\"text\">\n",
        "    <Label value=\"TOPONYM\" background=\"#ff0d00\"/>\n",
        "    <Label value=\"MEDICINE\" background=\"#022bf7\"/>\n",
        "    <Label value=\"SYMPTOM\" background=\"#ffd500\"/>\n",
        "    <Label value=\"ALLERGEN\" background=\"#00ff55\"/>\n",
        "    <Label value=\"BODY_PART\" background=\"#ff00ff\"/>\n",
        "  </Labels>\n",
        "\n",
        "  <Relations>\n",
        "    <Relation value=\"has_symptom\" />\n",
        "    <Relation value=\"has_medicine\" />\n",
        "  </Relations>\n",
        "\n",
        "  <Text name=\"text\" value=\"$text\" granularity=\"word\"/>\n",
        "</View>'''\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtqVftZ-ugG3"
      },
      "outputs": [],
      "source": [
        "n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
        "os.environ['LOKY_MAX_CPU_COUNT'] = str(n_jobs)\n",
        "\n",
        "# Подавляем лишние предупреждения, чтобы не засорять вывод.\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', message='No label_names provided for model class')\n",
        "warnings.filterwarnings('ignore', message='Could not find the number of physical cores')\n",
        "\n",
        "# Загружаем переменные окружения из .env файла (токены, URL и т.д.)\n",
        "# Для начинающих: .env файл - это файл с конфиденциальными данными (токены, пароли),\n",
        "# которые не должны попадать в репозиторий кода\n",
        "load_dotenv()\n",
        "LS_TOKEN = os.getenv('LS_LEGACY_TOKEN')  # Токен для Label Studio\n",
        "LS_URL = os.getenv('LS_URL', 'http://localhost:8080')  # URL сервера Label Studio\n",
        "HF_TOKEN = os.getenv('HUGGINGFACE_HUB_TOKEN')  # Токен для HuggingFace Hub\n",
        "assert LS_TOKEN and HF_TOKEN, 'Установите LS_LEGACY_TOKEN и HUGGINGFACE_HUB_TOKEN в .env'\n",
        "\n",
        "# Инициализация клиента для работы с Label Studio через API\n",
        "ls = LabelStudio(base_url=LS_URL, api_key=LS_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdGm9zH4vjwF"
      },
      "outputs": [],
      "source": [
        "## Конфигурация меток и токенизатора\n",
        "# Список всех сущностей, которые мы хотим распознавать.\n",
        "LABELS = ['TOPONYM', 'MEDICINE', 'SYMPTOM', 'ALLERGEN', 'BODY_PART']\n",
        "# Словари для преобразования между строковыми и числовыми метками.\n",
        "LABEL2ID = {'O': 0, **{f'B-{l}': i*2+1 for i, l in enumerate(LABELS)}, **{f'I-{l}': i*2+2 for i, l in enumerate(LABELS)}}\n",
        "ID2LABEL = {v: k for k, v in LABEL2ID.items()}\n",
        "\n",
        "TOKENIZER = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
        "\n",
        "# Список размеров обучающих выборок для активного обучения.\n",
        "sizes = list(range(50, 1501, 50))\n",
        "\n",
        "# Список допустимых отношений между сущностями для задачи RE.\n",
        "RE_RELATION_LABELS = ['has_symptom', 'has_medicine']\n",
        "\n",
        "# Тестовый пример\n",
        "TEST_EXAMPLES = [\n",
        "    \"В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\",\n",
        "]\n",
        "\n",
        "# Определяем функцию для вычисления метрик\n",
        "metric = evaluate.load('seqeval')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K6E1Sofu8xn"
      },
      "source": [
        "## Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06OxELJvT0n"
      },
      "outputs": [],
      "source": [
        "def bulk_import_via_http(project_id: int,\n",
        "                         tasks_list: List[Dict],\n",
        "                         ls_url: str,\n",
        "                         ls_token: str,\n",
        "                         chunk_size: int = 100,\n",
        "                         max_retries: int = 3):\n",
        "    \"\"\"\n",
        "    Импорт списка задач в Label Studio через HTTP-эндпоинт /import.\n",
        "\n",
        "    Параметры:\n",
        "    - project_id: ID проекта в Label Studio\n",
        "    - tasks_list: список задач для импорта\n",
        "    - ls_url: URL сервера Label Studio\n",
        "    - ls_token: токен доступа\n",
        "    - chunk_size: размер чанка для импорта\n",
        "    - max_retries: максимальное количество попыток при ошибке\n",
        "\n",
        "    Процесс:\n",
        "    1. Разбивает список задач на чанки\n",
        "    2. Отправляет каждый чанк через API\n",
        "    3. При ошибке делает повторные попытки с экспоненциальной задержкой\n",
        "    \"\"\"\n",
        "    url = f\"{ls_url}/api/projects/{project_id}/import\"\n",
        "    headers = {'Authorization': f'Token {ls_token}', 'Content-Type': 'application/json'}\n",
        "    total = len(tasks_list)\n",
        "\n",
        "    # Проходим по списку чанков\n",
        "    for i in range(0, total, chunk_size):\n",
        "        chunk = tasks_list[i:i + chunk_size]\n",
        "        start, end = i + 1, min(i + chunk_size, total)\n",
        "\n",
        "        # Пытаемся отправить с ретрай\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "            resp = requests.post(url, headers=headers, json=chunk)\n",
        "            if resp.ok:\n",
        "                print(f\"Импортировано задач {start}–{end} из {total}\")\n",
        "                break\n",
        "            print(f\"Ошибка импорта {start}–{end}: {resp.status_code}. Попытка {attempt}/{max_retries}\")\n",
        "            if attempt < max_retries:\n",
        "                time.sleep(2 ** attempt)  # Экспоненциальная задержка\n",
        "            else:\n",
        "                print(f\"Не удалось импортировать {start}–{end} после {max_retries} попыток.\")\n",
        "\n",
        "def calculate_uncertainty_scores(model, texts, tokenizer, batch_size=8):\n",
        "    \"\"\"\n",
        "    Рассчитывает оценки неопределенности для каждого текста на основе энтропии предсказаний модели.\n",
        "\n",
        "    Параметры:\n",
        "    - model: модель для предсказаний\n",
        "    - texts: список текстов для оценки\n",
        "    - tokenizer: токенизатор для обработки текстов\n",
        "    - batch_size: размер батча для обработки\n",
        "\n",
        "    Возвращает:\n",
        "    - список оценок неопределенности для каждого текста\n",
        "    \"\"\"\n",
        "    uncertainties = []\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Обработка текстов батчами\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts,\n",
        "                           padding=True,\n",
        "                           truncation=True,\n",
        "                           max_length=512,\n",
        "                           return_tensors=\"pt\")\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            # Вычисляем вероятности через softmax\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            # Рассчитываем энтропию как меру неопределенности\n",
        "            entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=-1)\n",
        "            # Усредняем энтропию по всем токенам в тексте\n",
        "            avg_entropy = entropy.mean(dim=1)\n",
        "            uncertainties.extend(avg_entropy.cpu().numpy())\n",
        "\n",
        "        # Очищаем память GPU\n",
        "        del outputs, logits, probs, entropy, avg_entropy\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return uncertainties\n",
        "\n",
        "def retry_on_error(func, max_retries=5, delay=2):\n",
        "    \"\"\"\n",
        "    Декоратор для повторных попыток выполнения функции при ошибках.\n",
        "\n",
        "    Параметры:\n",
        "    - func: функция для выполнения\n",
        "    - max_retries: максимальное количество попыток\n",
        "    - delay: начальная задержка между попытками\n",
        "\n",
        "    Возвращает:\n",
        "    - результат выполнения функции или None при неудаче\n",
        "    \"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise e\n",
        "                print(f\"Ошибка при выполнении {func.__name__}: {str(e)}. Попытка {attempt + 1}/{max_retries}\")\n",
        "                time.sleep(delay * (2 ** attempt))  # Экспоненциальная задержка\n",
        "        return None\n",
        "    return wrapper\n",
        "\n",
        "@retry_on_error\n",
        "def create_task(ls_client, project_id, text, text_id):\n",
        "    \"\"\"\n",
        "    Создание задачи в Label Studio с повторными попытками.\n",
        "    \"\"\"\n",
        "    return ls_client.tasks.create(\n",
        "        project=project_id,\n",
        "        data={\n",
        "            'text': text,\n",
        "            'meta': {\n",
        "                'id': str(text_id)\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "\n",
        "@retry_on_error\n",
        "def delete_task(ls_client, task_id):\n",
        "    \"\"\"\n",
        "    Удаление задачи в Label Studio с повторными попытками.\n",
        "    \"\"\"\n",
        "    return ls_client.tasks.delete(task_id)\n",
        "\n",
        "@retry_on_error\n",
        "def get_project_tasks(ls_client, project_id):\n",
        "    \"\"\"\n",
        "    Получение списка задач проекта с повторными попытками.\n",
        "    \"\"\"\n",
        "    return list(ls_client.tasks.list(project=project_id, fields=['data', 'is_labeled']))\n",
        "\n",
        "@retry_on_error\n",
        "def export_project(ls_client, project_id):\n",
        "    \"\"\"\n",
        "    Экспорт проекта с повторными попытками.\n",
        "    \"\"\"\n",
        "    resp = requests.get(\n",
        "        f\"{LS_URL}/api/projects/{project_id}/export?exportType=JSON&download_all_tasks=true\",\n",
        "        headers={'Authorization': f'Token {LS_TOKEN}'}\n",
        "    )\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "@retry_on_error\n",
        "def get_or_create_project(ls_client, title, label_config):\n",
        "    \"\"\"\n",
        "    Получение существующего проекта или создание нового с повторными попытками.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        proj = next((p for p in ls_client.projects.list() if p.title == title), None)\n",
        "        if not proj:\n",
        "            proj = ls_client.projects.create(title=title, label_config=label_config)\n",
        "            print(f\"Создан проект '{title}' (ID={proj.id})\")\n",
        "        return proj\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при работе с проектом '{title}': {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def ensure_project(texts_with_ids, title, export_path, import_prev_json=None):\n",
        "    \"\"\"\n",
        "    Убеждаемся, что в Label Studio есть проект с нужными текстами.\n",
        "\n",
        "    Параметры:\n",
        "    - texts_with_ids: список кортежей (id, text)\n",
        "    - title: название проекта\n",
        "    - export_path: путь для сохранения экспортированных данных\n",
        "    - import_prev_json: путь к файлу с предыдущими аннотациями\n",
        "\n",
        "    Процесс:\n",
        "    1. Проверяет существование проекта\n",
        "    2. Создает новый или использует существующий\n",
        "    3. Импортирует тексты и аннотации\n",
        "    4. Экспортирует размеченные данные\n",
        "\n",
        "    Возвращает:\n",
        "    - список примеров с аннотациями\n",
        "    \"\"\"\n",
        "    # Находим или создаём проект\n",
        "    proj = get_or_create_project(ls, title, LABEL_CONFIG)\n",
        "\n",
        "    # Получаем таски с повторными попытками\n",
        "    tasks = get_project_tasks(ls, proj.id)\n",
        "\n",
        "    # Если число совпадает\n",
        "    if len(tasks) == len(texts_with_ids):\n",
        "        labeled = sum(t.is_labeled for t in tasks)\n",
        "        if labeled == len(texts_with_ids):\n",
        "            print(f\"Все {len(texts_with_ids)} задач размечены в '{title}', экспорт\")\n",
        "            data = export_project(ls, proj.id)\n",
        "            with open(export_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "            examples = []\n",
        "            # Парсим аннотации в нужный формат\n",
        "            for item in data:\n",
        "                tags = []\n",
        "                for ann in item.get('annotations', []):\n",
        "                    for r in ann.get('result', []):\n",
        "                        v = r.get('value')\n",
        "                        if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                            tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "                examples.append({'text': item['data']['text'], 'tags': tags})\n",
        "            print(f\"Экспортировано {len(examples)} примеров в {export_path}\")\n",
        "            return examples\n",
        "        # Если есть неразмеченные — ждём\n",
        "        print(f\"В '{title}' размечено {labeled}/{len(texts_with_ids)}. Заверши разметку.\")\n",
        "        input(\"Нажми Enter после разметки...\")\n",
        "        return ensure_project(texts_with_ids, title, export_path, import_prev_json)\n",
        "\n",
        "    # Иначе — удаляем и создаём заново\n",
        "    if tasks:\n",
        "        for t in tasks:\n",
        "            delete_task(ls, t.id)\n",
        "        print(f\"Очистили {len(tasks)} задач в '{title}'\")\n",
        "\n",
        "    existing = []\n",
        "    # Импорт предыдущих аннотаций, если есть\n",
        "    if import_prev_json and os.path.exists(import_prev_json):\n",
        "        prev = json.load(open(import_prev_json, 'r', encoding='utf-8'))\n",
        "        bulk_import_via_http(proj.id, prev, LS_URL, LS_TOKEN, chunk_size=100)\n",
        "        existing = [i['data']['text'] for i in prev]\n",
        "\n",
        "    # Создаём новые таски для оставшихся текстов\n",
        "    for text_id, text in texts_with_ids:\n",
        "        if text not in existing:\n",
        "            create_task(ls, proj.id, text, text_id)\n",
        "\n",
        "    print(f\"Созданы {len(texts_with_ids) - len(existing)} новых задач в '{title}'\")\n",
        "    input(f\"Разметь их и нажми Enter...\")\n",
        "\n",
        "    # Экспорт и разбираем аннотации\n",
        "    data = export_project(ls, proj.id)\n",
        "    with open(export_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    examples = []\n",
        "    for item in data:\n",
        "        tags = []\n",
        "        for ann in item.get('annotations', []):\n",
        "            for r in ann.get('result', []):\n",
        "                v = r.get('value')\n",
        "                if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                    tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "        examples.append({'text': item['data']['text'], 'tags': tags})\n",
        "\n",
        "    print(f\"Экспортировано {len(examples)} примеров в {export_path}\")\n",
        "    return examples\n",
        "\n",
        "def align_labels(example):\n",
        "    \"\"\"\n",
        "    Привязывает аннотации к токенам текста.\n",
        "\n",
        "    Параметры:\n",
        "    - example: пример с текстом и аннотациями\n",
        "\n",
        "    Возвращает:\n",
        "    - список ID меток для каждого токена\n",
        "    \"\"\"\n",
        "    tok = TOKENIZER(example['text'], return_offsets_mapping=True, truncation=True, max_length=512)\n",
        "    labels = ['O'] * len(tok['offset_mapping'])\n",
        "\n",
        "    # Для каждой аннотации находим соответствующие токены\n",
        "    for tag in example.get('tags', []):\n",
        "        for i, (s, e) in enumerate(tok['offset_mapping']):\n",
        "            if s >= tag['start'] and e <= tag['end']:\n",
        "                # B- для начала сущности, I- для продолжения\n",
        "                labels[i] = ('B-' if s == tag['start'] else 'I-') + tag['label']\n",
        "\n",
        "    return [LABEL2ID[l] for l in labels]\n",
        "\n",
        "def to_hf_dataset(examples):\n",
        "    \"\"\"\n",
        "    Преобразует примеры в формат HuggingFace Dataset.\n",
        "\n",
        "    Параметры:\n",
        "    - examples: список примеров с текстами и аннотациями\n",
        "\n",
        "    Возвращает:\n",
        "    - датасет в формате HuggingFace\n",
        "    - коллатор для батчей\n",
        "    - список текстов\n",
        "    \"\"\"\n",
        "    if not examples: return None, None, []\n",
        "\n",
        "    # Преобразуем в DataFrame\n",
        "    df = pd.DataFrame(examples)\n",
        "    ds = Dataset.from_pandas(df)\n",
        "\n",
        "    # Сохраняем тексты для последующего анализа\n",
        "    texts = df['text'].tolist()\n",
        "\n",
        "    def fn(ex):\n",
        "        # Токенизация и выравнивание меток\n",
        "        tok = TOKENIZER(ex['text'], truncation=True, padding='max_length', max_length=512)\n",
        "        aligned = align_labels(ex)\n",
        "        tok['labels'] = aligned + [-100] * (512 - len(aligned))  # -100 для padding\n",
        "        return tok\n",
        "\n",
        "    ds = ds.map(fn, batched=False, remove_columns=['text','tags'])\n",
        "    return ds, DataCollatorForTokenClassification(TOKENIZER), texts\n",
        "\n",
        "def update_remaining_dataset(remaining_df, json_file):\n",
        "    \"\"\"\n",
        "    Обновляет оставшийся датасет, удаляя из него сообщения, которые были размечены.\n",
        "    Args:\n",
        "        remaining_df: DataFrame с оставшимися сообщениями\n",
        "        json_file: путь к JSON файлу с размеченными данными\n",
        "    Returns:\n",
        "        Обновленный DataFrame с оставшимися сообщениями\n",
        "    \"\"\"\n",
        "    # Удаляем все print, связанные с размером датасета и совпадениями\n",
        "    # Загружаем размеченные данные\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        labeled_data = json.load(f)\n",
        "    # Получаем ID сообщений из JSON файла\n",
        "    labeled_ids = []\n",
        "    for item in labeled_data:\n",
        "        if 'data' in item and 'meta' in item['data'] and 'id' in item['data']['meta']:\n",
        "            labeled_ids.append(str(item['data']['meta']['id']))\n",
        "    if labeled_ids:\n",
        "        # Проверяем, есть ли совпадения ID\n",
        "        matching_ids = remaining_df.index.astype(str).isin(labeled_ids)\n",
        "        # Удаляем строки, где индекс совпадает с ID из JSON\n",
        "        remaining_df = remaining_df[~remaining_df.index.astype(str).isin(labeled_ids)]\n",
        "    return remaining_df\n",
        "\n",
        "def compute_metrics(p):\n",
        "    \"\"\"\n",
        "    Вычисляет метрики для оценки модели NER.\n",
        "    \"\"\"\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    refs, hyps = [], []\n",
        "    for pr, gt in zip(preds, p.label_ids):\n",
        "        r_seq, h_seq = [], []\n",
        "        for pi, gi in zip(pr, gt):\n",
        "            if gi == -100:\n",
        "                continue\n",
        "            r_seq.append(ID2LABEL[gi])\n",
        "            h_seq.append(ID2LABEL[pi])\n",
        "        refs.append(r_seq)\n",
        "        hyps.append(h_seq)\n",
        "    out = metric.compute(predictions=hyps, references=refs)\n",
        "    return {\n",
        "        'precision': out['overall_precision'],\n",
        "        'recall': out['overall_recall'],\n",
        "        'f1': out['overall_f1']\n",
        "    }\n",
        "\n",
        "def predict_entities(text: str, model, tokenizer, id2label: Dict[int, str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Извлекает именованные сущности из текста с помощью обученной модели.\n",
        "\n",
        "    Args:\n",
        "        text (str): Входной текст для анализа\n",
        "        model: Обученная модель NER\n",
        "        tokenizer: Токенизатор для обработки текста\n",
        "        id2label (Dict[int, str]): Словарь для преобразования ID в метки\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Список словарей с найденными сущностями в формате:\n",
        "            [{'text': 'текст сущности', 'label': 'тип сущности', 'start': начало, 'end': конец}]\n",
        "    \"\"\"\n",
        "    # Определяем устройство для вычислений (GPU/CPU)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Токенизация текста с сохранением маппинга позиций\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    offset_mapping = inputs.pop('offset_mapping')[0]\n",
        "\n",
        "    # Перенос входных данных на нужное устройство\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Получение предсказаний модели\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = outputs.logits.argmax(-1)[0]\n",
        "\n",
        "    # Перенос предсказаний обратно на CPU для обработки\n",
        "    predictions = predictions.cpu()\n",
        "\n",
        "    # Обработка предсказаний и сбор сущностей\n",
        "    entities = []\n",
        "    current_entity = None\n",
        "\n",
        "    # Проходим по всем токенам и их позициям\n",
        "    for pred, (start, end) in zip(predictions, offset_mapping):\n",
        "        # Пропускаем специальные токены (CLS, SEP, PAD)\n",
        "        if start == 0 and end == 0:\n",
        "            continue\n",
        "\n",
        "        # Получаем метку для текущего токена\n",
        "        label = id2label[pred.item()]\n",
        "\n",
        "        if label.startswith('B-'):\n",
        "            # Если встретили начало новой сущности\n",
        "            if current_entity:\n",
        "                # Сохраняем предыдущую сущность\n",
        "                entities.append(current_entity)\n",
        "            # Создаем новую сущность\n",
        "            current_entity = {\n",
        "                'text': text[start:end],\n",
        "                'label': label[2:],  # Убираем префикс B-\n",
        "                'start': start,\n",
        "                'end': end\n",
        "            }\n",
        "        elif label.startswith('I-') and current_entity and label[2:] == current_entity['label']:\n",
        "            # Продолжаем текущую сущность\n",
        "            current_entity['text'] += text[start:end]\n",
        "            current_entity['end'] = end\n",
        "        else:\n",
        "            # Если встретили токен вне сущности\n",
        "            if current_entity:\n",
        "                # Сохраняем текущую сущность\n",
        "                entities.append(current_entity)\n",
        "                current_entity = None\n",
        "\n",
        "    # Добавляем последнюю сущность, если она есть\n",
        "    if current_entity:\n",
        "        entities.append(current_entity)\n",
        "\n",
        "    return entities\n",
        "\n",
        "def test_model_on_example(model, tokenizer, text):\n",
        "    \"\"\"\n",
        "    Тестирует только NER модель на одном примере и выводит результаты разметки в унифицированном формате.\n",
        "    Выводит все определенные сущности.\n",
        "    \"\"\"\n",
        "    print(f\"\\nТестовый пример:\")\n",
        "    print(f\"Текст: {text}\")\n",
        "\n",
        "    # Получаем предсказанные сущности\n",
        "    entities = predict_entities(text, model, tokenizer, ID2LABEL)\n",
        "\n",
        "    # Группируем сущности по типу\n",
        "    ent_by_type = {label: [] for label in LABELS}\n",
        "    for ent in entities:\n",
        "        if ent['label'] in ent_by_type:\n",
        "            ent_by_type[ent['label']].append(ent['text'])\n",
        "\n",
        "    # Выводим результаты NER\n",
        "    print(\"\\n[NER] Результаты анализа:\")\n",
        "    for label in LABELS:\n",
        "        if ent_by_type[label]:\n",
        "            print(f\"{label}: {', '.join(ent_by_type[label])}\")\n",
        "        else:\n",
        "            print(f\"{label}: не найдено\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFJexHKPktqv"
      },
      "outputs": [],
      "source": [
        "def run_cycle(df_path: str, sizes, start_size: Optional[int] = None) -> None:\n",
        "    \"\"\"\n",
        "    Запускает цикл обучения модели NER с активным обучением.\n",
        "\n",
        "    Args:\n",
        "        df_path (str): Путь к исходному датасету\n",
        "        start_size (Optional[int]): Размер выборки, с которой начать обучение\n",
        "    \"\"\"\n",
        "    # Загружаем датасет и создаем копию для оставшихся сообщений\n",
        "    df = pd.read_csv(df_path, sep=';', index_col=0)\n",
        "    print(f\"Загружен исходный датасет размером {len(df)} сообщений\")\n",
        "    print(\"Первые 5 строк исходного датасета:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Если указан start_size, находим его индекс в списке sizes\n",
        "    start_index = 0\n",
        "    if start_size is not None:\n",
        "        try:\n",
        "            start_index = sizes.index(start_size)\n",
        "            print(f\"Начинаем с итерации {start_index + 1} (размер выборки {start_size})\")\n",
        "        except ValueError:\n",
        "            print(f\"Ошибка: размер выборки {start_size} не найден в списке допустимых размеров\")\n",
        "            return\n",
        "\n",
        "    # Проверяем существование тестового проекта\n",
        "    test_project_title = 'PollenNER TEST'\n",
        "    test_project = get_or_create_project(ls, test_project_title, LABEL_CONFIG)\n",
        "    test_tasks = get_project_tasks(ls, test_project.id)\n",
        "\n",
        "    # Если тестовый проект пустой или не существует, создаем его\n",
        "    if not test_tasks:\n",
        "        print(\"\\nСоздание тестового проекта из случайных записей\")\n",
        "        # Выбираем 100 случайных записей с фиксированным seed\n",
        "        test_df = df.sample(n=100, random_state=SEED)\n",
        "        test_texts_with_ids = [(idx, text) for idx, text in zip(test_df.index, test_df['text'])]\n",
        "\n",
        "        # Создаем задачи в Label Studio\n",
        "        for text_id, text in test_texts_with_ids:\n",
        "            create_task(ls, test_project.id, text, text_id)\n",
        "\n",
        "        print(f\"Создано {len(test_texts_with_ids)} тестовых задач\")\n",
        "        print(\"Пожалуйста, разместите тестовые данные в Label Studio\")\n",
        "        input(\"Нажмите Enter после завершения разметки...\")\n",
        "\n",
        "        # Экспортируем размеченные данные\n",
        "        test_data = export_project(ls, test_project.id)\n",
        "        with open('PollenNER_TEST.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # Преобразуем данные в формат для обучения\n",
        "        test_ex = []\n",
        "        for item in test_data:\n",
        "            tags = []\n",
        "            for ann in item.get('annotations', []):\n",
        "                for r in ann.get('result', []):\n",
        "                    v = r.get('value')\n",
        "                    if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                        tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "            test_ex.append({'text': item['data']['text'], 'tags': tags})\n",
        "\n",
        "        # Создаем тестовый датасет\n",
        "        test_ds, _, _ = to_hf_dataset(test_ex)\n",
        "\n",
        "        # Обновляем оставшийся датасет\n",
        "        test_ids = [str(item['data']['meta']['id']) for item in test_data]\n",
        "        remaining_df = df[~df.index.astype(str).isin(test_ids)]\n",
        "        print(f\"Размер оставшегося датасета после создания тестового: {len(remaining_df)}\")\n",
        "    else:\n",
        "        print(\"\\nТестовый проект уже существует, загружаем данные\")\n",
        "        # Загружаем существующие тестовые данные\n",
        "        with open('PollenNER_TEST.json', 'r', encoding='utf-8') as f:\n",
        "            test_data = json.load(f)\n",
        "\n",
        "        # Преобразуем данные в формат для обучения\n",
        "        test_ex = []\n",
        "        for item in test_data:\n",
        "            tags = []\n",
        "            for ann in item.get('annotations', []):\n",
        "                for r in ann.get('result', []):\n",
        "                    v = r.get('value')\n",
        "                    if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                        tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "            test_ex.append({'text': item['data']['text'], 'tags': tags})\n",
        "\n",
        "        test_ds, _, _ = to_hf_dataset(test_ex)\n",
        "        test_ids = [str(item['data']['meta']['id']) for item in test_data]\n",
        "        remaining_df = df[~df.index.astype(str).isin(test_ids)]\n",
        "        print(f\"Размер оставшегося датасета: {len(remaining_df)}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # --- Инициализация базовой модели с dropout через конфиг ---\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        'DeepPavlov/rubert-base-cased',\n",
        "        hidden_dropout_prob=0.3,  # Dropout для регуляризации\n",
        "        attention_probs_dropout_prob=0.3,  # Dropout на внимании\n",
        "        id2label=ID2LABEL,\n",
        "        label2id=LABEL2ID\n",
        "    )\n",
        "    base_model = AutoModelForTokenClassification.from_pretrained('DeepPavlov/rubert-base-cased', config=config)\n",
        "\n",
        "    # Если начинаем не с начала, загружаем последнюю обученную модель\n",
        "    if start_index > 0:\n",
        "        prev_size = sizes[start_index - 1]\n",
        "        model_path = f'models/pollen_ner_{prev_size}'\n",
        "        if os.path.exists(model_path):\n",
        "            print(f\"Загружаем модель из {model_path}\")\n",
        "            model = get_peft_model(base_model,\n",
        "                                   LoraConfig(task_type='TOKEN_CLS',\n",
        "                                              r=16,\n",
        "                                              lora_alpha=32,\n",
        "                                              lora_dropout=0.1))\n",
        "            model.load_adapter(model_path, adapter_name=\"default\")\n",
        "            # Перемещаем модель на GPU, если доступен\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model = model.to(device)\n",
        "            print(f\"Модель перемещена на {device}\")\n",
        "        else:\n",
        "            print(f\"Ошибка: модель {model_path} не найдена\")\n",
        "            return\n",
        "    else:\n",
        "        model = get_peft_model(base_model, LoraConfig(task_type='TOKEN_CLS',\n",
        "                                                      r=16,\n",
        "                                                      lora_alpha=32,\n",
        "                                                      lora_dropout=0.1))\n",
        "        # Перемещаем модель на GPU, если доступен\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        print(f\"Модель перемещена на {device}\")\n",
        "\n",
        "    # Продолжаем с указанной итерации\n",
        "    for i, size in enumerate(sizes[start_index:], start_index):\n",
        "        print(f\"\\n[NER] Начинаем итерацию с размером выборки {size}\")\n",
        "\n",
        "        # Проверяем наличие существующего проекта для текущего размера\n",
        "        title = f'PollenNER TRAIN {size}'\n",
        "        export_file = f'PollenNER_TRAIN_{size}.json'\n",
        "\n",
        "        # Проверяем, существует ли проект и все ли задачи размечены\n",
        "        proj = get_or_create_project(ls, title, LABEL_CONFIG)\n",
        "        tasks = get_project_tasks(ls, proj.id)\n",
        "\n",
        "        if tasks and all(t.is_labeled for t in tasks):\n",
        "            print(f\"Найден существующий размеченный проект для размера {size}\")\n",
        "            # Экспортируем размеченные данные\n",
        "            data = export_project(ls, proj.id)\n",
        "            with open(export_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            # Преобразуем данные в формат для обучения\n",
        "            train_ex = []\n",
        "            for item in data:\n",
        "                tags = []\n",
        "                for ann in item.get('annotations', []):\n",
        "                    for r in ann.get('result', []):\n",
        "                        v = r.get('value')\n",
        "                        if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                            tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "                train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
        "        else:\n",
        "            # Если это первая итерация и проект пустой, создаем его с нуля\n",
        "            if i == start_index and not tasks:\n",
        "                print(f\"\\nСоздание первого тренировочного проекта с размером {size}\")\n",
        "                # Выбираем случайные записи с фиксированным seed\n",
        "                train_df = remaining_df.sample(n=size, random_state=SEED)\n",
        "                train_texts_with_ids = [(idx, text) for idx, text in zip(train_df.index, train_df['text'])]\n",
        "\n",
        "                # Создаем задачи в Label Studio\n",
        "                for text_id, text in train_texts_with_ids:\n",
        "                    create_task(ls, proj.id, text, text_id)\n",
        "\n",
        "                print(f\"Создано {len(train_texts_with_ids)} тренировочных задач\")\n",
        "                print(\"Пожалуйста, разместите тренировочные данные в Label Studio\")\n",
        "                input(\"Нажмите Enter после завершения разметки...\")\n",
        "\n",
        "                # Экспортируем размеченные данные\n",
        "                data = export_project(ls, proj.id)\n",
        "                with open(export_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "                # Преобразуем данные в формат для обучения\n",
        "                train_ex = []\n",
        "                for item in data:\n",
        "                    tags = []\n",
        "                    for ann in item.get('annotations', []):\n",
        "                        for r in ann.get('result', []):\n",
        "                            v = r.get('value')\n",
        "                            if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                                tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "                    train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
        "            else:\n",
        "                # Загружаем размеченные данные из предыдущей итерации\n",
        "                prev_size = sizes[i-1] if i > 0 else 0\n",
        "                prev_json = f'PollenNER_TRAIN_{prev_size}.json'\n",
        "                if os.path.exists(prev_json):\n",
        "                    print(f\"Загружаем размеченные данные из {prev_json}\")\n",
        "                    with open(prev_json, 'r', encoding='utf-8') as f:\n",
        "                        prev_data = json.load(f)\n",
        "\n",
        "                    # Создаем список задач для импорта\n",
        "                    tasks_list = []\n",
        "\n",
        "                    # Добавляем размеченные данные из предыдущей итерации\n",
        "                    for item in prev_data:\n",
        "                        tasks_list.append({\n",
        "                            'data': {\n",
        "                                'text': item['data']['text'],\n",
        "                                'meta': {\n",
        "                                    'id': item['data']['meta']['id']\n",
        "                                }\n",
        "                            },\n",
        "                            'annotations': item.get('annotations', [])\n",
        "                        })\n",
        "\n",
        "                    # Импортируем размеченные данные\n",
        "                    if tasks_list:\n",
        "                        print(f\"Импортируем {len(tasks_list)} размеченных сообщений из предыдущей итерации\")\n",
        "                        bulk_import_via_http(proj.id, tasks_list, LS_URL, LS_TOKEN)\n",
        "\n",
        "                # Выбираем наименее уверенные примеры из оставшегося датасета\n",
        "                if len(remaining_df) > 0:\n",
        "                    # Получаем оценки неопределенности для всех оставшихся сообщений\n",
        "                    uncertainties = calculate_uncertainty_scores(model,\n",
        "                                                                 remaining_df['text'].tolist(),\n",
        "                                                                 TOKENIZER)\n",
        "\n",
        "                    # Выбираем сообщения с наивысшей неопределенностью\n",
        "                    # Количество новых примеров = текущий размер - предыдущий размер\n",
        "                    n_new_samples = size - prev_size\n",
        "                    selected_indices = select_samples_improved(\n",
        "                        model,\n",
        "                        remaining_df['text'].tolist(),\n",
        "                        TOKENIZER,\n",
        "                        n_samples=n_new_samples,\n",
        "                        remaining_texts=remaining_df['text'].tolist(),\n",
        "                        current_iteration=i\n",
        "                    )\n",
        "\n",
        "                    # Получаем выбранные сообщения с их ID\n",
        "                    selected_df = remaining_df.iloc[selected_indices]\n",
        "                    train_texts = [(idx, text) for idx, text in zip(selected_df.index, selected_df['text'])]\n",
        "\n",
        "                    # Добавляем новые сообщения в проект\n",
        "                    print(f\"Добавляем {len(train_texts)} новых сообщений для разметки\")\n",
        "                    for text_id, text in train_texts:\n",
        "                        create_task(ls, proj.id, text, text_id)\n",
        "\n",
        "                    # Ждем разметки новых данных\n",
        "                    print(f\"\\nРазметьте {len(train_texts)} новых сообщений в Label Studio\")\n",
        "                    input(\"Нажмите Enter после завершения разметки...\")\n",
        "\n",
        "                    # Экспортируем все размеченные данные\n",
        "                    data = export_project(ls, proj.id)\n",
        "                    with open(export_file, 'w', encoding='utf-8') as f:\n",
        "                        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "                    # Преобразуем данные в формат для обучения\n",
        "                    train_ex = []\n",
        "                    for item in data:\n",
        "                        tags = []\n",
        "                        for ann in item.get('annotations', []):\n",
        "                            for r in ann.get('result', []):\n",
        "                                v = r.get('value')\n",
        "                                if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
        "                                    tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
        "                        train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
        "                else:\n",
        "                    print(\"Больше нет доступных сообщений для обучения\")\n",
        "                    break\n",
        "\n",
        "        # Обновляем оставшийся датасет\n",
        "        remaining_df = update_remaining_dataset(remaining_df, export_file)\n",
        "\n",
        "        print(f\"После итерации {i+1} осталось {len(remaining_df)} сообщений\")\n",
        "\n",
        "        train_ds, coll, train_texts = to_hf_dataset(train_ex)\n",
        "\n",
        "        # Настройка аргументов тренировки\n",
        "        args = TrainingArguments(\n",
        "            output_dir=f'runs/train_{size}',\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=8,\n",
        "            num_train_epochs=10,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model='eval_f1',\n",
        "            greater_is_better=True,\n",
        "            eval_strategy='epoch',\n",
        "            save_strategy='epoch',\n",
        "            save_total_limit=2,\n",
        "            push_to_hub=True,\n",
        "            hub_model_id=f'pollen-ner-{size}',\n",
        "            hub_token=HF_TOKEN,\n",
        "            no_cuda=not torch.cuda.is_available(),\n",
        "            weight_decay=0.01  # L2-регуляризация для борьбы с переобучением\n",
        "        )\n",
        "\n",
        "        # Создаем trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=args,\n",
        "            train_dataset=train_ds,\n",
        "            eval_dataset=test_ds,\n",
        "            data_collator=coll,\n",
        "            tokenizer=TOKENIZER,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(\n",
        "                early_stopping_patience=2,\n",
        "                early_stopping_threshold=0.001\n",
        "            )]\n",
        "        )\n",
        "\n",
        "        print(f\"[NER] Обучение на {size} примерах\")\n",
        "        trainer.train()\n",
        "        ev = trainer.evaluate()\n",
        "        print(f\"[NER] Результаты: F1 = {ev['eval_f1']:.4f}\")\n",
        "\n",
        "        # Получаем предсказания для тестового набора\n",
        "        predictions = trainer.predict(test_ds)\n",
        "        preds = predictions.predictions.argmax(-1)\n",
        "        labels = predictions.label_ids\n",
        "\n",
        "        # Подготавливаем списки для эталонных и предсказанных последовательностей\n",
        "        refs, hyps = [], []\n",
        "        for pr, gt in zip(preds, labels):\n",
        "            r_seq, h_seq = [], []\n",
        "            for pi, gi in zip(pr, gt):\n",
        "                if gi == -100:\n",
        "                    continue\n",
        "                r_seq.append(ID2LABEL[gi])\n",
        "                h_seq.append(ID2LABEL[pi])\n",
        "            refs.append(r_seq)\n",
        "            hyps.append(h_seq)\n",
        "\n",
        "        # Преобразуем последовательности в плоский формат для classification_report\n",
        "        flat_refs = []\n",
        "        flat_hyps = []\n",
        "        for r_seq, h_seq in zip(refs, hyps):\n",
        "            flat_refs.extend(r_seq)\n",
        "            flat_hyps.extend(h_seq)\n",
        "\n",
        "        # Выводим подробный отчет о классификации\n",
        "        print(\"\\n[NER] Подробный отчет о классификации:\")\n",
        "        print(classification_report(flat_refs,\n",
        "                                    flat_hyps,\n",
        "                                    digits=4))\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        model_save_path = f'models/pollen_ner_{size}'\n",
        "        os.makedirs(model_save_path, exist_ok=True)\n",
        "        trainer.save_model(model_save_path)\n",
        "        print(f\"[NER] Модель сохранена в {model_save_path}\")\n",
        "\n",
        "        # --- Сохраняем только лучшую и одну финальную модель NER ---\n",
        "        best_f1 = -1\n",
        "        best_model_path = 'models/pollen_ner_best'\n",
        "\n",
        "        if ev['eval_f1'] > best_f1:\n",
        "            best_f1 = ev['eval_f1']\n",
        "            os.makedirs(best_model_path, exist_ok=True)\n",
        "            trainer.save_model(best_model_path)\n",
        "            TOKENIZER.save_pretrained(best_model_path)\n",
        "            print(f\"[NER] Лучшая модель за все итерации сохранена в {best_model_path}\")\n",
        "\n",
        "        # Тестируем модель на примерах после каждой итерации\n",
        "        print(\"\\n[NER] Тестирование модели после обучения:\")\n",
        "        test_model_on_example(model, TOKENIZER, TEST_EXAMPLES[0])\n",
        "\n",
        "        results.append({'size': size, 'f1': ev['eval_f1']})\n",
        "\n",
        "        # Загружаем лучшую модель для следующей итерации\n",
        "        model = get_peft_model(base_model,\n",
        "                               LoraConfig(task_type='TOKEN_CLS',\n",
        "                                          r=16,\n",
        "                                          lora_alpha=32,\n",
        "                                          lora_dropout=0.1))\n",
        "        model.load_adapter(model_save_path, adapter_name=\"default\")\n",
        "        # Перемещаем модель на GPU, если доступен\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        print(f\"Модель перемещена на {device}\")\n",
        "\n",
        "        # После каждой итерации выводим статистику распределения классов по train_texts\n",
        "        from collections import Counter\n",
        "        print(f\"\\nСтатистика распределения классов в тренировочном датасете после итерации {i+1}:\")\n",
        "        all_labels = []\n",
        "        for ex in train_texts:\n",
        "            # Для каждого текста можно получить предсказания NER, но если train_texts — это список текстов, то статистика по ним\n",
        "            # Если нужно по меткам, то train_ex содержит 'tags'\n",
        "            pass  # Можно доработать, если нужно по меткам\n",
        "        # Если train_ex доступен, можно посчитать по меткам:\n",
        "        if 'train_ex' in locals():\n",
        "            for ex in train_ex:\n",
        "                for tag in ex.get('tags', []):\n",
        "                    all_labels.append(tag['label'])\n",
        "            print(Counter(all_labels))\n",
        "        else:\n",
        "            print('Нет данных для подсчёта статистики по меткам.')\n",
        "\n",
        "    # Визуализация результатов\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    results_df = pd.DataFrame(results)\n",
        "    ax = plt.gca()\n",
        "    sns.lineplot(data=results_df, x='size', y='f1', marker='o', ax=ax)\n",
        "    ax.set_title('Зависимость F1 от размера выборки', pad=20)\n",
        "    ax.set_xlabel('Размер обучающей выборки')\n",
        "    ax.set_ylabel('F1 Score')\n",
        "    # Подпись только у максимального значения F1\n",
        "    max_idx = results_df['f1'].idxmax()\n",
        "    max_x = results_df.loc[max_idx, 'size']\n",
        "    max_y = results_df.loc[max_idx, 'f1']\n",
        "    ax.annotate(f'{max_y:.3f}', (max_x, max_y),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext=(0,10),\n",
        "                ha='center',\n",
        "                color='red',\n",
        "                fontsize=12,\n",
        "                fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Сохраняем график на диск\n",
        "    plt.savefig('learning_curve.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    # Выводим график на экран\n",
        "    plt.show()\n",
        "\n",
        "    # Закрываем график после сохранения и отображения\n",
        "    plt.close()\n",
        "\n",
        "    # Сохраняем финальный оставшийся датасет\n",
        "    remaining_df.to_csv('remaining_dataset_final.csv', sep=';')\n",
        "    print(f\"\\nФинальный оставшийся датасет сохранен в remaining_dataset_final.csv\")\n",
        "    print(f\"Размер финального датасета: {len(remaining_df)} сообщений\")\n",
        "\n",
        "    # После цикла обучения NER:\n",
        "    last_ner_model = model  # Сохраняем последнюю обученную NER-модель\n",
        "\n",
        "    # Загружаем последнюю сохранённую модель из директории\n",
        "    last_size = sizes[-1] if start_size is None else sizes[start_index + len(results) - 1]\n",
        "    model_save_path = f'models/pollen_ner_{last_size}'\n",
        "    base_model = AutoModelForTokenClassification.from_pretrained('DeepPavlov/rubert-base-cased',\n",
        "                                                                 id2label=ID2LABEL,\n",
        "                                                                 label2id=LABEL2ID)\n",
        "    last_ner_model = get_peft_model(base_model,\n",
        "                                    LoraConfig(task_type='TOKEN_CLS',\n",
        "                                               r=16,\n",
        "                                               lora_alpha=32,\n",
        "                                               lora_dropout=0.1))\n",
        "    last_ner_model.load_adapter(model_save_path,\n",
        "                                adapter_name=\"default\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    last_ner_model = last_ner_model.to(device)\n",
        "    return last_ner_model\n",
        "\n",
        "def calculate_text_diversity(texts, n_clusters=5):\n",
        "    \"\"\"\n",
        "    Рассчитывает разнообразие текстов с помощью кластеризации TF-IDF.\n",
        "\n",
        "    Параметры:\n",
        "    - texts: список текстов\n",
        "    - n_clusters: количество кластеров для кластеризации\n",
        "\n",
        "    Возвращает:\n",
        "    - оценку разнообразия текстов (0-1)\n",
        "    \"\"\"\n",
        "    with parallel_backend('loky', n_jobs=n_jobs):\n",
        "        # Векторизация текстов\n",
        "        vectorizer = TfidfVectorizer(max_features=1000)\n",
        "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "        # Кластеризация текстов\n",
        "        kmeans = KMeans(\n",
        "            n_clusters=min(n_clusters, len(texts)),\n",
        "            random_state=42\n",
        "        )\n",
        "        clusters = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "        # Анализ распределения текстов по кластерам\n",
        "        cluster_counts = Counter(clusters)\n",
        "\n",
        "        # Нормализация счетчиков для получения оценки разнообразия\n",
        "        total = len(texts)\n",
        "        diversity_scores = [1 - (count/total) for count in cluster_counts.values()]\n",
        "\n",
        "        return np.mean(diversity_scores)\n",
        "\n",
        "def calculate_class_distribution(texts, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Рассчитывает распределение классов в наборе текстов.\n",
        "\n",
        "    Параметры:\n",
        "    - texts: список текстов\n",
        "    - tokenizer: токенизатор\n",
        "    - model: модель для предсказаний\n",
        "\n",
        "    Возвращает:\n",
        "    - словарь с распределением классов\n",
        "    \"\"\"\n",
        "    class_counts = Counter()\n",
        "    total_tokens = 0\n",
        "\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(next(model.parameters()).device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = outputs.logits.argmax(-1)[0]\n",
        "\n",
        "        for pred in predictions:\n",
        "            label = ID2LABEL[pred.item()]\n",
        "            if label != 'O':\n",
        "                class_counts[label.split('-')[1]] += 1\n",
        "                total_tokens += 1\n",
        "\n",
        "    return {k: v/total_tokens for k, v in class_counts.items()} if total_tokens > 0 else {}\n",
        "\n",
        "def calculate_class_balance_score(class_distribution):\n",
        "    \"\"\"\n",
        "    Рассчитывает оценку баланса классов.\n",
        "\n",
        "    Параметры:\n",
        "    - class_distribution: распределение классов\n",
        "\n",
        "    Возвращает:\n",
        "    - оценку баланса (0-1)\n",
        "    \"\"\"\n",
        "    if not class_distribution:\n",
        "        return 0\n",
        "\n",
        "    # Расчет энтропии распределения\n",
        "    probs = list(class_distribution.values())\n",
        "    entropy = -sum(p * np.log(p) for p in probs)\n",
        "\n",
        "    # Нормализация энтропии\n",
        "    max_entropy = np.log(len(LABELS))\n",
        "    return entropy / max_entropy if max_entropy > 0 else 0\n",
        "\n",
        "def select_samples_improved(model,\n",
        "                            texts,\n",
        "                            tokenizer,\n",
        "                            n_samples=50,\n",
        "                            remaining_texts=None,\n",
        "                            current_iteration=0):\n",
        "    \"\"\"\n",
        "    Улучшенная стратегия отбора сообщений для активного обучения.\n",
        "    Учитывает неопределенность модели, разнообразие текстов и баланс классов.\n",
        "\n",
        "    Параметры:\n",
        "    - model: текущая модель\n",
        "    - texts: список текстов для отбора\n",
        "    - tokenizer: токенизатор\n",
        "    - n_samples: количество сообщений для отбора\n",
        "    - remaining_texts: оставшиеся тексты для учета разнообразия\n",
        "    - current_iteration: текущая итерация обучения\n",
        "\n",
        "    Возвращает:\n",
        "    - индексы отобранных сообщений\n",
        "    \"\"\"\n",
        "    # Веса для метрик\n",
        "    weights = {\n",
        "        'uncertainty': 0.5,      # Неопределенность модели\n",
        "        'text_diversity': 0.2,   # Разнообразие текстов\n",
        "        'class_balance': 0.3     # Баланс классов\n",
        "    }\n",
        "\n",
        "    # Получаем оценки неопределенности\n",
        "    uncertainties = calculate_uncertainty_scores(model, texts, tokenizer)\n",
        "\n",
        "    # Рассчитываем разнообразие текстов\n",
        "    n_clusters = min(5, max(2, len(texts) // 10))\n",
        "    if remaining_texts:\n",
        "        text_diversity = calculate_text_diversity(texts + remaining_texts, n_clusters=n_clusters)\n",
        "    else:\n",
        "        text_diversity = calculate_text_diversity(texts, n_clusters=n_clusters)\n",
        "\n",
        "    # Рассчитываем текущее распределение классов\n",
        "    current_distribution = calculate_class_distribution(texts, tokenizer, model)\n",
        "    class_balance = calculate_class_balance_score(current_distribution)\n",
        "\n",
        "    # Нормализация неопределенности\n",
        "    uncertainties = np.array(uncertainties)\n",
        "    uncertainties = (uncertainties - uncertainties.min()) / (uncertainties.max() - uncertainties.min() + 1e-10)\n",
        "\n",
        "    # Комбинирование метрик с весами\n",
        "    combined_scores = (\n",
        "        weights['uncertainty'] * uncertainties +\n",
        "        weights['text_diversity'] * text_diversity +\n",
        "        weights['class_balance'] * class_balance\n",
        "    )\n",
        "\n",
        "    # Выбор сообщений с наивысшими комбинированными оценками\n",
        "    selected_indices = np.argsort(combined_scores)[-n_samples:]\n",
        "\n",
        "    # Вывод подробной статистики\n",
        "    print(\"\\nСтатистика отобранных сообщений:\")\n",
        "    print(f\"Итерация: {current_iteration}\")\n",
        "    print(f\"Веса метрик:\")\n",
        "    for metric, weight in weights.items():\n",
        "        print(f\"- {metric}: {weight:.3f}\")\n",
        "    print(f\"Средняя неопределенность: {np.mean(uncertainties[selected_indices]):.4f}\")\n",
        "    print(f\"Разнообразие текстов: {text_diversity:.4f}\")\n",
        "    print(f\"Баланс классов: {class_balance:.4f}\")\n",
        "    print(\"\\nРаспределение классов:\")\n",
        "    for label, prob in current_distribution.items():\n",
        "        print(f\"- {label}: {prob:.3f}\")\n",
        "\n",
        "    return selected_indices\n",
        "\n",
        "def parse_labelstudio_json(json_path):\n",
        "    \"\"\"\n",
        "    Извлекает сущности и отношения из разметки Label Studio (JSON).\n",
        "    Поддерживает только отношения из RE_RELATION_LABELS.\n",
        "    Пропускает примеры без сущностей или с одной сущностью.\n",
        "\n",
        "    Важно: для RE критично, чтобы id в отношениях (from_id, to_id) совпадали с id сущностей.\n",
        "    Также важно учитывать направленность отношений (from_id -> to_id).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    for item in data:\n",
        "        text = item['data']['text']\n",
        "        ann = item['annotations'][0]['result'] if item['annotations'] and 'result' in item['annotations'][0] else []\n",
        "        entities = []\n",
        "        relations = []\n",
        "        for obj in ann:\n",
        "            if obj.get('type') == 'labels':\n",
        "                ent = {\n",
        "                    'id': obj['id'],\n",
        "                    'start': obj['value']['start'],\n",
        "                    'end': obj['value']['end'],\n",
        "                    'label': obj['value']['labels'][0],\n",
        "                    'text': obj['value']['text']\n",
        "                }\n",
        "                entities.append(ent)\n",
        "        for obj in ann:\n",
        "            if obj.get('type') == 'relation':\n",
        "                if 'labels' in obj:\n",
        "                    rel_label = obj['labels'][0]\n",
        "                elif 'label' in obj:\n",
        "                    rel_label = obj['label']\n",
        "                else:\n",
        "                    rel_label = 'unknown_relation'\n",
        "                if rel_label in RE_RELATION_LABELS:\n",
        "                    rel = {\n",
        "                        'from_id': obj['from_id'],\n",
        "                        'to_id': obj['to_id'],\n",
        "                        'label': rel_label\n",
        "                    }\n",
        "                    relations.append(rel)\n",
        "        # Пропускаем примеры без сущностей или с одной сущностью\n",
        "        if len(entities) < 2:\n",
        "            continue\n",
        "        results.append({'text': text, 'entities': entities, 'relations': relations})\n",
        "    return results\n",
        "\n",
        "def split_sentences(text):\n",
        "    \"\"\"\n",
        "    Разбивает текст на предложения по точкам, восклицательным и вопросительным знакам.\n",
        "    Можно заменить на более продвинутый токенизатор (например, nltk), если потребуется.\n",
        "    \"\"\"\n",
        "    return [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
        "\n",
        "def prepare_re_dataset(parsed_data,\n",
        "                       relation_labels=None,\n",
        "                       max_no_relation_ratio=3,\n",
        "                       oversample_medicine=False):\n",
        "    \"\"\"\n",
        "    Формирует датасет для обучения модели извлечения отношений (RE) с балансировкой класса 'no_relation'.\n",
        "    Использует только отношения из RE_RELATION_LABELS.\n",
        "    Пропускает примеры с одной сущностью.\n",
        "    max_no_relation_ratio: максимальное соотношение 'no_relation' к числу позитивных примеров (например, 3:1).\n",
        "    Теперь пары формируются только между сущностями, находящимися в одном предложении.\n",
        "    oversample_medicine: если True, увеличивает число примеров has_medicine до числа has_symptom (дублированием)\n",
        "    \"\"\"\n",
        "    if relation_labels is None:\n",
        "        relation_labels = RE_RELATION_LABELS.copy()\n",
        "    relation_labels = relation_labels + ['no_relation']\n",
        "\n",
        "    re_examples = []\n",
        "    for item in parsed_data:\n",
        "        text = item['text']\n",
        "        entities = item['entities']\n",
        "        relations = item['relations']\n",
        "        if len(entities) < 2:\n",
        "            continue\n",
        "        # Разбиваем текст на предложения\n",
        "        sentences = split_sentences(text)\n",
        "        # Для каждого предложения ищем сущности, которые в него попадают\n",
        "        for sent in sentences:\n",
        "            sent_start = text.find(sent)\n",
        "            sent_end = sent_start + len(sent)\n",
        "            ents_in_sent = [e for e in entities if e['start'] >= sent_start and e['end'] <= sent_end]\n",
        "            # Генерируем пары только внутри предложения\n",
        "            positive, negative = [], []\n",
        "            for i, ent1 in enumerate(ents_in_sent):\n",
        "                for j, ent2 in enumerate(ents_in_sent):\n",
        "                    if i == j:\n",
        "                        continue\n",
        "                    # Фильтруем только осмысленные пары:\n",
        "                    # BODY_PART–SYMPTOM (has_symptom) и BODY_PART–MEDICINE (has_medicine)\n",
        "                    if ent1['label'] == 'BODY_PART' and ent2['label'] == 'SYMPTOM':\n",
        "                        rel_label = None\n",
        "                        for rel in relations:\n",
        "                            if rel['from_id'] == ent1['id'] and rel['to_id'] == ent2['id']:\n",
        "                                rel_label = rel['label']\n",
        "                                break\n",
        "                        rel_label = rel_label if rel_label in relation_labels else 'no_relation'\n",
        "                        ex = {\n",
        "                            'text': text,\n",
        "                            'entity1': ent1,\n",
        "                            'entity2': ent2,\n",
        "                            'relation': rel_label\n",
        "                        }\n",
        "                        if ex['relation'] == 'no_relation':\n",
        "                            negative.append(ex)\n",
        "                        else:\n",
        "                            positive.append(ex)\n",
        "                    elif ent1['label'] == 'BODY_PART' and ent2['label'] == 'MEDICINE':\n",
        "                        rel_label = None\n",
        "                        for rel in relations:\n",
        "                            if rel['from_id'] == ent1['id'] and rel['to_id'] == ent2['id']:\n",
        "                                rel_label = rel['label']\n",
        "                                break\n",
        "                        rel_label = rel_label if rel_label in relation_labels else 'no_relation'\n",
        "                        ex = {\n",
        "                            'text': text,\n",
        "                            'entity1': ent1,\n",
        "                            'entity2': ent2,\n",
        "                            'relation': rel_label\n",
        "                        }\n",
        "                        if ex['relation'] == 'no_relation':\n",
        "                            negative.append(ex)\n",
        "                        else:\n",
        "                            positive.append(ex)\n",
        "            # Балансируем: не больше max_no_relation_ratio * positive\n",
        "            if max_no_relation_ratio is not None and positive:\n",
        "                negative = random.sample(negative,\n",
        "                                         min(len(negative),\n",
        "                                             max_no_relation_ratio * len(positive)))\n",
        "            # --- Oversample has_medicine ---\n",
        "            if oversample_medicine:\n",
        "                medicine_pos = [ex for ex in positive if ex['relation'] == 'has_medicine']\n",
        "                symptom_count = len([ex for ex in positive if ex['relation'] == 'has_symptom'])\n",
        "                if medicine_pos and symptom_count > 0:\n",
        "                    repeats = max(1, symptom_count // len(medicine_pos))\n",
        "                    positive += medicine_pos * (repeats - 1)\n",
        "            re_examples.extend(positive + negative)\n",
        "    return re_examples, relation_labels\n",
        "\n",
        "def insert_entity_markers(text, ent1, ent2):\n",
        "    \"\"\"\n",
        "    Вставляет специальные маркеры вокруг двух сущностей с указанием их типа.\n",
        "    Теперь маркеры имеют вид [TYPE]...[/TYPE], где TYPE — тип сущности (например, BODY_PART, SYMPTOM).\n",
        "    Это помогает RE-модели лучше различать роли сущностей в паре.\n",
        "    \"\"\"\n",
        "    # Определяем порядок: сначала более ранняя сущность\n",
        "    if ent1['start'] < ent2['start']:\n",
        "        first, second = ent1, ent2\n",
        "    else:\n",
        "        first, second = ent2, ent1\n",
        "    # Формируем маркеры с типом сущности\n",
        "    first_tag = f'[{first[\"label\"]}]'\n",
        "    first_end_tag = f'[/{first[\"label\"]}]'\n",
        "    second_tag = f'[{second[\"label\"]}]'\n",
        "    second_end_tag = f'[/{second[\"label\"]}]'\n",
        "    # Вставляем маркеры с конца, чтобы не сбить индексы\n",
        "    text_marked = (\n",
        "        text[:second['start']] + second_tag +\n",
        "        text[second['start']:second['end']] + second_end_tag +\n",
        "        text[second['end']:] )\n",
        "    text_marked = (\n",
        "        text_marked[:first['start']] + first_tag +\n",
        "        text_marked[first['start']:first['end']] + first_end_tag +\n",
        "        text_marked[first['end']:] )\n",
        "    return text_marked\n",
        "\n",
        "def prepare_hf_re_dataset(re_examples, tokenizer, label2id, max_length=256):\n",
        "    \"\"\"\n",
        "    Преобразует список примеров RE в HuggingFace Dataset.\n",
        "    Теперь не добавляет признак distance, так как он не используется стандартной моделью.\n",
        "    Пропускает примеры с relation == 'unknown_relation'.\n",
        "    Пропускает пустые примеры.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for ex in re_examples:\n",
        "        if ex['relation'] == 'unknown_relation':\n",
        "            continue\n",
        "        if not ex['entity1']['text'].strip() or not ex['entity2']['text'].strip():\n",
        "            continue\n",
        "        text_marked = insert_entity_markers(ex['text'], ex['entity1'], ex['entity2'])\n",
        "        rows.append({\n",
        "            'text': text_marked,\n",
        "            'label': label2id[ex['relation']]\n",
        "        })\n",
        "    if not rows:\n",
        "        raise ValueError('Нет валидных примеров для RE!')\n",
        "    df = pd.DataFrame(rows)\n",
        "    def tokenize_fn(ex):\n",
        "        return tokenizer(\n",
        "            ex['text'],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length\n",
        "        )\n",
        "    ds = Dataset.from_pandas(df)\n",
        "    ds = ds.map(tokenize_fn, batched=False)\n",
        "    return ds\n",
        "\n",
        "def train_and_eval_re_model(train_ds,\n",
        "                            test_ds,\n",
        "                            num_labels,\n",
        "                            label2id,\n",
        "                            id2label,\n",
        "                            tokenizer,\n",
        "                            hf_token=None,\n",
        "                            output_dir='re_model',\n",
        "                            epochs=5):\n",
        "    \"\"\"\n",
        "    Обучает и оценивает модель для извлечения отношений (RE) на основе BERT.\n",
        "\n",
        "    Параметры:\n",
        "        train_ds: HuggingFace Dataset для обучения\n",
        "        test_ds: HuggingFace Dataset для теста\n",
        "        num_labels: число классов (отношений)\n",
        "        label2id, id2label: словари метка<->id\n",
        "        tokenizer: токенизатор\n",
        "        hf_token: токен для HuggingFace Hub (если нужен пуш)\n",
        "        output_dir: директория для сохранения модели\n",
        "        epochs: число эпох обучения\n",
        "\n",
        "    Возвращает:\n",
        "        trainer, eval_results: Trainer и результаты оценки\n",
        "    \"\"\"\n",
        "    # Загружаем базовую модель (ruBERT)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        'DeepPavlov/rubert-base-cased',\n",
        "        num_labels=num_labels,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "    # Аргументы тренировки для RE\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=5,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='eval_f1',\n",
        "        greater_is_better=True,\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        save_total_limit=2,\n",
        "        push_to_hub=bool(hf_token),\n",
        "        hub_model_id='pollen-re-model',\n",
        "        hub_token=hf_token,\n",
        "        no_cuda=not torch.cuda.is_available(),\n",
        "        weight_decay=0.01  # L2-регуляризация для RE\n",
        "    )\n",
        "    # Метрика\n",
        "    metric = evaluate.load('f1')\n",
        "    def compute_metrics_re(p):\n",
        "        preds = np.argmax(p.predictions, axis=1)\n",
        "        return metric.compute(predictions=preds,\n",
        "                              references=p.label_ids,\n",
        "                              average='macro')\n",
        "    # Trainer с EarlyStopping для RE\n",
        "    from transformers import EarlyStoppingCallback\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=test_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics_re,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    # Обучение\n",
        "    trainer.train()\n",
        "    # Оценка\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"\\nRE-модель: Macro F1 = {eval_results['eval_f1']:.4f}\")\n",
        "    # Сохраняем модель\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    trainer.save_model(output_dir)\n",
        "    print(f\"RE-модель сохранена в {output_dir}\")\n",
        "    return trainer, eval_results\n",
        "\n",
        "def infer_ner_re_on_text(text,\n",
        "                         ner_model,\n",
        "                         re_model,\n",
        "                         tokenizer,\n",
        "                         id2label_ner,\n",
        "                         id2label_re):\n",
        "    \"\"\"\n",
        "    Извлекает сущности и отношения из текста с помощью обученных моделей NER и RE.\n",
        "    Возвращает список сущностей и отношений.\n",
        "    Теперь перебирает только допустимые пары (BODY_PART–SYMPTOM и BODY_PART–MEDICINE) и только внутри одного предложения.\n",
        "    \"\"\"\n",
        "    # 1. Извлекаем сущности\n",
        "    entities = predict_entities(text, ner_model,\n",
        "                                tokenizer,\n",
        "                                id2label_ner)\n",
        "    # 2. Разбиваем текст на предложения\n",
        "    sentences = split_sentences(text)\n",
        "    relations = []\n",
        "    for sent in sentences:\n",
        "        sent_start = text.find(sent)\n",
        "        sent_end = sent_start + len(sent)\n",
        "        ents_in_sent = [e for e in entities if e['start'] >= sent_start and e['end'] <= sent_end]\n",
        "        # 3. Перебираем только допустимые пары внутри предложения\n",
        "        for ent1 in ents_in_sent:\n",
        "            for ent2 in ents_in_sent:\n",
        "                if ent1 == ent2:\n",
        "                    continue\n",
        "                # Только BODY_PART–SYMPTOM и BODY_PART–MEDICINE\n",
        "                if ent1['label'] == 'BODY_PART' and ent2['label'] == 'SYMPTOM':\n",
        "                    marked_text = insert_entity_markers(text, ent1, ent2)\n",
        "                    inputs = tokenizer(marked_text,\n",
        "                                       return_tensors='pt',\n",
        "                                       truncation=True,\n",
        "                                       max_length=256)\n",
        "                    inputs = {k: v.to(next(re_model.parameters()).device) for k, v in inputs.items()}\n",
        "                    with torch.no_grad():\n",
        "                        logits = re_model(**inputs).logits\n",
        "                        pred = logits.argmax(-1).item()\n",
        "                        rel_label = id2label_re[pred]\n",
        "                    if rel_label != 'no_relation':\n",
        "                        relations.append({'head': ent1,\n",
        "                                          'tail': ent2,\n",
        "                                          'relation': rel_label})\n",
        "                elif ent1['label'] == 'BODY_PART' and ent2['label'] == 'MEDICINE':\n",
        "                    marked_text = insert_entity_markers(text, ent1, ent2)\n",
        "                    inputs = tokenizer(marked_text,\n",
        "                                       return_tensors='pt',\n",
        "                                       truncation=True,\n",
        "                                       max_length=256)\n",
        "                    inputs = {k: v.to(next(re_model.parameters()).device) for k, v in inputs.items()}\n",
        "                    with torch.no_grad():\n",
        "                        logits = re_model(**inputs).logits\n",
        "                        pred = logits.argmax(-1).item()\n",
        "                        rel_label = id2label_re[pred]\n",
        "                    if rel_label != 'no_relation':\n",
        "                        relations.append({'head': ent1, 'tail': ent2, 'relation': rel_label})\n",
        "    return entities, relations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC07XiJqwxsI"
      },
      "source": [
        "## Запуск пайплайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "02e8f391af0840bfa4b91c67ccccc26d",
            "8c3be57727c4488eaef0ed20ca992223",
            "5e38ee2aa5fd4e2e9eaf4dbc217ef36e",
            "b4e7409dedab44009fc499fef5e8225a",
            "2b6b7931dfb34a2bb75fdf2a16ae7bce",
            "8b2debe2397f4a1fa2ebc08e1382c7b5",
            "cc766c1f11684d529103dd543052f857",
            "4ae82eaeb1fb429eb76e4a271c4aa826",
            "0ddec7ecc42f487ab1b14ff2024aec1a",
            "17dfdb822eab45cda405d63cddb832f6",
            "fc69fd6e2ad34795a477eb026bd60db6",
            "2c255f175fee4e348bef52f0c349672b",
            "7877df69b9844b1da4712e7c51f1d0e8",
            "a7d4b586c05d4ca38e43db9e773cc7a6",
            "b9fcf6d3b58c4179bd825016ef760455",
            "958a1af987c042f99903938a0cce10bb",
            "2b7007a54fa5453bbe1a9c4e84b5fe66",
            "2bbeab8b5db144c3b324f2e631f01dc4",
            "73ced4c5fe094a10a84bfd9cbf5dd4db",
            "51df127576174a228c6608d9736547ef",
            "8cb7acba16214dbcb582c94757698ea2",
            "c0cde6b7ca0e496ba4300f4773cd18a4",
            "f1587d9d0f324d4d88e770bb08ea5698",
            "9aa2970bd6d044629cd96d137dd02167",
            "51c2c2d4a375459d841643eca087bf13",
            "961cd81f23574200982195e954fb803e",
            "8b5644da55e346e88c6e8aee3b3cd8f2",
            "90796c4afe734738b635ccad8bb3701e",
            "5ec8ad785441485eaf358ae3c61ac33d",
            "178ceca309fb4f329a4a4821c8ebcd2b",
            "ebf39451fd1f446bb9e23624f4bcde60",
            "69a2ffebedb14d4f94ca5238e379a550",
            "63f9378721db43b6922e2881cf793bae"
          ]
        },
        "id": "5ImiWGcivFd7",
        "outputId": "2725df0b-0cfc-4722-916a-03111d8fbf26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Начинаем обучение NER-модели ===\n",
            "Загружен исходный датасет размером 4143 сообщений\n",
            "Первые 5 строк исходного датасета:\n",
            "                                                text\n",
            "0             Утром проснулась с отекшими глазами)))\n",
            "1  Открывала окна без спандбонда, нормально, ниче...\n",
            "2  Пока изменений в худшую сторону нет. Каникулы,...\n",
            "3  Я сегодня еле разодрала глаза и до сих сдуться...\n",
            "4  Я тоже сегодня опухшая, надутая, глаза дерет, ...\n",
            "\n",
            "Тестовый проект уже существует, загружаем данные\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02e8f391af0840bfa4b91c67ccccc26d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер оставшегося датасета: 4043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Модель перемещена на cuda\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 50\n",
            "Найден существующий размеченный проект для размера 50\n",
            "После итерации 1 осталось 3993 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c3be57727c4488eaef0ed20ca992223",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 50 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/70 00:19 < 00:49, 1.00 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.189697</td>\n",
              "      <td>0.011337</td>\n",
              "      <td>0.048193</td>\n",
              "      <td>0.018356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.074554</td>\n",
              "      <td>0.009229</td>\n",
              "      <td>0.028112</td>\n",
              "      <td>0.013896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.960316</td>\n",
              "      <td>0.004237</td>\n",
              "      <td>0.008032</td>\n",
              "      <td>0.005548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the best model at runs/train_50\\checkpoint-7\\pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0055\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
            " B-BODY_PART     0.0173    0.0390    0.0240        77\n",
            "  B-MEDICINE     0.0278    0.0196    0.0230        51\n",
            "   B-SYMPTOM     0.0659    0.1089    0.0821       101\n",
            "   B-TOPONYM     0.0182    0.0306    0.0229       196\n",
            "  I-ALLERGEN     0.1667    0.0250    0.0435        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.0667    0.0714    0.0690        84\n",
            "   I-SYMPTOM     0.0339    0.0164    0.0221       122\n",
            "   I-TOPONYM     0.0175    0.0227    0.0198        44\n",
            "           O     0.7749    0.7312    0.7524      2604\n",
            "\n",
            "    accuracy                         0.5620      3445\n",
            "   macro avg     0.1081    0.0968    0.0962      3445\n",
            "weighted avg     0.5964    0.5620    0.5770      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: В, началась, на, цу, ,, глаза, и, и, началось, ,, глаза, все\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: екли, приним, Зир, онекс, чешу, тся, оге, кса, онекс, приним\n",
            "ALLERGEN: сильная\n",
            "BODY_PART: пыль, ы, пот, но, равно, ятся\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 1:\n",
            "Counter({'SYMPTOM': 52, 'TOPONYM': 50, 'BODY_PART': 33, 'ALLERGEN': 32, 'MEDICINE': 29})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 100\n",
            "После итерации 2 осталось 3943 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e38ee2aa5fd4e2e9eaf4dbc217ef36e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 100 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 39/130 00:28 < 01:09, 1.32 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.681827</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.002865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.424544</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.003810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.221702</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0038\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
            " B-BODY_PART     0.1000    0.0130    0.0230        77\n",
            "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
            "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
            "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
            "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.2500    0.0119    0.0227        84\n",
            "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
            "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
            "           O     0.7563    0.9927    0.8585      2604\n",
            "\n",
            "    accuracy                         0.7509      3445\n",
            "   macro avg     0.1006    0.0925    0.0822      3445\n",
            "weighted avg     0.5800    0.7509    0.6500      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: оге\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: приним, приним\n",
            "ALLERGEN: не найдено\n",
            "BODY_PART: не найдено\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 2:\n",
            "Counter({'TOPONYM': 66, 'SYMPTOM': 60, 'ALLERGEN': 40, 'BODY_PART': 37, 'MEDICINE': 30})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 150\n",
            "После итерации 3 осталось 3893 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4e7409dedab44009fc499fef5e8225a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 150 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 57/190 00:37 < 01:31, 1.46 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.138603</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.077130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.063349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0000\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
            " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
            "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
            "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
            "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
            "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
            "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
            "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
            "           O     0.7556    0.9985    0.8602      2604\n",
            "\n",
            "    accuracy                         0.7547      3445\n",
            "   macro avg     0.0687    0.0908    0.0782      3445\n",
            "weighted avg     0.5711    0.7547    0.6502      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: не найдено\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: не найдено\n",
            "ALLERGEN: не найдено\n",
            "BODY_PART: не найдено\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 3:\n",
            "Counter({'TOPONYM': 83, 'SYMPTOM': 61, 'ALLERGEN': 43, 'BODY_PART': 37, 'MEDICINE': 31})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 200\n",
            "После итерации 4 осталось 3843 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b6b7931dfb34a2bb75fdf2a16ae7bce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 200 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 75/250 00:46 < 01:50, 1.58 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.069246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.048469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.031699</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0000\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
            " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
            "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
            "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
            "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
            "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
            "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
            "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
            "           O     0.7557    0.9992    0.8606      2604\n",
            "\n",
            "    accuracy                         0.7553      3445\n",
            "   macro avg     0.0687    0.0908    0.0782      3445\n",
            "weighted avg     0.5712    0.7553    0.6505      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: не найдено\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: не найдено\n",
            "ALLERGEN: не найдено\n",
            "BODY_PART: не найдено\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 4:\n",
            "Counter({'TOPONYM': 119, 'SYMPTOM': 92, 'ALLERGEN': 63, 'BODY_PART': 62, 'MEDICINE': 53})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 250\n",
            "После итерации 5 осталось 3793 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b2debe2397f4a1fa2ebc08e1382c7b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 250 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 96/320 00:55 < 02:12, 1.70 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.036307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.008782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.984869</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0000\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
            " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
            "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
            "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
            "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
            "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
            "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
            "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
            "           O     0.7558    0.9996    0.8608      2604\n",
            "\n",
            "    accuracy                         0.7556      3445\n",
            "   macro avg     0.0687    0.0909    0.0783      3445\n",
            "weighted avg     0.5713    0.7556    0.6506      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: не найдено\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: не найдено\n",
            "ALLERGEN: не найдено\n",
            "BODY_PART: не найдено\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 5:\n",
            "Counter({'TOPONYM': 179, 'SYMPTOM': 166, 'BODY_PART': 109, 'ALLERGEN': 102, 'MEDICINE': 101})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 300\n",
            "После итерации 6 осталось 3743 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc766c1f11684d529103dd543052f857",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 300 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [380/380 03:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.012953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.969458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.944900</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.004016</td>\n",
              "      <td>0.007937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.903092</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.010040</td>\n",
              "      <td>0.019646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.873162</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>0.023256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.850644</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.020080</td>\n",
              "      <td>0.038023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.831839</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.028112</td>\n",
              "      <td>0.052336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.820610</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.038153</td>\n",
              "      <td>0.069217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.812019</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.040161</td>\n",
              "      <td>0.072464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.808766</td>\n",
              "      <td>0.381818</td>\n",
              "      <td>0.042169</td>\n",
              "      <td>0.075949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.0759\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     1.0000    0.0145    0.0286        69\n",
            " B-BODY_PART     1.0000    0.0130    0.0256        77\n",
            "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
            "   B-SYMPTOM     0.4375    0.0693    0.1197       101\n",
            "   B-TOPONYM     0.7600    0.0969    0.1719       196\n",
            "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.7692    0.1190    0.2062        84\n",
            "   I-SYMPTOM     0.4000    0.0164    0.0315       122\n",
            "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
            "           O     0.7674    0.9973    0.8674      2604\n",
            "\n",
            "    accuracy                         0.7655      3445\n",
            "   macro avg     0.4667    0.1206    0.1319      3445\n",
            "weighted avg     0.7115    0.7655    0.6762      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: не найдено\n",
            "MEDICINE: не найдено\n",
            "SYMPTOM: пот\n",
            "ALLERGEN: не найдено\n",
            "BODY_PART: глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 6:\n",
            "Counter({'SYMPTOM': 262, 'TOPONYM': 251, 'BODY_PART': 172, 'MEDICINE': 136, 'ALLERGEN': 122})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 350\n",
            "После итерации 7 осталось 3693 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ae82eaeb1fb429eb76e4a271c4aa826",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 350 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [440/440 04:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.763975</td>\n",
              "      <td>0.388489</td>\n",
              "      <td>0.108434</td>\n",
              "      <td>0.169545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.710454</td>\n",
              "      <td>0.400943</td>\n",
              "      <td>0.170683</td>\n",
              "      <td>0.239437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.659551</td>\n",
              "      <td>0.443686</td>\n",
              "      <td>0.261044</td>\n",
              "      <td>0.328698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.632698</td>\n",
              "      <td>0.464646</td>\n",
              "      <td>0.369478</td>\n",
              "      <td>0.411633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.601423</td>\n",
              "      <td>0.475638</td>\n",
              "      <td>0.411647</td>\n",
              "      <td>0.441335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.577227</td>\n",
              "      <td>0.496552</td>\n",
              "      <td>0.433735</td>\n",
              "      <td>0.463023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.565663</td>\n",
              "      <td>0.512035</td>\n",
              "      <td>0.469880</td>\n",
              "      <td>0.490052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.559002</td>\n",
              "      <td>0.514463</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.507128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.548745</td>\n",
              "      <td>0.514523</td>\n",
              "      <td>0.497992</td>\n",
              "      <td>0.506122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.549772</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.514056</td>\n",
              "      <td>0.515091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.5151\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8696    0.2899    0.4348        69\n",
            " B-BODY_PART     0.7821    0.7922    0.7871        77\n",
            "  B-MEDICINE     0.8824    0.2941    0.4412        51\n",
            "   B-SYMPTOM     0.5109    0.6931    0.5882       101\n",
            "   B-TOPONYM     0.6973    0.6582    0.6772       196\n",
            "  I-ALLERGEN     1.0000    0.2125    0.3505        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.6400    0.7619    0.6957        84\n",
            "   I-SYMPTOM     0.5839    0.6557    0.6178       122\n",
            "   I-TOPONYM     1.0000    0.0682    0.1277        44\n",
            "           O     0.9076    0.9578    0.9320      2604\n",
            "\n",
            "    accuracy                         0.8572      3445\n",
            "   macro avg     0.7158    0.4894    0.5138      3445\n",
            "weighted avg     0.8609    0.8572    0.8417      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: не найдено\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс\n",
            "SYMPTOM: пыльцу, потекли, чешутся, течет, Эри, слезятся\n",
            "ALLERGEN: березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 7:\n",
            "Counter({'SYMPTOM': 385, 'TOPONYM': 314, 'BODY_PART': 247, 'MEDICINE': 173, 'ALLERGEN': 135})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 400\n",
            "После итерации 8 осталось 3643 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ddec7ecc42f487ab1b14ff2024aec1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 400 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 04:42, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.518508</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.578313</td>\n",
              "      <td>0.544423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.488345</td>\n",
              "      <td>0.529825</td>\n",
              "      <td>0.606426</td>\n",
              "      <td>0.565543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.482647</td>\n",
              "      <td>0.542429</td>\n",
              "      <td>0.654618</td>\n",
              "      <td>0.593267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.445696</td>\n",
              "      <td>0.562712</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.434444</td>\n",
              "      <td>0.561258</td>\n",
              "      <td>0.680723</td>\n",
              "      <td>0.615245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.426277</td>\n",
              "      <td>0.567700</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.626463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.418710</td>\n",
              "      <td>0.577997</td>\n",
              "      <td>0.706827</td>\n",
              "      <td>0.635953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.411142</td>\n",
              "      <td>0.587171</td>\n",
              "      <td>0.716867</td>\n",
              "      <td>0.645570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.409497</td>\n",
              "      <td>0.586491</td>\n",
              "      <td>0.714859</td>\n",
              "      <td>0.644344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.789100</td>\n",
              "      <td>0.408791</td>\n",
              "      <td>0.576299</td>\n",
              "      <td>0.712851</td>\n",
              "      <td>0.637343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.6456\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8000    0.5217    0.6316        69\n",
            " B-BODY_PART     0.7356    0.8312    0.7805        77\n",
            "  B-MEDICINE     0.6875    0.6471    0.6667        51\n",
            "   B-SYMPTOM     0.5517    0.7921    0.6504       101\n",
            "   B-TOPONYM     0.7104    0.9388    0.8088       196\n",
            "  I-ALLERGEN     0.9737    0.4625    0.6271        80\n",
            " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
            "  I-MEDICINE     0.7188    0.8214    0.7667        84\n",
            "   I-SYMPTOM     0.5600    0.8033    0.6599       122\n",
            "   I-TOPONYM     1.0000    0.3409    0.5085        44\n",
            "           O     0.9590    0.9343    0.9465      2604\n",
            "\n",
            "    accuracy                         0.8851      3445\n",
            "   macro avg     0.6997    0.6448    0.6406      3445\n",
            "weighted avg     0.8969    0.8851    0.8836      3445\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Модель сохранена в models/pollen_ner_400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московской\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: пыльцу, потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 8:\n",
            "Counter({'SYMPTOM': 497, 'TOPONYM': 366, 'BODY_PART': 331, 'MEDICINE': 204, 'ALLERGEN': 144})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 450\n",
            "После итерации 9 осталось 3593 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17dfdb822eab45cda405d63cddb832f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 450 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [570/570 05:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.389871</td>\n",
              "      <td>0.583468</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.645740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.373708</td>\n",
              "      <td>0.598039</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.659459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369982</td>\n",
              "      <td>0.599057</td>\n",
              "      <td>0.765060</td>\n",
              "      <td>0.671958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.348430</td>\n",
              "      <td>0.624793</td>\n",
              "      <td>0.759036</td>\n",
              "      <td>0.685403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.345752</td>\n",
              "      <td>0.619968</td>\n",
              "      <td>0.773092</td>\n",
              "      <td>0.688114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.332668</td>\n",
              "      <td>0.627869</td>\n",
              "      <td>0.769076</td>\n",
              "      <td>0.691336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.329945</td>\n",
              "      <td>0.631922</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>0.697842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.329302</td>\n",
              "      <td>0.633712</td>\n",
              "      <td>0.785141</td>\n",
              "      <td>0.701345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.660200</td>\n",
              "      <td>0.326973</td>\n",
              "      <td>0.631494</td>\n",
              "      <td>0.781124</td>\n",
              "      <td>0.698384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.660200</td>\n",
              "      <td>0.325700</td>\n",
              "      <td>0.633550</td>\n",
              "      <td>0.781124</td>\n",
              "      <td>0.699640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.7013\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7656    0.7101    0.7368        69\n",
            " B-BODY_PART     0.7765    0.8571    0.8148        77\n",
            "  B-MEDICINE     0.6471    0.6471    0.6471        51\n",
            "   B-SYMPTOM     0.6119    0.8119    0.6979       101\n",
            "   B-TOPONYM     0.7224    0.9694    0.8279       196\n",
            "  I-ALLERGEN     0.9444    0.6375    0.7612        80\n",
            " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
            "  I-MEDICINE     0.7245    0.8452    0.7802        84\n",
            "   I-SYMPTOM     0.6024    0.8197    0.6944       122\n",
            "   I-TOPONYM     0.9667    0.6591    0.7838        44\n",
            "           O     0.9652    0.9263    0.9453      2604\n",
            "\n",
            "    accuracy                         0.8952      3445\n",
            "   macro avg     0.7933    0.7220    0.7091      3445\n",
            "weighted avg     0.9091    0.8952    0.8965      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московской, Новокузнецке, .\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 9:\n",
            "Counter({'SYMPTOM': 571, 'TOPONYM': 416, 'BODY_PART': 388, 'MEDICINE': 222, 'ALLERGEN': 164})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 500\n",
            "После итерации 10 осталось 3543 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc69fd6e2ad34795a477eb026bd60db6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 500 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='567' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [567/630 05:08 < 00:34, 1.83 it/s, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.314299</td>\n",
              "      <td>0.635179</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.701439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.323984</td>\n",
              "      <td>0.644654</td>\n",
              "      <td>0.823293</td>\n",
              "      <td>0.723104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.306723</td>\n",
              "      <td>0.657512</td>\n",
              "      <td>0.817269</td>\n",
              "      <td>0.728738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.315237</td>\n",
              "      <td>0.647335</td>\n",
              "      <td>0.829317</td>\n",
              "      <td>0.727113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.286546</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.815261</td>\n",
              "      <td>0.738182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.291112</td>\n",
              "      <td>0.669903</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.741935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.287452</td>\n",
              "      <td>0.673139</td>\n",
              "      <td>0.835341</td>\n",
              "      <td>0.745520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.568600</td>\n",
              "      <td>0.292005</td>\n",
              "      <td>0.669342</td>\n",
              "      <td>0.837349</td>\n",
              "      <td>0.743979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.568600</td>\n",
              "      <td>0.286882</td>\n",
              "      <td>0.672581</td>\n",
              "      <td>0.837349</td>\n",
              "      <td>0.745975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.7460\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7746    0.7971    0.7857        69\n",
            " B-BODY_PART     0.8000    0.8831    0.8395        77\n",
            "  B-MEDICINE     0.7193    0.8039    0.7593        51\n",
            "   B-SYMPTOM     0.6316    0.8317    0.7179       101\n",
            "   B-TOPONYM     0.7579    0.9745    0.8527       196\n",
            "  I-ALLERGEN     0.9180    0.7000    0.7943        80\n",
            " I-BODY_PART     1.0000    0.1176    0.2105        17\n",
            "  I-MEDICINE     0.7474    0.8452    0.7933        84\n",
            "   I-SYMPTOM     0.6108    0.8361    0.7059       122\n",
            "   I-TOPONYM     0.8810    0.8409    0.8605        44\n",
            "           O     0.9726    0.9263    0.9489      2604\n",
            "\n",
            "    accuracy                         0.9054      3445\n",
            "   macro avg     0.8012    0.7779    0.7517      3445\n",
            "weighted avg     0.9182    0.9054    0.9073      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 10:\n",
            "Counter({'SYMPTOM': 627, 'TOPONYM': 465, 'BODY_PART': 422, 'MEDICINE': 245, 'ALLERGEN': 189})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 550\n",
            "После итерации 11 осталось 3493 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c255f175fee4e348bef52f0c349672b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/550 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 550 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='276' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [276/690 02:29 < 03:45, 1.84 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275882</td>\n",
              "      <td>0.676898</td>\n",
              "      <td>0.841365</td>\n",
              "      <td>0.750224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.260196</td>\n",
              "      <td>0.698145</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.758937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.263141</td>\n",
              "      <td>0.675896</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.746403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.264877</td>\n",
              "      <td>0.679092</td>\n",
              "      <td>0.841365</td>\n",
              "      <td>0.751570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.7589\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7794    0.7681    0.7737        69\n",
            " B-BODY_PART     0.8118    0.8961    0.8519        77\n",
            "  B-MEDICINE     0.7193    0.8039    0.7593        51\n",
            "   B-SYMPTOM     0.6975    0.8218    0.7545       101\n",
            "   B-TOPONYM     0.7610    0.9745    0.8546       196\n",
            "  I-ALLERGEN     0.9322    0.6875    0.7914        80\n",
            " I-BODY_PART     1.0000    0.1176    0.2105        17\n",
            "  I-MEDICINE     0.7473    0.8095    0.7771        84\n",
            "   I-SYMPTOM     0.6711    0.8197    0.7380       122\n",
            "   I-TOPONYM     0.9000    0.8182    0.8571        44\n",
            "           O     0.9679    0.9382    0.9528      2604\n",
            "\n",
            "    accuracy                         0.9118      3445\n",
            "   macro avg     0.8170    0.7686    0.7565      3445\n",
            "weighted avg     0.9198    0.9118    0.9122      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 11:\n",
            "Counter({'SYMPTOM': 685, 'TOPONYM': 514, 'BODY_PART': 457, 'MEDICINE': 274, 'ALLERGEN': 207})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 600\n",
            "После итерации 12 осталось 3443 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7877df69b9844b1da4712e7c51f1d0e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 600 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 06:44, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.262303</td>\n",
              "      <td>0.675896</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.746403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.265472</td>\n",
              "      <td>0.669887</td>\n",
              "      <td>0.835341</td>\n",
              "      <td>0.743521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.248131</td>\n",
              "      <td>0.697171</td>\n",
              "      <td>0.841365</td>\n",
              "      <td>0.762511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.258475</td>\n",
              "      <td>0.684976</td>\n",
              "      <td>0.851406</td>\n",
              "      <td>0.759176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.239446</td>\n",
              "      <td>0.712585</td>\n",
              "      <td>0.841365</td>\n",
              "      <td>0.771639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.240971</td>\n",
              "      <td>0.710660</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.771350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.241466</td>\n",
              "      <td>0.715017</td>\n",
              "      <td>0.841365</td>\n",
              "      <td>0.773063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.239296</td>\n",
              "      <td>0.716469</td>\n",
              "      <td>0.847390</td>\n",
              "      <td>0.776449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.239785</td>\n",
              "      <td>0.717206</td>\n",
              "      <td>0.845382</td>\n",
              "      <td>0.776037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.238852</td>\n",
              "      <td>0.721368</td>\n",
              "      <td>0.847390</td>\n",
              "      <td>0.779317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.7793\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7639    0.7971    0.7801        69\n",
            " B-BODY_PART     0.8734    0.8961    0.8846        77\n",
            "  B-MEDICINE     0.7368    0.8235    0.7778        51\n",
            "   B-SYMPTOM     0.6967    0.8416    0.7623       101\n",
            "   B-TOPONYM     0.7917    0.9694    0.8716       196\n",
            "  I-ALLERGEN     0.9254    0.7750    0.8435        80\n",
            " I-BODY_PART     1.0000    0.4706    0.6400        17\n",
            "  I-MEDICINE     0.7582    0.8214    0.7886        84\n",
            "   I-SYMPTOM     0.6755    0.8361    0.7473       122\n",
            "   I-TOPONYM     0.8261    0.8636    0.8444        44\n",
            "           O     0.9717    0.9374    0.9543      2604\n",
            "\n",
            "    accuracy                         0.9176      3445\n",
            "   macro avg     0.8200    0.8211    0.8086      3445\n",
            "weighted avg     0.9251    0.9176    0.9194      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 12:\n",
            "Counter({'SYMPTOM': 777, 'TOPONYM': 561, 'BODY_PART': 521, 'MEDICINE': 304, 'ALLERGEN': 232})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 650\n",
            "После итерации 13 осталось 3393 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7d4b586c05d4ca38e43db9e773cc7a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/650 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 650 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='656' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [656/820 05:48 < 01:27, 1.88 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.245201</td>\n",
              "      <td>0.699507</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.769648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.237728</td>\n",
              "      <td>0.723051</td>\n",
              "      <td>0.875502</td>\n",
              "      <td>0.792007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.221499</td>\n",
              "      <td>0.740035</td>\n",
              "      <td>0.857430</td>\n",
              "      <td>0.794419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.227091</td>\n",
              "      <td>0.739353</td>\n",
              "      <td>0.871486</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.224230</td>\n",
              "      <td>0.738908</td>\n",
              "      <td>0.869478</td>\n",
              "      <td>0.798893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.217384</td>\n",
              "      <td>0.753472</td>\n",
              "      <td>0.871486</td>\n",
              "      <td>0.808194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.451300</td>\n",
              "      <td>0.217089</td>\n",
              "      <td>0.746967</td>\n",
              "      <td>0.865462</td>\n",
              "      <td>0.801860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.451300</td>\n",
              "      <td>0.215259</td>\n",
              "      <td>0.754355</td>\n",
              "      <td>0.869478</td>\n",
              "      <td>0.807836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8082\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7733    0.8406    0.8056        69\n",
            " B-BODY_PART     0.9091    0.9091    0.9091        77\n",
            "  B-MEDICINE     0.7500    0.8824    0.8108        51\n",
            "   B-SYMPTOM     0.7265    0.8416    0.7798       101\n",
            "   B-TOPONYM     0.8341    0.9745    0.8988       196\n",
            "  I-ALLERGEN     0.8889    0.8000    0.8421        80\n",
            " I-BODY_PART     1.0000    0.6471    0.7857        17\n",
            "  I-MEDICINE     0.7604    0.8690    0.8111        84\n",
            "   I-SYMPTOM     0.7203    0.8443    0.7774       122\n",
            "   I-TOPONYM     0.8298    0.8864    0.8571        44\n",
            "           O     0.9766    0.9443    0.9602      2604\n",
            "\n",
            "    accuracy                         0.9283      3445\n",
            "   macro avg     0.8335    0.8581    0.8398      3445\n",
            "weighted avg     0.9341    0.9283    0.9299      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цветение, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 13:\n",
            "Counter({'SYMPTOM': 859, 'TOPONYM': 610, 'BODY_PART': 579, 'MEDICINE': 349, 'ALLERGEN': 262})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 700\n",
            "После итерации 14 осталось 3343 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9fcf6d3b58c4179bd825016ef760455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 700 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='880' max='880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [880/880 07:49, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.208885</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.857430</td>\n",
              "      <td>0.807183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.202005</td>\n",
              "      <td>0.775583</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.818957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.201407</td>\n",
              "      <td>0.775401</td>\n",
              "      <td>0.873494</td>\n",
              "      <td>0.821530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.201964</td>\n",
              "      <td>0.775583</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.818957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.204661</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.883534</td>\n",
              "      <td>0.825516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.193576</td>\n",
              "      <td>0.793419</td>\n",
              "      <td>0.871486</td>\n",
              "      <td>0.830622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.196010</td>\n",
              "      <td>0.787004</td>\n",
              "      <td>0.875502</td>\n",
              "      <td>0.828897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.191897</td>\n",
              "      <td>0.797814</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.836676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.192033</td>\n",
              "      <td>0.794545</td>\n",
              "      <td>0.877510</td>\n",
              "      <td>0.833969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.420800</td>\n",
              "      <td>0.193803</td>\n",
              "      <td>0.795290</td>\n",
              "      <td>0.881526</td>\n",
              "      <td>0.836190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8367\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7973    0.8551    0.8252        69\n",
            " B-BODY_PART     0.9351    0.9351    0.9351        77\n",
            "  B-MEDICINE     0.7627    0.8824    0.8182        51\n",
            "   B-SYMPTOM     0.7890    0.8515    0.8190       101\n",
            "   B-TOPONYM     0.8925    0.9745    0.9317       196\n",
            "  I-ALLERGEN     0.9420    0.8125    0.8725        80\n",
            " I-BODY_PART     1.0000    0.7647    0.8667        17\n",
            "  I-MEDICINE     0.7582    0.8214    0.7886        84\n",
            "   I-SYMPTOM     0.7574    0.8443    0.7984       122\n",
            "   I-TOPONYM     0.8667    0.8864    0.8764        44\n",
            "           O     0.9746    0.9574    0.9659      2604\n",
            "\n",
            "    accuracy                         0.9390      3445\n",
            "   macro avg     0.8614    0.8714    0.8634      3445\n",
            "weighted avg     0.9419    0.9390    0.9399      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_700\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 14:\n",
            "Counter({'SYMPTOM': 928, 'TOPONYM': 650, 'BODY_PART': 626, 'MEDICINE': 367, 'ALLERGEN': 285})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 750\n",
            "После итерации 15 осталось 3293 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "958a1af987c042f99903938a0cce10bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 750 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='470' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [470/940 04:11 < 04:12, 1.86 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.187157</td>\n",
              "      <td>0.800738</td>\n",
              "      <td>0.871486</td>\n",
              "      <td>0.834615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.197693</td>\n",
              "      <td>0.778369</td>\n",
              "      <td>0.881526</td>\n",
              "      <td>0.826742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.187399</td>\n",
              "      <td>0.797834</td>\n",
              "      <td>0.887550</td>\n",
              "      <td>0.840304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.186295</td>\n",
              "      <td>0.797468</td>\n",
              "      <td>0.885542</td>\n",
              "      <td>0.839201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.184871</td>\n",
              "      <td>0.788909</td>\n",
              "      <td>0.885542</td>\n",
              "      <td>0.834437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8403\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7805    0.9275    0.8477        69\n",
            " B-BODY_PART     0.9474    0.9351    0.9412        77\n",
            "  B-MEDICINE     0.8182    0.8824    0.8491        51\n",
            "   B-SYMPTOM     0.7890    0.8515    0.8190       101\n",
            "   B-TOPONYM     0.8967    0.9745    0.9340       196\n",
            "  I-ALLERGEN     0.9315    0.8500    0.8889        80\n",
            " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
            "  I-MEDICINE     0.7640    0.8095    0.7861        84\n",
            "   I-SYMPTOM     0.7647    0.8525    0.8062       122\n",
            "   I-TOPONYM     0.8298    0.8864    0.8571        44\n",
            "           O     0.9769    0.9570    0.9668      2604\n",
            "\n",
            "    accuracy                         0.9414      3445\n",
            "   macro avg     0.8635    0.8863    0.8727      3445\n",
            "weighted avg     0.9443    0.9414    0.9423      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 15:\n",
            "Counter({'SYMPTOM': 1000, 'TOPONYM': 706, 'BODY_PART': 684, 'MEDICINE': 391, 'ALLERGEN': 323})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 800\n",
            "После итерации 16 осталось 3243 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b7007a54fa5453bbe1a9c4e84b5fe66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 800 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 300/1000 02:37 < 06:10, 1.89 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.182070</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.847328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.180801</td>\n",
              "      <td>0.801085</td>\n",
              "      <td>0.889558</td>\n",
              "      <td>0.843007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.176098</td>\n",
              "      <td>0.798903</td>\n",
              "      <td>0.877510</td>\n",
              "      <td>0.836364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8473\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7805    0.9275    0.8477        69\n",
            " B-BODY_PART     0.9474    0.9351    0.9412        77\n",
            "  B-MEDICINE     0.7895    0.8824    0.8333        51\n",
            "   B-SYMPTOM     0.8269    0.8515    0.8390       101\n",
            "   B-TOPONYM     0.9052    0.9745    0.9386       196\n",
            "  I-ALLERGEN     0.9324    0.8625    0.8961        80\n",
            " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
            "  I-MEDICINE     0.7474    0.8452    0.7933        84\n",
            "   I-SYMPTOM     0.7879    0.8525    0.8189       122\n",
            "   I-TOPONYM     0.8478    0.8864    0.8667        44\n",
            "           O     0.9781    0.9593    0.9686      2604\n",
            "\n",
            "    accuracy                         0.9443      3445\n",
            "   macro avg     0.8675    0.8909    0.8770      3445\n",
            "weighted avg     0.9471    0.9443    0.9452      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 16:\n",
            "Counter({'SYMPTOM': 1095, 'TOPONYM': 758, 'BODY_PART': 748, 'MEDICINE': 438, 'ALLERGEN': 352})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 850\n",
            "После итерации 17 осталось 3193 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bbeab8b5db144c3b324f2e631f01dc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 850 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='535' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 535/1070 04:39 < 04:40, 1.91 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.189465</td>\n",
              "      <td>0.790780</td>\n",
              "      <td>0.895582</td>\n",
              "      <td>0.839925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.183422</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.885542</td>\n",
              "      <td>0.833648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.171336</td>\n",
              "      <td>0.813309</td>\n",
              "      <td>0.883534</td>\n",
              "      <td>0.846968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.177640</td>\n",
              "      <td>0.801085</td>\n",
              "      <td>0.889558</td>\n",
              "      <td>0.843007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.178618</td>\n",
              "      <td>0.798214</td>\n",
              "      <td>0.897590</td>\n",
              "      <td>0.844991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8470\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8205    0.9275    0.8707        69\n",
            " B-BODY_PART     0.9600    0.9351    0.9474        77\n",
            "  B-MEDICINE     0.8333    0.8824    0.8571        51\n",
            "   B-SYMPTOM     0.8269    0.8515    0.8390       101\n",
            "   B-TOPONYM     0.9048    0.9694    0.9360       196\n",
            "  I-ALLERGEN     0.9437    0.8375    0.8874        80\n",
            " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
            "  I-MEDICINE     0.7882    0.7976    0.7929        84\n",
            "   I-SYMPTOM     0.8062    0.8525    0.8287       122\n",
            "   I-TOPONYM     0.8478    0.8864    0.8667        44\n",
            "           O     0.9760    0.9666    0.9713      2604\n",
            "\n",
            "    accuracy                         0.9478      3445\n",
            "   macro avg     0.8825    0.8845    0.8819      3445\n",
            "weighted avg     0.9491    0.9478    0.9481      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 17:\n",
            "Counter({'SYMPTOM': 1190, 'TOPONYM': 811, 'BODY_PART': 809, 'MEDICINE': 476, 'ALLERGEN': 376})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 900\n",
            "После итерации 18 осталось 3143 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73ced4c5fe094a10a84bfd9cbf5dd4db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 900 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='678' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 678/1130 05:54 < 03:56, 1.91 it/s, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.175860</td>\n",
              "      <td>0.799277</td>\n",
              "      <td>0.887550</td>\n",
              "      <td>0.841104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.174841</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.843305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.175908</td>\n",
              "      <td>0.803220</td>\n",
              "      <td>0.901606</td>\n",
              "      <td>0.849574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.171896</td>\n",
              "      <td>0.808244</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.854167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.351300</td>\n",
              "      <td>0.170424</td>\n",
              "      <td>0.802867</td>\n",
              "      <td>0.899598</td>\n",
              "      <td>0.848485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.351300</td>\n",
              "      <td>0.170166</td>\n",
              "      <td>0.807899</td>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.853081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8542\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.7976    0.9710    0.8758        69\n",
            " B-BODY_PART     0.9600    0.9351    0.9474        77\n",
            "  B-MEDICINE     0.8036    0.8824    0.8411        51\n",
            "   B-SYMPTOM     0.8148    0.8713    0.8421       101\n",
            "   B-TOPONYM     0.9014    0.9796    0.9389       196\n",
            "  I-ALLERGEN     0.9200    0.8625    0.8903        80\n",
            " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
            "  I-MEDICINE     0.7826    0.8571    0.8182        84\n",
            "   I-SYMPTOM     0.7761    0.8525    0.8125       122\n",
            "   I-TOPONYM     0.8864    0.8864    0.8864        44\n",
            "           O     0.9808    0.9604    0.9705      2604\n",
            "\n",
            "    accuracy                         0.9472      3445\n",
            "   macro avg     0.8748    0.8983    0.8842      3445\n",
            "weighted avg     0.9500    0.9472    0.9480      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 18:\n",
            "Counter({'SYMPTOM': 1266, 'TOPONYM': 854, 'BODY_PART': 841, 'MEDICINE': 511, 'ALLERGEN': 403})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 950\n",
            "После итерации 19 осталось 3093 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51df127576174a228c6608d9736547ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/950 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 950 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='833' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 833/1190 07:18 < 03:08, 1.89 it/s, Epoch 7/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.169344</td>\n",
              "      <td>0.808318</td>\n",
              "      <td>0.897590</td>\n",
              "      <td>0.850618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.181625</td>\n",
              "      <td>0.780702</td>\n",
              "      <td>0.893574</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.166653</td>\n",
              "      <td>0.820183</td>\n",
              "      <td>0.897590</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.165112</td>\n",
              "      <td>0.816029</td>\n",
              "      <td>0.899598</td>\n",
              "      <td>0.855778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.334200</td>\n",
              "      <td>0.161152</td>\n",
              "      <td>0.829358</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.866731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.334200</td>\n",
              "      <td>0.159658</td>\n",
              "      <td>0.832103</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.867308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.334200</td>\n",
              "      <td>0.162118</td>\n",
              "      <td>0.822993</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.862333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8673\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8000    0.9855    0.8831        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8519    0.9020    0.8762        51\n",
            "   B-SYMPTOM     0.8165    0.8812    0.8476       101\n",
            "   B-TOPONYM     0.9363    0.9745    0.9550       196\n",
            "  I-ALLERGEN     0.9342    0.8875    0.9103        80\n",
            " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
            "  I-MEDICINE     0.8068    0.8452    0.8256        84\n",
            "   I-SYMPTOM     0.8268    0.8607    0.8434       122\n",
            "   I-TOPONYM     0.8864    0.8864    0.8864        44\n",
            "           O     0.9809    0.9677    0.9743      2604\n",
            "\n",
            "    accuracy                         0.9536      3445\n",
            "   macro avg     0.8848    0.9033    0.8925      3445\n",
            "weighted avg     0.9553    0.9536    0.9541      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_950\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 19:\n",
            "Counter({'SYMPTOM': 1330, 'TOPONYM': 910, 'BODY_PART': 880, 'MEDICINE': 530, 'ALLERGEN': 435})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ошибка при выполнении get_project_tasks: status_code: 500, body: {'id': '40808da0-039f-4623-a6f5-cba106de417b', 'status_code': 500, 'version': '1.18.0', 'detail': 'connection already closed', 'exc_info': 'Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\views.py\", line 506, in dispatch\\n    response = handler(request, *args, **kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\utils\\\\decorators.py\", line 48, in _wrapper\\n    return bound_method(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 352, in get\\n    return self.get_paginated_response(serializer.data)\\n                                       ^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 795, in data\\n    ret = super().data\\n          ^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 249, in data\\n    self._data = self.to_representation(self.instance)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 714, in to_representation\\n    self.child.to_representation(item) for item in iterable\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\serializers.py\", line 370, in to_representation\\n    ret = super(DataManagerTaskSerializer, self).to_representation(obj)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\tasks\\\\serializers.py\", line 193, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_flex_fields\\\\serializers.py\", line 64, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 538, in to_representation\\n    ret[field.field_name] = field.to_representation(attribute)\\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\relations.py\", line 566, in to_representation\\n    for value in iterable\\n                 ^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 400, in __iter__\\n    self._fetch_all()\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 1928, in _fetch_all\\n    self._result_cache = list(self._iterable_class(self))\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 91, in __iter__\\n    results = compiler.execute_sql(\\n              ^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\sql\\\\compiler.py\", line 1574, in execute_sql\\n    cursor.execute(sql, params)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\utils.py\", line 1788, in runner\\n    return sentry_patched_function(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 652, in execute\\n    _set_db_data(span, self)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 717, in _set_db_data\\n    connection_params = cursor_or_db.connection.get_dsn_parameters()\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\npsycopg2.InterfaceError: connection already closed\\n'}. Попытка 1/5\n",
            "Найден существующий размеченный проект для размера 1000\n",
            "После итерации 20 осталось 3043 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cb7acba16214dbcb582c94757698ea2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1000 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 625/1250 05:26 < 05:27, 1.91 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.154497</td>\n",
              "      <td>0.844278</td>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.872939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.161576</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.860687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.148135</td>\n",
              "      <td>0.848771</td>\n",
              "      <td>0.901606</td>\n",
              "      <td>0.874391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.150249</td>\n",
              "      <td>0.839851</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.871498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.153374</td>\n",
              "      <td>0.832103</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.867308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8744\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8519    0.9020    0.8762        51\n",
            "   B-SYMPTOM     0.8447    0.8614    0.8529       101\n",
            "   B-TOPONYM     0.9406    0.9694    0.9548       196\n",
            "  I-ALLERGEN     0.9595    0.8875    0.9221        80\n",
            " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
            "  I-MEDICINE     0.8452    0.8452    0.8452        84\n",
            "   I-SYMPTOM     0.8667    0.8525    0.8595       122\n",
            "   I-TOPONYM     0.8696    0.9091    0.8889        44\n",
            "           O     0.9803    0.9754    0.9779      2604\n",
            "\n",
            "    accuracy                         0.9585      3445\n",
            "   macro avg     0.8982    0.9031    0.8994      3445\n",
            "weighted avg     0.9592    0.9585    0.9586      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 20:\n",
            "Counter({'SYMPTOM': 1410, 'TOPONYM': 961, 'BODY_PART': 948, 'MEDICINE': 565, 'ALLERGEN': 457})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1050\n",
            "После итерации 21 осталось 2993 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0cde6b7ca0e496ba4300f4773cd18a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1050 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1050 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1056' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1056/1320 09:09 < 02:17, 1.92 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.154154</td>\n",
              "      <td>0.832103</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.867308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.155847</td>\n",
              "      <td>0.834254</td>\n",
              "      <td>0.909639</td>\n",
              "      <td>0.870317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158449</td>\n",
              "      <td>0.831810</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.870813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.301400</td>\n",
              "      <td>0.150362</td>\n",
              "      <td>0.843284</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.874275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.301400</td>\n",
              "      <td>0.145143</td>\n",
              "      <td>0.849624</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.877670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.301400</td>\n",
              "      <td>0.145626</td>\n",
              "      <td>0.853107</td>\n",
              "      <td>0.909639</td>\n",
              "      <td>0.880466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.301400</td>\n",
              "      <td>0.149380</td>\n",
              "      <td>0.844860</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.875121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>0.146531</td>\n",
              "      <td>0.846442</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.875969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8805\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9589    0.9091    0.9333        77\n",
            "  B-MEDICINE     0.8519    0.9020    0.8762        51\n",
            "   B-SYMPTOM     0.8411    0.8911    0.8654       101\n",
            "   B-TOPONYM     0.9598    0.9745    0.9671       196\n",
            "  I-ALLERGEN     0.9351    0.9000    0.9172        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8690    0.8690    0.8690        84\n",
            "   I-SYMPTOM     0.8400    0.8607    0.8502       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9833    0.9750    0.9792      2604\n",
            "\n",
            "    accuracy                         0.9605      3445\n",
            "   macro avg     0.8950    0.9104    0.9016      3445\n",
            "weighted avg     0.9616    0.9605    0.9608      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 21:\n",
            "Counter({'SYMPTOM': 1555, 'BODY_PART': 1027, 'TOPONYM': 1013, 'MEDICINE': 598, 'ALLERGEN': 474})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1100\n",
            "После итерации 22 осталось 2943 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1587d9d0f324d4d88e770bb08ea5698",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1100 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='552' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 552/1380 04:48 < 07:14, 1.91 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.144363</td>\n",
              "      <td>0.859048</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.881720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.141806</td>\n",
              "      <td>0.857955</td>\n",
              "      <td>0.909639</td>\n",
              "      <td>0.883041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.148389</td>\n",
              "      <td>0.840149</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.872587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.273800</td>\n",
              "      <td>0.152391</td>\n",
              "      <td>0.844732</td>\n",
              "      <td>0.917671</td>\n",
              "      <td>0.879692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8830\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8415    1.0000    0.9139        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
            "   B-SYMPTOM     0.8447    0.8614    0.8529       101\n",
            "   B-TOPONYM     0.9550    0.9745    0.9646       196\n",
            "  I-ALLERGEN     0.9600    0.9000    0.9290        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8916    0.8810    0.8862        84\n",
            "   I-SYMPTOM     0.8537    0.8607    0.8571       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9838    0.9785    0.9811      2604\n",
            "\n",
            "    accuracy                         0.9631      3445\n",
            "   macro avg     0.9026    0.9120    0.9063      3445\n",
            "weighted avg     0.9639    0.9631    0.9633      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 22:\n",
            "Counter({'SYMPTOM': 1634, 'BODY_PART': 1099, 'TOPONYM': 1071, 'MEDICINE': 615, 'ALLERGEN': 482})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1150\n",
            "После итерации 23 осталось 2893 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aa2970bd6d044629cd96d137dd02167",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1150 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='720' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 720/1440 06:13 < 06:14, 1.92 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.141548</td>\n",
              "      <td>0.853383</td>\n",
              "      <td>0.911647</td>\n",
              "      <td>0.881553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.143283</td>\n",
              "      <td>0.845725</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.878378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.137953</td>\n",
              "      <td>0.856874</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.884354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.270500</td>\n",
              "      <td>0.137779</td>\n",
              "      <td>0.856061</td>\n",
              "      <td>0.907631</td>\n",
              "      <td>0.881092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.270500</td>\n",
              "      <td>0.145559</td>\n",
              "      <td>0.845438</td>\n",
              "      <td>0.911647</td>\n",
              "      <td>0.877295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8844\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8313    1.0000    0.9079        69\n",
            " B-BODY_PART     0.9600    0.9351    0.9474        77\n",
            "  B-MEDICINE     0.8393    0.9216    0.8785        51\n",
            "   B-SYMPTOM     0.8411    0.8911    0.8654       101\n",
            "   B-TOPONYM     0.9550    0.9745    0.9646       196\n",
            "  I-ALLERGEN     0.9351    0.9000    0.9172        80\n",
            " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
            "  I-MEDICINE     0.9024    0.8810    0.8916        84\n",
            "   I-SYMPTOM     0.8548    0.8689    0.8618       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9857    0.9773    0.9815      2604\n",
            "\n",
            "    accuracy                         0.9637      3445\n",
            "   macro avg     0.9043    0.9165    0.9091      3445\n",
            "weighted avg     0.9648    0.9637    0.9640      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 23:\n",
            "Counter({'SYMPTOM': 1718, 'BODY_PART': 1158, 'TOPONYM': 1128, 'MEDICINE': 641, 'ALLERGEN': 497})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1200\n",
            "После итерации 24 осталось 2843 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51c2c2d4a375459d841643eca087bf13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1200 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 600/1500 05:10 < 07:47, 1.93 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.140173</td>\n",
              "      <td>0.858491</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.885214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.137342</td>\n",
              "      <td>0.863118</td>\n",
              "      <td>0.911647</td>\n",
              "      <td>0.886719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.137285</td>\n",
              "      <td>0.850746</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.882012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.259400</td>\n",
              "      <td>0.134271</td>\n",
              "      <td>0.858223</td>\n",
              "      <td>0.911647</td>\n",
              "      <td>0.884129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8867\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9589    0.9091    0.9333        77\n",
            "  B-MEDICINE     0.8704    0.9216    0.8952        51\n",
            "   B-SYMPTOM     0.8462    0.8713    0.8585       101\n",
            "   B-TOPONYM     0.9695    0.9745    0.9720       196\n",
            "  I-ALLERGEN     0.9351    0.9000    0.9172        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.9036    0.8929    0.8982        84\n",
            "   I-SYMPTOM     0.8480    0.8689    0.8583       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9849    0.9789    0.9819      2604\n",
            "\n",
            "    accuracy                         0.9640      3445\n",
            "   macro avg     0.9020    0.9136    0.9068      3445\n",
            "weighted avg     0.9649    0.9640    0.9642      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 24:\n",
            "Counter({'SYMPTOM': 1790, 'BODY_PART': 1220, 'TOPONYM': 1181, 'MEDICINE': 663, 'ALLERGEN': 507})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1250\n",
            "После итерации 25 осталось 2793 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "961cd81f23574200982195e954fb803e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1250 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='471' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 471/1570 04:02 < 09:29, 1.93 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.141972</td>\n",
              "      <td>0.853933</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.883721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.134423</td>\n",
              "      <td>0.856874</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.884354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.144206</td>\n",
              "      <td>0.851577</td>\n",
              "      <td>0.921687</td>\n",
              "      <td>0.885246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8852\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9600    0.9351    0.9474        77\n",
            "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
            "   B-SYMPTOM     0.8198    0.9010    0.8585       101\n",
            "   B-TOPONYM     0.9552    0.9796    0.9673       196\n",
            "  I-ALLERGEN     0.9351    0.9000    0.9172        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8750    0.9167    0.8953        84\n",
            "   I-SYMPTOM     0.8217    0.8689    0.8446       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9875    0.9727    0.9801      2604\n",
            "\n",
            "    accuracy                         0.9617      3445\n",
            "   macro avg     0.8922    0.9207    0.9052      3445\n",
            "weighted avg     0.9635    0.9617    0.9622      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 25:\n",
            "Counter({'SYMPTOM': 1883, 'BODY_PART': 1279, 'TOPONYM': 1231, 'MEDICINE': 682, 'ALLERGEN': 537})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1300\n",
            "После итерации 26 осталось 2743 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b5644da55e346e88c6e8aee3b3cd8f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1300 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='489' max='1630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 489/1630 04:12 < 09:50, 1.93 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.133780</td>\n",
              "      <td>0.863378</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.887805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.134549</td>\n",
              "      <td>0.860377</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.887160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.134592</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.885437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8878\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8415    1.0000    0.9139        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8704    0.9216    0.8952        51\n",
            "   B-SYMPTOM     0.8627    0.8713    0.8670       101\n",
            "   B-TOPONYM     0.9598    0.9745    0.9671       196\n",
            "  I-ALLERGEN     0.9600    0.9000    0.9290        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8929    0.8929    0.8929        84\n",
            "   I-SYMPTOM     0.8618    0.8689    0.8653       122\n",
            "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
            "           O     0.9850    0.9804    0.9827      2604\n",
            "\n",
            "    accuracy                         0.9655      3445\n",
            "   macro avg     0.9070    0.9149    0.9101      3445\n",
            "weighted avg     0.9661    0.9655    0.9656      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 26:\n",
            "Counter({'SYMPTOM': 1965, 'BODY_PART': 1340, 'TOPONYM': 1295, 'MEDICINE': 718, 'ALLERGEN': 553})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1350\n",
            "После итерации 27 осталось 2693 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90796c4afe734738b635ccad8bb3701e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1350 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='507' max='1690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 507/1690 04:24 < 10:18, 1.91 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.135386</td>\n",
              "      <td>0.860113</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.886076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.133331</td>\n",
              "      <td>0.858223</td>\n",
              "      <td>0.911647</td>\n",
              "      <td>0.884129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.240500</td>\n",
              "      <td>0.131228</td>\n",
              "      <td>0.857411</td>\n",
              "      <td>0.917671</td>\n",
              "      <td>0.886518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8865\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8704    0.9216    0.8952        51\n",
            "   B-SYMPTOM     0.8476    0.8812    0.8641       101\n",
            "   B-TOPONYM     0.9600    0.9796    0.9697       196\n",
            "  I-ALLERGEN     0.9474    0.9000    0.9231        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8851    0.9167    0.9006        84\n",
            "   I-SYMPTOM     0.8346    0.8689    0.8514       122\n",
            "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
            "           O     0.9868    0.9766    0.9817      2604\n",
            "\n",
            "    accuracy                         0.9640      3445\n",
            "   macro avg     0.8999    0.9202    0.9089      3445\n",
            "weighted avg     0.9652    0.9640    0.9644      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 27:\n",
            "Counter({'SYMPTOM': 2081, 'BODY_PART': 1424, 'TOPONYM': 1359, 'MEDICINE': 758, 'ALLERGEN': 587})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1400\n",
            "После итерации 28 осталось 2643 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ec8ad785441485eaf358ae3c61ac33d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1400 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='700' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 700/1750 06:11 < 09:18, 1.88 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.135833</td>\n",
              "      <td>0.855805</td>\n",
              "      <td>0.917671</td>\n",
              "      <td>0.885659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.133965</td>\n",
              "      <td>0.862524</td>\n",
              "      <td>0.919679</td>\n",
              "      <td>0.890185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>0.129446</td>\n",
              "      <td>0.865019</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.888672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>0.130726</td>\n",
              "      <td>0.860640</td>\n",
              "      <td>0.917671</td>\n",
              "      <td>0.888241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8902\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8704    0.9216    0.8952        51\n",
            "   B-SYMPTOM     0.8476    0.8812    0.8641       101\n",
            "   B-TOPONYM     0.9648    0.9796    0.9722       196\n",
            "  I-ALLERGEN     0.9474    0.9000    0.9231        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8851    0.9167    0.9006        84\n",
            "   I-SYMPTOM     0.8346    0.8689    0.8514       122\n",
            "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
            "           O     0.9864    0.9766    0.9815      2604\n",
            "\n",
            "    accuracy                         0.9640      3445\n",
            "   macro avg     0.9003    0.9202    0.9091      3445\n",
            "weighted avg     0.9652    0.9640    0.9644      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 28:\n",
            "Counter({'SYMPTOM': 2184, 'BODY_PART': 1483, 'TOPONYM': 1414, 'MEDICINE': 772, 'ALLERGEN': 616})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1450\n",
            "После итерации 29 осталось 2593 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "178ceca309fb4f329a4a4821c8ebcd2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1450 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1450 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1092' max='1820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1092/1820 09:21 < 06:15, 1.94 it/s, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.136329</td>\n",
              "      <td>0.857678</td>\n",
              "      <td>0.919679</td>\n",
              "      <td>0.887597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.130521</td>\n",
              "      <td>0.864151</td>\n",
              "      <td>0.919679</td>\n",
              "      <td>0.891051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.127071</td>\n",
              "      <td>0.874525</td>\n",
              "      <td>0.923695</td>\n",
              "      <td>0.898438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.124798</td>\n",
              "      <td>0.877863</td>\n",
              "      <td>0.923695</td>\n",
              "      <td>0.900196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.131191</td>\n",
              "      <td>0.864662</td>\n",
              "      <td>0.923695</td>\n",
              "      <td>0.893204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.213700</td>\n",
              "      <td>0.132433</td>\n",
              "      <td>0.870056</td>\n",
              "      <td>0.927711</td>\n",
              "      <td>0.897959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.9002\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8395    0.9855    0.9067        69\n",
            " B-BODY_PART     0.9595    0.9221    0.9404        77\n",
            "  B-MEDICINE     0.8679    0.9020    0.8846        51\n",
            "   B-SYMPTOM     0.8641    0.8812    0.8725       101\n",
            "   B-TOPONYM     0.9796    0.9796    0.9796       196\n",
            "  I-ALLERGEN     0.9600    0.9000    0.9290        80\n",
            " I-BODY_PART     0.8750    0.8235    0.8485        17\n",
            "  I-MEDICINE     0.8966    0.9286    0.9123        84\n",
            "   I-SYMPTOM     0.8571    0.8852    0.8710       122\n",
            "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
            "           O     0.9876    0.9816    0.9846      2604\n",
            "\n",
            "    accuracy                         0.9684      3445\n",
            "   macro avg     0.9091    0.9222    0.9148      3445\n",
            "weighted avg     0.9692    0.9684    0.9686      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 29:\n",
            "Counter({'SYMPTOM': 2254, 'BODY_PART': 1527, 'TOPONYM': 1479, 'MEDICINE': 788, 'ALLERGEN': 633})\n",
            "\n",
            "[NER] Начинаем итерацию с размером выборки 1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Найден существующий размеченный проект для размера 1500\n",
            "После итерации 30 осталось 2543 сообщений\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebf39451fd1f446bb9e23624f4bcde60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Обучение на 1500 примерах\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='564' max='1880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 564/1880 04:53 < 11:27, 1.91 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.139861</td>\n",
              "      <td>0.857944</td>\n",
              "      <td>0.921687</td>\n",
              "      <td>0.888674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.145402</td>\n",
              "      <td>0.845725</td>\n",
              "      <td>0.913655</td>\n",
              "      <td>0.878378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.140696</td>\n",
              "      <td>0.855787</td>\n",
              "      <td>0.905622</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Результаты: F1 = 0.8887\n",
            "\n",
            "[NER] Подробный отчет о классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  B-ALLERGEN     0.8214    1.0000    0.9020        69\n",
            " B-BODY_PART     0.9605    0.9481    0.9542        77\n",
            "  B-MEDICINE     0.8704    0.9216    0.8952        51\n",
            "   B-SYMPTOM     0.7759    0.8911    0.8295       101\n",
            "   B-TOPONYM     0.9746    0.9796    0.9771       196\n",
            "  I-ALLERGEN     0.9600    0.9000    0.9290        80\n",
            " I-BODY_PART     1.0000    0.6471    0.7857        17\n",
            "  I-MEDICINE     0.9059    0.9167    0.9112        84\n",
            "   I-SYMPTOM     0.8231    0.8770    0.8492       122\n",
            "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
            "           O     0.9868    0.9747    0.9807      2604\n",
            "\n",
            "    accuracy                         0.9628      3445\n",
            "   macro avg     0.9082    0.9080    0.9032      3445\n",
            "weighted avg     0.9650    0.9628    0.9633      3445\n",
            "\n",
            "[NER] Модель сохранена в models/pollen_ner_1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
            "\n",
            "[NER] Тестирование модели после обучения:\n",
            "\n",
            "Тестовый пример:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "[NER] Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: потекли, чешутся, течет, слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n",
            "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
            "Модель перемещена на cuda\n",
            "\n",
            "Статистика распределения классов в тренировочном датасете после итерации 30:\n",
            "Counter({'SYMPTOM': 2323, 'BODY_PART': 1587, 'TOPONYM': 1534, 'MEDICINE': 831, 'ALLERGEN': 645})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJNCAYAAAAs3xZxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAd4JJREFUeJzt3Qd8U+X+x/Ff0l3aQpmyNzJko8hQceEWxHFVVNx73Ov9XxW8Kk4EvV7nFRwoKi7ce4EbXCAIKsjem5aW7oz/6/eUE9ISumh6kpPP+/UKSU7GeZInKfmeZ7n8fr9fAAAAAABArXPX/lMCAAAAAABF6AYAAAAAIEwI3QAAAAAAhAmhGwAAAACAMCF0AwAAAAAQJoRuAAAAAADChNANAAAAAECYELoBAAAAAAgTQjcAAAAAAGESH64nBgBEjm+//VYmT54sS5cuFZfLJd27d5e///3v0rt3b7uLBhE5//zz5aefftrn7W+88Yb07NmzzLZNmzbJySefLE888YQMHDiwDkoJuxQXF8vzzz8vH3zwgaxZs0YKCgrM9uTkZHnzzTelU6dOdhcRAFABQjcAONxXX30lV155pQwbNkwmTZpktr344osyevRo80N+wIABdhcRIuZAyB133BHyto4dO5a5vnHjRrnkkkskNze3jkoHO+kBsrVr18qFF14orVq1MmE7Pj5e2rRpI+np6XYXDwBQCUI3ADjcf/7zH9Oi/eSTT5pWbjV48GA5+uij5aWXXiJ0R4i0tDTp06dPhffx+XzyzjvvyMSJE+usXLDXH3/8IXPmzJGZM2dKw4YN7S4OAKAGGNMNAA5WWFgoLVu2lDPPPDMQuFViYqJpISspKSlzXw3ow4cPl4MOOkj69esnF110kfz555+B+9xyyy1y4IEHBk4aEs8++2z5/fffy3SV1lMwfV69/1tvvRXYtmLFCrn22mvlkEMOkYMPPliuuOIKWb58ublt3bp1e92/qKjIHCjQ7cH70utazmBer1eGDBmy13OsWrVKrr/+enObll0fP3fu3DKP3bVrl9x9991y2GGHmfucfvrpprdA8P5CnX788UezL72s5Q+HJUuWmNbwkSNHBnotVIW+d9oN/fjjjzfd1LWOn3rqKRPi1b5eU/B7XZ7epgdtbr75Zunbt685kHPvvfeafQXXg+5Hu8H36tUr8Hn54YcfypRt/PjxMmjQINNN/v/+7/9k586dgduPOuoos69///vfZfav99HPqfXeW/766y/zWdLPr56uueYa00ps0fvqY7777jvT20PLpe/Hyy+/XOb5d+zYIXfeeacceeSRZj/6OdXnqqhurc+tddLeC0OHDjV1Zb3X1v6DyxzqOazPrQ470Neh38NRo0aZ+tP3ROtT399gH330kbmP1od+xm+//fYy7+Vjjz1mHvvll1+az4IejDvrrLPKlKV8+fT9POaYY0y9WfWhfweC3XjjjRW+JgCIdbR0A4CDaTdUHcsdPDZUf4RrWNLQe9NNNwVu08u//PKL+QGt3VZXr14tjzzyiPzzn/+UDz/8MBDamzRpIo8//rgJETquWH/8a3jWlji3e+9juToGVbuxB9u8ebP87W9/k2bNmpnAlZqaagLBmDFjzLjVUJ555pmQgadevXry888/m67WVldbDSoamoItW7bMBIx27dqZAJeQkCAvvPCC2efUqVNNqNIQc/HFFwfCeYcOHeTtt982YWvatGkm8GooV1r+M844wxzQUDqudv369VJTfr9fPB7PXtvj4uIC733z5s3l888/lwMOOKDKAUefV4cXzJ8/39RT165dzWMffvhhE0b1AMNrr71m7qsHT+666y4T1nr06FHpc+vnQ4ObPpceMNHzrVu3mnP14IMPyiuvvGI+QxrKtN7183LDDTeYAxkpKSnywAMPmNb72267TTIyMkzQ1c/Ef//73zJ1rPfX12K9F5999tleoXPlypUmHGq9aW8AfT+1h8c555wj7777rjRq1Chw33/84x/m4IW+N/rZ1f2qc8891+xHg7t+V/QgQOPGjc0BD31d+hl49tlnK3xfrrrqKjOcQ8def//99/L0009L+/btA5+V6tDPvJ60nPrZ1O+n1pN+XzZs2GAOdKj//e9/8uijj5ry62vTutX60Xp//fXXzd8Cpd8LPVCinwX9nutnX4cqzJgxQ7p167bX/rV+9KCDvqZQ9G+G/n0AAOwboRsAYshJJ51kQrA67rjjTGuYFcbz8vJMGD3xxBPNNg2hGjDvv/9+2bZtmwnbVit5cDdo/RGvwU3PNZyUd99990nnzp3LtIZrCNd9Pvfcc4Hn1TCo4WjBggUhxzBrcNEgGPw8SlsTNSR/88035vVZLX7aeh4cTPVAgZZdg7Z25VYajLQVVlsidbIyfQ7dvwZDbd1Thx56qAkw2jqrQSWYht/KuoRXlR44CBV0H3roocDratCgQbWfV1/T7NmzyzyP1ruGMA1lF1xwQeA1WK3UegChKq9LuzvrQR0dX3zEEUeYgy4TJkyQ6667ztThli1bTAAM7vmQlJRkbtcQq/vQgKsHfLRHgZo3b54JgMG0Ffzrr782dWOV6+OPPw5Zxxrk9fNl1bE+VutSD9po2LQce+yxcuutt5rL2qtBy6rBVT+DelmfR+9vDb/QVnj97lgHKCqiYdYqp+5fX8+iRYtqFLo1uOvnWw/86IEgpa3netBIDyxoLw/9DunBBT2opAdMLF26dDGt+TrZmp5bz6cHNfSAg/X51vdHeyQEH+hQeuBNewS899575jtcnh54u+eee0J+LwEAe9C9HABiiIZJ/XF93nnnmRZTnaBJaRjV1jsN3NoaqQHz1VdfNd1QlQbkYNqCqF3TNQxrwNUu7KHGm1qBLzjsKO3SraHECtxWgNX9aXgrT8OFhh/t6luetnzqdm2ttMqmraBWwLRo67fezwpjSsOi3k8DkR500HJpmNEutBYNkvpelA/cFdEwUr4VtjIaXDT4lz9pwNof+rr1dWp34mCnnnpq4PaaOuWUU8xzW/RAjnUAwRpWoD0J9ICMtohq+NMAF/yZ0hZubZ3V90s/ezp+ufxBF+3BoAeBrDrW59OwXb6O9XOr99MDCvo50JPWt3529HMY7LTTTitzXbuYayu9tpZrDww9ONO/f3/Tyqyt1Tr5oB4QKP9d2Ff96751yMb7778f6Aof6j6VsVr2rZBssQ6O6fugrdlaLj2AFExft343g+tY6yv4fvpeHX744YE6s+Tn55sQrgcbQgVupd8Lfc/0gAAAYN9o6QaAGKItX3rSYKs/trX1T1sPtYuwLiumrdLa7Vy782rLs3b7VtoaadEu1OVbZLU1vHzXcg3l+nyXXnqp+eEfLDs728zCXBUaGL744gsT1vbVjVVb6rQLs+5TQ5uWRVsYg2nwCdUSr9v09WmrvpZLW5NDdZOvDm1FVdpa2rp1a9OKqzNPV0Tf8/LLgtUGfd2ZmZmmm3ow64DH/syAruE0mNV92xpHvHDhQtNtW8/1vdAW9BYtWuz1mVLa+m2F6vItrkrH80+fPt3U86effmo+xzpUIJjWnx4E0lN55Q8KVVZ2/bxp7wA9sKSfCe16bXXRroy2oFut6EoPIlgHOSzW50EPeOmwAQ3Cobpw6+ciVHm1TpV+bq0y7+vzHVzHej34QIn12vW9C6bd2bW7vx74CUXvrz0ltJdC8IEsAMDeCN0A4GDaLVq7915++eWmJS+YtuJZ46T1B7y2Vml4nTJligmK2sKmIUfDeDCrK6vS1mEdH67dVbWbqoYHi46B1tY33bd2Ty/fcll+zLXSwKxh3Grd09ZP7b6qXaB1nO6+aMDW+2pA18ClLa7lg3P9+vX3KofSljql74GWS8NE8NhhawZp3VaVcc5K3x99n7S7traeW7ONVxa8w0Ffd1ZWlnl/goO3dqEODm81oc8bzHp/NeBqGNQDLjqWWw+WaP1pnWg3cQ3N5WlvCO0qrZ+bsWPHmgNBwQdrNHTrMAbtaq11bLX0BtP60wndyk+sp8oHTS27dgO3bN++PRBAtVVey6Pd4nW8sxV4dRhC+Yn3QtFeETp0QVuz9SCWjpPXx2qrvkUPRujnSQ8ULV682HxGcnJy9vqMWAcptHzWZWXNH6Dl1Tq23v/y3xP9fOv32VI+XFuPCx7vrjRMf/LJJ6ZLu/4dKB+sNXDr+6cTt+1PbwkAiAV0LwcAB9PQouFCu5WX7xarAVdpi6F2r9aAqAFZf0hbgdMK3MGtktoypy2yetKgrT/KtRutdnG1aEDQ8bH6wz1U66B2e9UW9uDgrY/RkKahzKITQOl9rr766gpfp5ZJx+VqSNBW8VCBTMf/avd1ayI0pUFUA6G+Fn0OLZeGIO0Wb9HXriFQD0ZUlb6n+pz6fDohl50zO2t3a+3GrO9NMKubtx58qalZs2aVua5hWj87+rnQsKkBTw+YaAu3dRDEem81kGp3cp2oTMcDt23b1tSRBlb9PP32229lnluHH2hI1S7NGnxPOOGEkK9VJ8zTVmnrM6rdunWMtw6nCKafk2D6/uj3RT//v/76qymftr5bgVs/K1YXdWsm8n3R59F964ED7caun83gGduVTqym99GZybV7vQ4jCBVedbu+p9pNPZjObq7vqd6u+9HPb/lJCPXggU62pvuw6HsbfCBNr2udlO8Zou+bjpHXcK+TqQXTGc11nLoeRAg+OAUACI2WbgBwMP1Rri3Fl112mQk/Or5Wu6tq+NTwojNw63hN/cGuLYH641pnSNaArj/qraWydHynRW+zArYGWB2nqz+8g8fh6kzWGrzKjyO2aGuezlitIVtDqY6j1tZhDVY6TtjqDqvBS1sAq9J9VVtCNRxri52GXQ0bwTTMabjQ90EPLug+tZVeewNoi7/S1kldbkmXRNLx7tpCqLNe6+vRVtaq0uWdtPVQ3x8dK6shpXz34rqi43V1XK5OkqchV4cNaLjTiek0EGogrin9HGhoHjFihGmt1Rm1dTIvfd+0S7bWmzXRmp40lFvdlXVCL+3qrM+hB260R4Y+RutCJ1srPwbaqmMNghpWtUdE+dni9eCMzl6unymdEE2fRyc+04CtM3sH00n89HadW0DnANDvhI5BV7qMmNIWah0aoN23tbVXX6P1fajoM6kTrunr0oMd1iR85UOtHhzQ/ev7oAe9dNy4NZlcMP1e6WvR8ut99bOtnymdg0Fb4fU7o/QzrQfX9HOtcxdoDxZtjdb6LT9+Xb8n+vnW74o+j76eUF3b9YCD3k9nSNeyWe+LHiQJvg4AqBihGwAcTn/s6yRQGla0G7j+wNYuqBrCtIVNaSujBg69j/741u6qGkb0cdrFVlvMrDWbtbuqhnWlYV0Dlo7d1tZdiwas8usqB9Nu6LousoZ8Dbj6PBoMdSyv7tsK3RqANdBVhQYNDf/aAhpqTLYeXNB96jhdDR16Xw0NOmGWNUO1dr/WMKpLXWlg0ZCjr1uXVapOwLAmXdPXpV2CtcXUjq7lSl+nttJraNMWX+05oIFVl54K1Q27OvQgjgZ5fb3aTV3HAWvgtbp6a28H7VatS4TpwR5tgdYDHXoQSD9TOmGdhj49sKIHNfSAjtaTBvXgLtEWHf6g9RKqJ4PSAwoajvVzpL0stJeCfi41jGpgDzZu3DizHJy+N/p90PfHmghOP4s6C7gGc20B14MDuk2/HzoMQ1vaQ034Z9EDSNYQDH1f9ABU8BhvK9Bb3xUNt3qwQN8nq5t7MP0uaUDW8ur7pUMX9ECFvt8W/YxpOfX91QMNegBDD3ppaLbmZrDo3wH9zupnQVvBdVk3/RsQiv6N0ANw2h3emlVe61bH1gMAqsblLz+TCQAAQCX0YISGbQ170US7+WtvBz3YokE6lmhPBD1woMu1AQDqDmO6AQAAAAAIE0I3AAAAAABhQvdyAAAAAADChJZuAAAAAADChNANAAAAAECYELoBAAAAAAgTQjcAAAAAAGFC6AYAAAAAIEwI3QAAAAAAhAmhGwAAAACAMCF0AwAAAAAQJoRuAAAAAADChNANAAAAAECYELoBAAAAAAgTQjcAAAAAAGFC6AYAAAAAIEwI3QAAAAAAhAmhGwAAAACAMCF0AwAAAAAQJoRuAAAAAADChNANAAAAAECYELoBAAAAAAgTQjcAAAAAAGFC6AYAAAAAJ3r7bZGePUWSkkTatROZOLHi++fni/zjHyLNm4ukpIgMHCjyxRd73+/bb0UOPVQkObn0vjfdJFJSUvY+a9eKjBolkp4uUr++yFlniWzYILHI5ff7/XYXAgAAAABQi2bNEjnmGBGNexp6d+4s3T5hgsgtt4R+zHHHiXz2mYjbXRq68/JE4uNFPvpI5NhjS++zeLFI374ihYUiGRkiu3aJ+HwiV1whMnly6X2KikR69xZZsqQ0mGsZdNtBB4nMmyeSkCCxJGZCt8/nE4/HI263W1wul93FAQAAAICwcR99tLi+/lp8F14o/qefFtcTT4j7738Xf/364tu4USQxsewDvvpK4o45RvyJieL7+WeRLl3Efe654nr7bfEfdJD45s83d3Ndcom4p00T/9FHi+/DD0U+/ljiTjtN/G63+FavNi3frhdeEPfFF4u/aVPxLVggUlws7p49xZWTI75XXhH/mWeKE2iU1pwZHx9vcua+xEuM0MC9cOFCu4sBAAAAAGHlKiqSvt99Zy4vHTRIdi1YIO7+/aWPyyWunTtl6csvS16fPmUe0+y996SV9jDv1EkWa1fx33+X1BEjpNvbb4tr0SL548MPpbhlS+n50UeicX3VYYfJjkWLRFq3ll4NG0rCjh2y5rnnZMeJJ0q711+XRiKyfeBAWb1+vXn+9occIg2/+EJ2vPqqrO7cWZykZ8+eklj+IEYshm7ryIO+IXFxcVV6jNfrNUG9Oo9BZKIunYX6dA7q0lmoT+egLp2F+ozBuvz9d3F5veZip2HDRDp2LN3eqJHItm3Sxe8Xf7nQ7fr+e3Oe6nZLH+u2oB7C3TVPdeokcVu3muttBg2SNrvv5+7QQWTHDmlbVGS2ubdtM9sb9uwpmbvv4+rVy4wPb7R9e2CbU+qjolbumArdVpdy/XBW949NTR6DyERdOgv16RzUpbNQn85BXToL9RlDdanjrK376kRm1n11nLaG5NzcPdssBx9szrRVO+6dd0rHcD/00J7n0cfoGO+qPO/u8ePutLQ996lXr/T5c3Ic9zmsbPhyzIRuAAAAAMA+DBokMmKEyLvvipxxRum24C7TzItVYywZBgAAAABOorOKWwoKyi4JpnQ281Beflnkn/8UOfBAkUMOEZkxY89tDRtW/Xmt+1Vn3w5G6AYAAAAAJ2nffk/L9Jo1e0Lvjh2ll7t0Cf047Saua27rsmA//ijSteue23S5L+0u3rRp2edV69aVfV5rDHlF94khhG4AAAAAcBIdPz1wYOnl554rPX/++T1rdmsrdnlr14okJYk0a1YauHXt7f/8p/Q2vX+LFqWXjzqq9PyFF3SJqNI1vDdvLl3b++ijy97ngw9EtmwR2bBB5NNPS7cNHy6xhtANAAAAAE5z++2lrd0ajjMzRa65pnS7tmTrWG2dJK1VKxGd3Vy1br3n8pAhpeH8qadKg/h//7vneW+5pXTbl1+WzoZ+yiml2y+5xKzRbZx/vojOaL59u0jbtqWXs7NFevQQOe00iTWEbgAAAABwmhNOEHnrLRFdqku7lmuovu8+kbFjS2/PyRHRNbQ3bSo7plsDs4Z0bek+8sjScD148J779O4t8vnnIoceKlJUJNKkiciNN4o8/vie+6Sminz1lcjpp4vEx5eGfL2srd0JCRJrmL0cAAAAAJxo5MjSUyjjx5eegjVuXNoyXpnDDhOZM6fi+2jIf+ONahTWuWjpBgAAAAAgTAjdAAAAAACECaEbAAAAAIAwIXQDAAAAABAmhG4AAAAAAMKE0A0AAAAAQJgQugEAAAAACBNCNwAAAAAAYULoBgAAAADspaDYI8Uen2zfVWTO84s9dhcpKsXbXQAAAAAAQGQpKvHK5K9XyHOzV0pOgUcyUuLlosHt5ephHSUpIc7u4kUVQjcAAAAAoEwLtwbuR2YuDWzT4G1dv+KIDpKaSJSsKrqXAwAAAECM0+7jSzblyieLNonL5TIt3KHo9ji3SzbuLBC/31/n5YxGHJ4AAAAAgCiRnJy8X4/3+vyyenue/LU5V/7avEuW6PmmXFm5LU88Pr8c2CxderTIMC3boej2rblFcsnzv8iW3EI5qGV96dGivhzUMkN6tqwvbRqmmtCOPQjdAAAAABAFXb7j3G5p0rqDeP0uKSr2VNjF2+fzy/rsAhOuNVgv1YC9KVeWbd1lWrVDSUuKl+b1k6RJepIZwx0qeOv2RvWSJCu/WLLyS+TbpdvMyZKeHG9C+0EmiJee2jeuZ1rHYxWhGwAAAHC4/W0djZZAmltYIunJCeLx+Rw15riiSc0S492yOadod8t16WnJ5l2ydHOu5Bd7Qz5fcoJbOjdNly7N9JQmXQ5INy3czesnm1ZqfT/1+YPHdFt0u1/88u3NR8pfm3bJog07ZdH60tOfm3Ilt9AjP6zYYU6W1MQ46d48Y3ereIb0bFVfOjVJk/g4d0zUZXSXHgAAAECttY7W5j7rKjTZMct2Xb5GXaZryj4mNdMx1b1bN5BLpv0S8rEJcS7p2CRtT7huli4HHpAurTJTK2x5TkmMN++fquh91fCsJ0uJ1yfLtuwKhPBFG3Lkjw05Jvz/sjrLnCxJ8W7pqkFcQ3jL+tK/baa0bpjqyBnTCd0AAACIOXa0psVCGK3rfdoxy3Z1X6MG4yKPT3IKSiSnsER2FnjMeel1T2B7TrntuQUl4naLvHft0H1Oavb8nFXyw7CjpXFaomSkJJjW6s4arE24TpO2jepJQojW5KrQ16Lv3zVHdirzma2oHnVf3ZpnmNOZA1oHxpCv3LZLFpognmPC+O8bcmRXkUcWrM02J/X0Bf3lvQUb5LFZyxw3Y3p0lhoAAACI0TCqIaagxCsFxbtPernEa1pEC812n+nC+9av6+TRmXsHGO0aPLJPS5m/NtuEJO2enLj73LquLaR7b3Ob1kk9D9VKWpUA7Ha5TKunllXLnhd0WbeXnnvM9sC2Eo85zyvac1lv03K8dsWhFc6yrfs85qGvZFehVxLiXZLgLi2/Xo53l77u+DhX6TZzKr2s2/S28pdP7t1cPlq4cZ/v67ADm8p/P/8rEJqtMF3sDT2GujIanrfvKq5wUjN9X76/+aiwfHatkNsoLcmcJ9Zg8as4t0s6NU03p9P67hlvvnpH/u7W8J1mYrchnRrLP2cs2GddaviPVoRuAAAA2KouW4Bro2VUWy51lmftSlvi8UuJzxe4rOFKyx+47PWZLrOv/rxmn0Ht+B4HyOu/rCsToAOXi70mSJeGz9LTvibBsjSslyjf3XykPD97VcjbdfuVR3SUeyb/KTvyiqUmNHMHB/EmaUny1tWDKw3Ag++fVeN91iSQ6r7iXG7ZlJO33/vT9/XqIztW+r5qK26o16jvmX6+9YBLhp4HX04JdT1eMuslSrOM5AonNaufkmDqIpq43S4zuZqeTundwmzbvquowrrUvw9W+I82hG4AAADYZn9bgDXsBreQlrailm09tbbrksIXDmlXYTDU0PS3KXNk664i8Xh3B2tzKnu5qqoagLVbbU3CaEpCnJmkKjkhTlIS48x1nRRLZ5WuKMBk55fIcT2amWWiNMTrayo995mDBYHL1m3lWmp9fpHCEp855WpLaL0k2VaFAKzhXM81qGu59QCHlrv0ctD13a9LxxYH31a6rfS6htLKAmnT9GR5/Ny+pnu3voYSjx4UsQ6I7F2/epCkuNxlPdfrmamJsrOS91UnEZs4qqeIy2XKZ8Lz7gBdLzHehM3qqmxSMz3IU5MW6EiTvvugw77qUm+PVoRuAAAA1Pls19parGM6n/52xT5bgI/q2kye+mZ5IEiXD9Z6vTrddrVl9KRezSsMTdvzikwgXbG1ei2jCSG6KOtJJ6/SkFnRPvV03VGdJK/IY0KmBueURLekJJQG0FDBWq9rcN3XesgalisKMI3TkmTCqF7Vqi8rmO4dzv2my3vTjKRKA/CbVw825a+t5aOqEkh1jHNtqex91WB+bI8DpDZVdVKzaOf1+Rx7cIHQDQAAgFqd7brI45UtOUWyOafQLGW0KadQtpjLhbsvF5n7fH7jEZW2AOuyQ1VpAdYQp62jKftoFdXrOtlUZesP6+13juguIqXBOXjMb2K5scBmjLDe7nbtM/xWJahpa/hFQ9pLJAcYfX2J8XpyS72kmgdgXQc6mgOpXcEweFKznflFUj81qdJJzaJNioMPLhC6AQAAUKWu3jr50fa84t1hujRAa6jevLNQNucWyqadhbIlt6hKIbkq43G1q+4dp3Q3XYPLdzEOdD3WVt+kOBOCKwq+VQ2G2mJ7aIfGEu1BzY4AY1doqsks29EYDPWz7/V6ZcvaFdKwa1dJjNKZvCOlLuuS82oKAAAA1ZZf5JEp34SeYMzn98uAtplmLWAdD1sV2iLaLCNJmqUnS7P6yeb8gPpJZgyunprrtkrG42pX3RF9Wtbq64zVMFpXraN2habamGU7WoJhYWGhOFlqHdZlXSF0AwAAxMCs3joD9obsAlmvp6w95+uyCySv0CMzrhq0zwnGps1ZJVcN62gmhMrKLzbjgTVQH5CRLE0zks25Cdi7A7Veb5CaUGnLs10TRNkRmuwMo3XdOurE0BSLrxG1h9ANAADggFm9dxaUBIXp/NLzQMAulG27ivZ7LeBP/36YNEhNNOOYndBVt65Dk51Bzemto0AkI3QDAABEmIrWktZZvU/u1UJenLM6EKq1BTu3KHRgDqbjoFs2SJGWmSllzts2TLVtLWC7u+oCQLgRugEAACKMdinfV1dva1bvDxdu3GvCMp0F24TpEMFaTxV1+bZzLWC66gJwMkI3AACAjXQ5qd837JS5q7Pk1zXZsrOg2KyfXFFXb+1Krus6J8XH7Q7VydKiQUqNx3s7fbkeALAToRsAAKAO6XrV89ZkmZA9b022LFy/0wTv4NbqRmmJFXb1blQvqdbXdY6VtYABoK4RugEAAMKkxOuTPzfmyLzdAVuDto7DLi8zNUH6tcmUfm0zzbmuh21nV2+nrwUMAHWJv6IAAAC1tISXzhBuBWxtzf5tXbYUluxpxVZul0iXZumBgN2/baa0a5S611hru7t6M9s1ANQOQjcAAMB+LOF12WEd5LFZS+WT3zfJ6u35ez1OZ/3u26ZBaUt2m0zp3bq+CeyVYVZvAHAGQjcAAKg1ycnJ4jQ63npXkUeen71SHp25bK8lvHx+v2mtnvLNCrO9S7O0QMDu17aBdGicJm5t3q4BZvUGgOhH6AYAALXW7bpJ6w7i9bukqNizXzNp10ZX76oqLPHKuqyCwJrX67Lygy4XSInPJ9/edKRZqiuUaXNWyU/jjpGXLxsoPVrUNy3bAABYCN0AACAs3a7DOfa4OvvUUG6FaD03AVsDtdmWL9t2lV3rurwDm6XL9l3FFS7hlVfkkcEdG9fqawQAOAOhGwAA7Fdrs4bf4Fm2rW7X6qIh7aTI4xOdI8wlLjOJmE4YZp3rdreemwnGSq+H3uaq0j794pfh3Q+QR2cuDbRe65rWlamXGCetMlN3r3mdIq30fPfl1g1TJSM5ocIlvKoyRhsAEJsI3QAAOExtdbsu+5xeE2A3aOvw7vPs/GIZd2J309ocim7XicCO+s/XsiOv4tbkqtDc3TgtSb7+17B97lO7gF95REf5ZXVWmX1ql28TpBuUhmkTsHeHaz3p7eVnDy/7+j22LeEFAIhuhG4AAGK8q7ff75es/JJA92urK3ZwwN4eIjRrt2tdIquibtcafJulJ0lWfrH4/fv32vTxDVMTK+3qrafxp3aXeonxgdbq/W2JTkmMt30JLwBAdCJ0AwAQZa3ONe3qfc4hrWX28u2BML0+u9CMad6QXSgFJd4qdcG2QmyLBinSsWk9aZqeVGG366bpyfLx3w8vE/B9/j3nOvO30nO9aM71fj4xXcWt+/h3P0b7nDdISaxwnw3rJcqpvVtKbWMJLwBATRC6AQCIkgnGNHRqOM4t1NbcEskpLClt2S0sMfs6tU/LSrt63/Phn/vs6q1dt03XaxOqk3d3xU41l1s1SDXlL98Fu7rdrvXxceYparaEVk32WZtYwgsAUF2EbgAAbGh1Pv/QtrJiW54Jz7lFu8NzuSBtwrW5rttLb/do028I2tV7UMfGFXa7zsorkWO6NhWfiGmp1nCtIVsvN6+fLMk1OBBgR7drunoDAKIJoRsAgDDQLuWVtTpf+dLcGk0wpjN/Z6QkBGbU1vMW9VOkSSVdvfX2SWf2lnB2u96ZXyT1U5PC3u2art4AgGhB6AYAoJb5fDoxWcWTfWnY7tO6gWzfVRQI0OnJ8bsvx4fYtidgpybGhZxp2+5u116vV7asXSENu3aVxDCNWy+/T0VXbwBAJCN0AwBQS7w+v3y4cKO8NGe1PH/xwZVOMDb1woMd1+26sLAw7PsAACCaELoBANhPJV6fvPPrevnfV8tl5bY8s+2H5dvlwsHt5NGZy+q01Zlu1wAARBZCNwAANVTk8cqMX9bJk18tN0twqQapCXLxkPZycPuGMqRTY3GJq85bnel2DQBA5CB0AwBQTQXFXnnlpzUy5ZvlsjmnyGxrnJYolx3WQUYf2lbSkvb890qrMwAAsY3QDQBAFe0q8siLc1bLM9+ukO27Zx0/ICNZrjyig5x9SJuQS27R6gwAQGwjdAMAUImd+SWmi/hz36+SnQUlZlurzBS5elgnOb1/S0mKp+UaAACERugGAGAfdDmvZ79bKS/MWW1auVWHJvXkmmGd5NQ+LSQhjlZrAABQMUI3AADlbM4plKe+WSHTf1wthSU+s63rAely7VGd5ISDmkuce+81sgEAAEIhdAMAsNu6rHyZ/PVyef3ndVLsLQ3bvVrVl2uP7CTHdGsmbsI2AACoJkI3ACBmFBR7JM7tLjOTuE50pmtrP/nVMnlr3nrx+PzmvgPaZsp1R3eWwzs3FpeLsA0AAGqG0A0AiAlFJV6Z/PWKvdbMvnhoe7n8hV9k6ZZd5n5DOzU23cgHtm9I2AYAAPuN0A0AiIkWbg3cj8xcGtimwVuv+/x++ddxB8prP6+Va47qJP3aZNpaVgAA4CyEbgCA42mXcm3hDmXanFXyy63HyPAeB9R5uQAAgPPZutZJUVGRjBs3TgYMGCBDhw6VqVOn7vO+n3/+uZxwwgnSt29fOeecc+T333+v07ICAKJXdkGxadkORbfnFoa+DQAAIKpD96RJk2TRokUybdo0ueOOO+Txxx+XTz75ZK/7LV26VP75z3/KFVdcIe+++65069bNXC4oKLCl3ACA6PDDiu1yxYu/SFpSvBnDHYpu10nVAAAAHBW68/PzZcaMGXLrrbdKjx495Nhjj5VLL71Upk+fvtd9v//+e+nUqZOMHDlS2rRpIzfeeKNs3bpVli1bZkvZAQCRy+/3y/fLtslZU+bI2U/9IJ/+vllmL9smFw5uF/L+OpmazmIOAADgqDHdixcvFo/HY7qLW/r37y+TJ08Wn88nbvee4wENGjQwAXvu3Lnm/m+99ZakpaWZAF5dXq+32vetzmMQmahLZ6E+naM261LD9rfLtsljs5bLvDXZZltinEvOGtBaerRIl6Gdm4hLXHvNXn71sI4S7+bzVBv4bjoHdeks1KdzUJeRpar14PLrrxQbfPrpp3LXXXeZVmzL8uXL5cQTT5Q5c+ZIw4YNA9uLi4vl//7v/8xj4uLiTCCfMmWKDBkypFpvyPz582v9dQAA7KX/jc3dWCQz/siTZVklZluiW+SYDqkysms9aZQSZ7YlJydLo2bNJbN+fckpKJaMlETJ2rlTtm/eKIWFhTa/CgAAEK369OljcmrEtXTreOzExMQy26zrGrKDZWVlme7kt99+u/Tu3VteeeUVGTt2rLz99tvSqFGjau23Z8+eFb4h5YP6woULq/UYRCbq0lmoT+fYn7r0+fzyxeIt8vis5fL7xhyzLTnBLaMPaSOXDm0nTTOS9/nYhvVK/79pklnfnFA7+G46B3XpLNSnc1CXkVkflbEtdCclJe0Vrq3r2hoR7MEHH5QuXbrI6NGjzfW7777bzGT+5ptvyuWXX16t/eqHs7of0Jo8BpGJunQW6jM261LD9seLNsljs5bK4k25ZltqYpycP6itXHZYB2mclhTm0qIyfDedg7p0FurTOajL6GJb6G7WrJlpwdZx3fHxpcXQ1mwN3BkZGWXuq8uDnX/++YHr2r28a9eusmHDhjovNwDAHl6fXz74bYM8PmuZLN2yy2zTWcl1grSLh7YPtF4DAABEEttCty77pWFbx1nrOt1KJ0rTrhLBk6ippk2bmvHewVauXGnuCwBwNo/XJ+8t2CCPf7lMVmzNM9vSk+Pl4iHt5aIh7aRBKmEbAABELttCd0pKilkCbPz48XLffffJli1bZOrUqTJhwoRAq3d6erpp+T7rrLPklltukYMOOsjMXq5LjWkr92mnnWZX8QEAtaT8kCJLidcnb/+6Xp74cpms3p5vttVPSZBLh7aXMUPaSQZrawMAgChgW+hWOhmahu4xY8aYJcCuu+46GT58uLlt6NChJoCPGjXKzGiel5dnZizftGmTaSWfNm1atSdRAwBEjoJij8S53dKkdQfx+l1SVOyR1MR4Kfb45I256+R/Xy2TdVkF5r7adfzSw9rLBYPamS7lAAAA0cLWXy7a2j1x4kRzKm/JkiVlrp955pnmBACIfkUlXpn89Yq91szWidAue+FnmbNih7lf47REufzwDjJ6YFupR9gGAABRiF8wAIA6b+HWwP3IzKWBbRq89brP75eLhrSX5Vvz5MojOso5h7SRlERmZwUAANGL0A0AqFPapVxbuEOZNmeV/DzuGPnmpiMlOYGwDQAAoh+hGwBQZ7bkFIrPX9qyHYpu31XkkUastQ0AAByC0A0ACKttu4rk44UbzbJf2m38u5uPNGO4QwVv3Z7OrOQAAMBBCN0AgFqXU1giny7aZIL27OXbxavN2yLicoksXLdTLhzcTh6duWyvx+lkah6fTxLFbUOpAQAAah+hGwBQKwpLvDLzzy3y3oL18uWSrWbpL0uvVvXl1N4t5KRezaV5/RTp07qBuMS11+zlVw/rKEmM5QYAAA5C6AYA1FiJ1yffLt0q783fIJ//sVnyir2B2zo1TTNB+5TeLaR943plHqfB+oojOsg1R3aSnflFUj81ybRwE7gBAIDTELoBANWiXcV/WrnDdB3/eNFGyc4vCdzWKjPFhGwN210PSBeX9iffh9TEePF6vbJl7Qpp2LWrJCbyXxIAAHAefuEAAMza2bqUV25hiZnITFudNRRb/H6/LFi307Rof7hwg2zOKQrc1jgtSU7u1dyE7X5tGlQYtEMpLCys1dcCAAAQSQjdABDjikq8MvnrFSHHV2/ILpQ3562T93/bIKu35wcek5EcLyccVBq0D+3QUOLjmPgMAAAgFEI3AMR4C7cG7kdmLg1s0+Ct131+v/RsWV8e/7J0lvGUhDg5pnsz03X88C6NJSme8dcAAACVIXQDQAzTLuXawh3KtDmr5IexR8vIPi3lqG5N5ZhuTct0OQcAAEDl+PUEADE2Cdpfm3Nl3pos03X8nENam5btUHR7QbFXHj67T52XEwAAwCkI3QDgYNt3Fcn8tdkmZP+6JlsWrM0OLOvVsF6iXHNkRzOGO1Tw1u06qRoAAABqjtANAA7h8fpk8aZc+XVNlsxbk23OVwVNfmaplxgnfdo0kL6tMyUrr9hMmhY8ptui23UW80RhkjQAAICaInQDQJQt32XZmlsUaMHW84XrdkpBSWkrdrCOTepJvzaZ0rdNpvRr20A6N02XOPeeZb10lnIVavbypAQmSwMAANgfhG4AiILlu64a1lFWbcuTOSu2B0L2uqyCvR6fnhwvfVo32B2yS1uz66dW3EVcg/UVR3SQa47sVCboE7gBAAD2H6EbAKJo+a473/8jcJvLJdKlaboJ11bI7tgkTdxBrdhVZbWkN0pLMud0KQcAAKgdhG4AiKLlu07t1Vw6N9OgnSm9W9dnojMAAIAIR+gGgAihXbsrW77r0XP71Xm5AAAAUHP0HwSACFDi9Um9pHgzhjsUlu8CAACIToRuALDZxp0Fcs5TP8i3S7fKmEHtQt7HWr4LAAAA0YXu5QBgIw3aN7w6X3bkFUvxzGXyyuWHitvlYvkuAAAAhyB0A4ANvD6/PDpzqTw6a6n4/SI9WmTIY+f2NV3MWb4LAADAOQjdAFDHtu0qkr+/Ol++W7bNXD93YBu5/eTukrw7WLN8FwAAgHMQugGgDv20codc+/I82ZJbJCkJcXLfqIPktL6t7C4WAAAAwoTQDQB1wOfzy1PfrpAHPl1iupZ3bpom/xvdz6y5DQAAAOcidANAmGXnF8s/X18gMxdvMddP69tS7j3toEA3cgAAADgXv/gAIIzmr82Wa6bPk/XZBZIY75Y7T+0hZx/cWlwul91FAwAAQB0gdANAGPj9fpk2e5Xc+9GfUuL1S9tGqaY7eY8W9e0uGgAAAOoQoRsAapku9XXLmwvlw4UbzfXjexwgk87sJRnJCXYXDQAAAHWM0A0AteiPDTlyzcvzZOW2PIl3u2Tcid3koiHt6E4OAAAQowjdAFBL3clf/2Wt3P7u71Lk8UmL+sny+Oh+0q9Npt1FAwAAgI0I3QCwn/KLPXLbO7/Lm/PWmevDDmwi/z2rj2TWS7S7aAAAALAZoRsA9sOyLbvk6ulz5a/Nu8TtEvnn8APlqiM6iluvAAAAIOYRugGght6dv17GvrVQ8ou90iQ9SR49u68M6tjI7mIBAAAgghC6AaCaijxeufuDP+SlH9aY64M6NJJHzukjTdOT7S4aAAAAIgyhGwAqUVDskTi32ywFlp6cIHNXZcmc5TvMbdcd1Un+fkwXiaM7OQAAAEIgdANABYpKvDL56xXy3OyVklPgkYyUeBkzqJ3MuHKQLNuSK4e0pzs5AAAA9o3QDQAVtHBr4H5k5tLANg3ej81aJm6XS644ooOt5QMAAEDkc9tdAACIVNqlXFu4Q9Ht8W7+hAIAAKBi/GIEgH3IKSwxLdshbyvwmDHeAAAAQEUI3QAQggbqeonxZgx3KLpdJ1UDAAAAKkLoBoByduQVyzlP/yDfLdtqJk0L5aLB7cXj89V52QAAABBdmEgNAIJszimU8575UZZu2WUmUXvpkkPMpGnBs5dr4L56WEdJSoizu7gAAACIcIRuANht7Y58Oe/ZH2X19nw5ICNZJp7eS1IS480s5dcc2SmwTre2cBO4AQAAUBWEbgAQkeVbd5kW7o07C6VNw1SZfulAad0w1dyWmlj6p7JRWpI5T2RkDgAAAKqI0A0g5v25MUfOf/ZH2barWDo1TZOXLhkoB9RPtrtYAAAAcABCN4CYNn9ttoyZ+pPsLCiRHi0y5IWLDwm0aAMAAAD7i9ANIGb9sGK7XPL8z5JX7JV+bRrIcxcdIvVTWAYMAAAAtYfQDSAmfblki1z54lwp8vhkSKdG8tT5A6ReEn8SAQAAULv4hQkg5ny8cKNc/+qvUuL1yzHdmsrj5/aTZGYjBwAAQBgQugHElDfmrpOb3lggPr/Iyb2ay3//1kcS4piNHAAAAOFB6AYQM16cs0pue/d3c/lvA1rLfaN6SpzbZXexAAAA4GCEbgAxYfLXy+X+jxebyxcNaSe3ndRd3ARuAAAAhBmhG4Cj+f1+eejzv+SxWcvM9euO6iQ3HttFXC4CNwAAAMKP0A3A0YH7rg/+kOe+X2Wu33JCV7nyiI52FwsAAAAxhNANwJG8Pr+Me2uhvPbLWnP97hE95PxB7ewuFgAAAGIMoRuA45R4fXLj6wvk/QUbRIdtTzqjt5zRv5XdxQIAAEAMInQDcJTCEq9c+/I8+eLPLZIQ55JHzu4rJ/ZsbnexAAAAEKMI3QAcI6/II5e/+It8v2y7JMW7ZfL5/eXIA5vaXSwAAADEMEI3AEfYWVAiFz//s8xdnSX1EuPkmTEHy6COjewuFgAAAGIcoRtA1Nu+q0gumPqT/L4hR+qnJMjzFx0sfdtk2l0sAAAAgNANIDolJyeb8805hTL6mR9l2ZZd0jgtUV68ZKB0a55hd/EAAAAAg9ANIKoUFHskzu2WJq07iNfvkiWbcsXvF2leP1leunSgdGySZncRAQAAgABCN4CoUVTilclfr5DnZq+UnAKPZKTEy5hB7eSNKweZWcubN0ixu4gAAABAGYRuAFHTwq2B+5GZSwPbNHg/NmuZuF0uueKIDraWDwAAAAjFHXIrAEQY7VKuLdyh6PZ4N3/OAAAAEHn4lQogKuQWlpiW7VB0u94OAAAARBpCN4CokJ6cYMZwh6Lb9XYAAAAg0hC6AUQFr88nFw5uF/K2iwa3F4/PV+dlAgAAACrDRGoAooJLXHLh4PZmebBpc1YFZi/XwH31sI6SlBBndxEBAACAvRC6AUSFN+atk+e+XyW3n9JNrjuqs+zML5L6qUmmhZvADQAAgEhF93IAEc/n88uz362U5Vt3yYqteRLn8suWtSvMeWoixw4BAAAQuQjdACLeF39ulpXb8iQjOV7OGtDabCssLLS7WAAAAEClCN0AIt4z35auz33uwLZSL4mWbQAAAEQPQjeAiLZgbbb8tGqHxLtd+5y9HAAAAIhUhG4AEe3pb1eY81P7tJAD6ifbXRwAAACgWgjdACLW2h358tHCjebypUM72F0cAAAAoNoI3QAili4R5vOLDO3UWLq3yLC7OAAAAEC1EboBRKSdBSXy2s9rzOVLD2tvd3EAAACAGiF0A4hIr/60RvKKvXJgs3Q5oksTu4sDAAAA1AihG0DEKfb4TNdydclh7cXlctldJAAAAKBGCN0AIs6HCzfIppxCaZKeJCP6tLC7OAAAAECNEboBRBS/3y9Pf7PSXB4zqK0kxcfZXSQAAACgxgjdACLKnOXb5Y+NOZKc4JbRA9vaXRwAAAAgekN3UVGRjBs3TgYMGCBDhw6VqVOn7vO+S5YskXPOOUd69eolp5xyivzwww91WlYAdePpb1eY87MGtJbMeol2FwcAAACI3tA9adIkWbRokUybNk3uuOMOefzxx+WTTz7Z6365ubly8cUXS6dOneT999+XY489Vq699lrZvn27LeUGEB5LN+fKl0u2is6bdvEQlgkDAABA9LMtdOfn58uMGTPk1ltvlR49epggfemll8r06dP3uu/bb78tqampMn78eGnbtq1cf/315lwDOwDneObb0rHcw7s3k3aN69ldHAAAAGC/xYtNFi9eLB6PR/r27RvY1r9/f5k8ebL4fD5xu/ccD/jpp5/k6KOPlri4PRMqvfnmm3VeZgDhszW3SN7+db25fNlhHewuDgAAABDdoXvr1q2SmZkpiYl7xmw2btzYjPPOzs6Whg0bBravXbvWjOW+7bbbZNasWdKyZUu5+eabTUivLq/XW+37VucxiEzUZeSbNnulFHt90rd1fenTKqPCuqI+nYO6dBbq0zmoS2ehPp2DuowsVa0H20J3QUFBmcCtrOvFxcV7dUV/6qmn5IILLpCnn35aPvzwQ7nkkkvk448/lubNm1drvwsXLqx2WWvyGEQm6jIyFXn8Mu37Leby0a1csmDBgio9jvp0DurSWahP56AunYX6dA7qMrrYFrqTkpL2CtfW9eTk5DLbtVt5t27dzFhu1b17d/n+++/l3XfflSuvvLJa++3Zs2eZbuqVHbnQD3R1HoPIRF1Gtuk/rpHc4s3SOjNFLj9xoMS5XRXen/p0DurSWahP56AunYX6dA7qMjLrI2JDd7NmzSQrK8uM646Pjw90OdfAnZGRUea+TZo0kQ4dyo7xbNeunWzcuLHa+9UPZ3U/oDV5DCITdRl5fD6/PDd7tbl88dD2kphQ9T9L1KdzUJfOQn06B3XpLNSnc1CX0cW22cu15VrD9vz58wPb5s6da47aBE+ipvr06WPW6Q62YsUKM7YbQHT74s/NsnJbnmQkx5u1uQEAAAAnsS10p6SkyMiRI80yYL/99pt88cUXMnXqVDNu22r1LiwsNJfPPvtsE7ofe+wxWb16tTzyyCNmcrURI0bYVXwAteTpb1eY89GHtpV6SbZ1vgEAAACcFbrV2LFjzRrdY8aMkTvvvFOuu+46GT58uLlt6NCh8tFHH5nL2qL9zDPPyJdffiknn3yyOdeJ1bSLOoDoNX9ttvy8KksS4lxy4eB2dhcHAAAAqHW2Nitpa/fEiRPNqbzy3cl1ebC33nqrDksHoK5auU/p3UKaZZSdQBEAAABwAltbugHErrU78uXjhaWTIV46tOxEiQAAAIBTELoB2OK571eJzy9yWOfG0r1F2RULAAAAAKcgdAOoczsLSuS1n9eYy5ceRis3AAAAnIvQDaDOvfLTGskr9sqBzdLl8M6N7S4OAAAAEDaEbgB1qtjjk+e/X2UuX3JYe3G5XHYXCQAAAAgbQjeAOvXhwg2yKadQmqQnyYg+LewuDgAAABBWhG4Adcbv98tT36w0l3Vd7qT4OLuLBAAAAIQVoRtAnZm9fLv8uTFHUhLiZPTANnYXBwAAAAg7QjeAOvP0tyvM+ZkDWkmD1ES7iwMAAACEHaEbQJ34a3OufLVkq+i8aRcPaW93cQAAAIA6QegGUCee2d3KfVz3A6Rd43p2FwcAAACoE4RuAGG3JbdQ3vl1g7l82eG0cgMAACB2ELoBhN2Lc1ZLsdcnfds0kP5tG9pdHAAAAKDOELoBhFVBsVde/GG1uXzZYR3sLg4AAABQpwjdAMLqjblrJTu/RFo3TJHjehxgd3EAAACAOkXoBhA2Xp9fnv1upbl8yZD2Eud22V0kAAAAoE4RugGEzRd/bpZV2/MlIzlezhzQ2u7iAAAAAHWO0A0g7MuEjT60rdRLire7OAAAAECdI3QDCItf12TJz6uyJCHOJRcObmd3cQAAAABbELoBhMUz35aO5T61d0tplpFsd3EAAAAAWxC6AdS6tTvy5eNFG83lSw9rb3dxAAAAANsQugHUuqnfrxSfX+Swzo2lW/MMu4sDAAAA2IbQDaBW7cwvkdd+XmsuX3pYB7uLAwAAANiK0A2gVr380xrJL/bKgc3S5fDOje0uDgAAAGArQjeAWlPs8cnzs1cGxnK7XC67iwQAAADYitANoNZ88NsG2ZxTJE3Sk+TUPi3sLg4AAABgO0I3gFrh9/vl6d3LhOm63EnxcXYXCQAAALAdoRtArfh+2Xb5c2OOpCTEyeiBbewuDgAAABARCN0AasXT364w52cNaCUNUhPtLg4AAAAQEQjdAPbbqu15snD9TtF50y4e2t7u4gAAAAARI97uAgCIXgXFHolzuyUxzi3f3Xyk6V7etlE9u4sFAAAARAxCN4AaKSrxyuSvV8hzs1dKToFHMlLi5aLB7eWgFvUlKYFJ1AAAAABF6AZQoxZuDdyPzFwa2KbB27p+xREdJDWRPy8AAAAAY7oBVJt2KdcW7lB0e7ybPy0AAACA4pcxgGrLLSwxLduh6Ha9HQAAAAChG0ANpCcnmDHcoeh2vR0AAAAAoRtADXh9PjNpWii63ePz1XmZAAAAgEjETEcAqi0lMV6uHtZR/H6/PD9nVZnZy3U7s5cDAAAApQjdAGpEg/WhHRvJlcM6yq4ijzRISTQt3ARuAAAAYA+6lwOosaunz5OhE7+UXYUeSYx3s0wYAAAAUE6NfiHn5ubKe++9JytXrpSrr75aFixYIB07dpQ2bdrU5OkARKGdBSWSnV86S3nTjGS7iwMAAAA4o6X7r7/+kuHDh8ubb74pr776quTl5clnn30mI0aMkJ9++ik8pQQQcdbuyDfnjeolSloSLdwAAABArYTue+65R8455xx56623JCGhdFmgCRMmyLnnniuTJk2q7tMBiPLQ3aZRqt1FAQAAAJwTuhcuXCgjR47ca/vZZ58ty5Ytq61yAYhwq63Q3ZDQDQAAANRa6G7YsKEZy13evHnzpFGjRtV9OgBRag2hGwAAAKhUtQdiXnbZZfLvf/9brrzySrNG7w8//CBvv/22TJs2Tf7xj39U9+kARHn38taEbgAAAKD2Qrd2I2/atKk8++yzkpycbMZxt2/fXu6++2458cQTq/t0AKK8pbstoRsAAACovdD9zDPPyMknnyzTp0+v7kMBOITH65P1WQXmMhOpAQAAALU4pnvy5MlSUlK6Ni+A2LRxZ6F4fH5JjHNLs3TW6AYAAABqLXRrK/eTTz4pq1atkuLi4uo+HICDupa3apgibrfL7uIAAAAAzule/s0338iGDRvM5Gmh/Pnnn7VRLgARjPHcAAAAQJhC9/3331/dhwBwmNXbWS4MAAAACEvoPuSQQ8y5di9fvny5+Hw+M3t5p06dqvtUAKIUy4UBAAAAYQrdOTk5MnbsWJk5c6bUr19fvF6v5OXlycEHHyxPPPGEpKenV/cpAURp93JaugEAAIBankjtnnvukU2bNslHH30kP/74o/zyyy/y/vvvS35+vkyYMKG6Twcgmsd0N6pnd1EAAAAAZ4XuWbNmyfjx46VDhw6Bbdq1/Pbbbzet3wCcbWd+iewsKF02sHXDFLuLAwAAADgrdCclJYnbvffDXC6X6WoOIDZauRunJUlqYrVHqAAAAAAxpdqh+6ijjpI777xT1qxZE9imk6ppt/MjjjiitssHIGLHc9PKDQAAAFSm2s1U//rXv+Saa66R4cOHm4nU1M6dO+Xwww+X2267rbpPByDKMIkaAAAAEMbQnZGRIS+++KIsWbLELBmm3c11ybDgMd4AYiB0M4kaAAAAUPuhu7i4WB5++GFp2bKljB492mwbNWqUDB48WG644QZJSEio7lMCiCJrduSZc1q6AQAAgDAtGfb1119L165dA9uuvvpq+eqrr2TixInVfToAUYbu5QAAAEAYQ/dnn30mDz74oPTv3z+w7ZhjjjFrdOva3QCcq8Trkw3ZheYyoRsAAAAIQ+j2+/1SVFQUcntJSenavQCcaWN2oXh9fkmKd0vT9CS7iwMAAAA4L3Qfd9xxZpbyX375RfLz881p3rx5Mn78eDn22GPDU0oAEWH17vHcrRumitvtsrs4AAAAgPMmUhs7dqzceuutMmbMGPH5fGab2+2WkSNHyrhx48JRRgARgvHcAAAAQJhDd0pKijz00EOSk5Mjq1evNrOVt2rVStLS0qr7VACiDKEbAAAACGP38m3btonX6w2s1x0XFyezZ8+WL774wnQzB+BsawndAAAAQO2H7ry8PLnyyivlsMMOk1WrVpltb731lpxxxhny4osvypQpU+SUU06RTZs2VW/vAKLK6u2EbgAAAKDWQ/djjz0m69evl5deekk6dOhgWrXvvfde6dWrl1lC7OOPP5ahQ4eapcQAOJOuULDGCt2NCN0AAABArYVuDdY6eZquze1yueS7774zrd/nn3++GdOtRo0aZbYDcKadBSWSW+Qxl1tnEroBAACAWgvdW7dulTZt2gSu6zhuHc+trduWxo0bS0FBQZV2CiB6J1HT9blTEuPsLg4AAADgnNDdrFkzWbt2baCL6ddffy29e/eW+vXrB+7z66+/SvPmzcNXUgC2Yjw3AAAAEKbQPWLECDOGe+bMmXLffffJxo0b5dxzzw3cvnjxYrOM2PHHH1+DIgCIBiwXBgAAAIRpne6rrrpKdu3aJePGjTNjuq+//no5+eSTzW0TJ06U5557ToYNG2buB8DZy4W1JnQDAAAAtRu64+PjZezYseZU3siRI81yYd27d6/6XgFEbUt3W2YuBwAAAGo3dFfkwAMP3N+nABAF6F4OAAAAhGlMN4DYVuzxyYbs0tUJCN0AAABA1RG6AVRKA7fPL5Kc4JYm6Ul2FwcAAACIGoRuANXqWq6TKQIAAACoGkI3gEoxnhsAAACoGUI3gCqHbpYLAwAAAMIwe3mopcL2ZcKECdUsAoBIt2Y7Ld0AAABA2Fq627RpI++9957Mnz+/RjsBEN3oXg4AAACEsaX7qquuktatW8u///1veeSRR6RLly413B2AaOP3+2Xt7tDdthGhGwAAAAjLmO6TTz5ZRowYIePHj6/WDgBEt6z8Eskt8pjLrTIJ3QAAAEDYJlK7/fbbZcqUKVJbioqKZNy4cTJgwAAZOnSoTJ06tdLHrFu3Tvr27Ss//vhjrZUDQOVdy5tlJElyQpzdxQEAAACc173cEhcXJ+np6bW280mTJsmiRYtk2rRpsmHDBrn55pulRYsWcvzxx+/zMdrSnp9fGgIAhB/juQEAAIAwt3SPHj1acnJyymwrLCzcj92KCc4zZsyQW2+9VXr06CHHHnusXHrppTJ9+vR9PkYnc8vLy9uv/QKoHms8d5uG9ewuCgAAAODM0D137lwpKSkps23w4MGydu3aGu948eLF4vF4TFdxS//+/WXBggXi8/n2un9WVpY88MADctddd9V4nwCqb/X20gNdtHQDAAAAYe5eXn5G4/2xdetWyczMlMTExMC2xo0bm3He2dnZ0rBhwzL3v//+++W0006Tzp0779d+vV5vte9bnccgMlGXNbd69xrdrTKTI+b9oz6dg7p0FurTOahLZ6E+nYO6jCxVrYcah+79VVBQUCZwK+t6cXFxme2zZ882re0ffPDBfu934cKFdfIYRCbqsvqWb84254Xb1sn8+VskklCfzkFdOgv16RzUpbNQn85BXUYX20J3UlLSXuHaup6cnFxm7LjOmn7HHXeU2V5TPXv2NBPCVfXIhX6gq/MYRCbqsmaKPT7Z/sZn5vIxh/aWxmlJEgmoT+egLp2F+nQO6tJZqE/noC4jsz5qLXR//PHHkpaWFriu464///zzvbqBjxw5skrP16xZMzNOW8d1x8fHB7qca7DOyMgI3O+3334zY8evv/76Mo+/7LLLzL6qO8ZbP5zV/YDW5DGITNRl9WzcUSA6kiQlIU6aZqSIy+WSSEJ9Ogd16SzUp3NQl85CfToHdRldqhS6dRmv8mtoN2rUSF566aUy2/QHeVVDd7du3UzYnj9/vlmnW2kXcj1q43bvmd+tV69e8tlnpS1tluHDh8s999wjQ4YMqdK+AOz/cmGRFrgBAAAAx4TuWbNm1fqOU1JSTEDXdbfvu+8+2bJliwn2EyZMCLR665rg2vLdtm3bkC3lGvwBhH+5sNbMXA4AAACEb8mwcBk7dqxZo3vMmDFy5513ynXXXWdasdXQoUPlo48+srN4QMyzWrrbNiJ0AwAAAFE1kZrV2j1x4kRzKm/JkiX7fFxFtwEIT/dyAAAAAFHW0g0gOtboJnQDAAAANUPoBhCS3+9nTDcAAACwnwjdAELakVcsecVe0UnLW2Wm2F0cAAAAICoRugFUOJ77gIxkSU5gHUgAAACgJgjdACoM3XQtBwAAAGqO0A0gpDVMogYAAADsN0I3gJBYLgwAAADYf4RuABWG7raNCN0AAABATRG6AYTEmG4AAABg/xG6AeylsMQrm3IKzWW6lwMAAAA1R+gGsJf12QXi94ukJsZJo3qJdhcHAAAAiFqEbgAVTqLmcrnsLg4AAAAQtQjdAPbCcmEAAABA7SB0A9gLy4UBAAAAtYPQDWDfoZvlwgAAAID9QugGsJe1tHQDAAAAtYLQDaAMv99P93IAAACglhC6AZSxbVex5Bd7RSctb5mZYndxAAAAgKhG6AZQhtXK3TwjWZLi4+wuDgAAABDVCN0AQo/nZhI1AAAAYL8RugGUwXhuAAAAoPYQugGUsXo7oRsAAACoLYRuACG7l7cmdAMAAAD7jdANIGT38raN6tldFAAAACDqEboBBBSWeGVTTqG5TPdyAAAAYP8RugEErMsqbeVOS4qXzNQEu4sDAAAARD1CN4C9upbreG6Xy2V3cQAAAICoR+gGELBm98zlbelaDgAAANQKQjeAgDU7Csx5m0aEbgAAAKA2ELoBBKzZkWfOWS4MAAAAqB2EbgB7jelm5nIAAACgdhC6ARh+v5/QDQAAANQyQjcAY+uuIiks8YnbJdKyQYrdxQEAAAAcgdANoMzM5c3rp0hiPH8aAAAAgNrAL2sABl3LAQAAgNpH6AZgELoBAACA2kfoBlA2dLNGNwAAAFBrCN0AjLW0dAMAAAC1jtANwFi9eyI1QjcAAABQewjdAKSg2CtbcovMZUI3AAAAUHsI3QBkXVZpK3d6crw0SE2wuzgAAACAYxC6AZSZudzlctldHAAAAMAxCN0AGM8NAAAAhAmhGwBrdAMAAABhQugGsGe5MNboBgAAAGoVoRsALd0AAABAmBC6gRjn8/kJ3QAAAECYELqBGLd1V5EUeXwS53ZJiwYpdhcHAAAAcBRCNxDjrFbuFg2SJSGOPwkAAABAbeIXNhDj1rBcGAAAABA2hG4gxq1mPDcAAAAQNoRuIMZZy4W1JnQDAAAAtY7QDcQ4a0x324b17C4KAAAA4DiEbiDGsVwYAAAAED6EbiCG5Rd7ZGtukblM6AYAAABqH6EbiGFrdxSY84zkeKmfmmB3cQAAAADHIXQDMSzQtbwRrdwAAABAOBC6gRjGJGoAAABAeBG6gRjGcmEAAABAeBG6gRi2enueOWcSNQAAACA8CN1ADGO5MAAAACC8CN1AjPL5/LI2q3T28rZMpAYAAACEBaEbiFFbcouk2OOTOLdLmtdPtrs4AAAAgCMRuoEYH8/dskGKxMfxpwAAAAAIB35pAzGK8dwAAABA+BG6gRhfLqwN47kBAACAsCF0AzGKlm4AAAAg/AjdQIxaTegGAAAAwo7QDcR693JCNwAAABA2hG4gBuUVeWTbrmJzmTHdAAAAQPgQuoEYtDartJW7QWqCZCQn2F0cAAAAwLEI3UAMWr2druUAAABAXSB0AzE8nrs1oRsAAAAIK0I3EMPLhbUldAMAAABhRegGYhBrdAMAAAB1g9ANxCBCNwAAAFA3CN1AjPH6/LJuR4G5zJhuAAAAILwI3UCM2ZxTKMVen8S7XdKiQYrdxQEAAAAcjdANxGjX8laZKRLndtldHAAAAMDRCN1AjIZuupYDAAAA4UfoBmLMmu1MogYAAADUFUI3EGOYuRwAAACoO4RuIEZDd9tGhG4AAAAg3AjdQIxZy5huAAAAoM4QuoEYsqvII9vzis1lQjcAAAAQfoRuIAYnUctMTZCM5AS7iwMAAAA4HqEbiMVJ1BrVs7soAAAAQEywNXQXFRXJuHHjZMCAATJ06FCZOnXqPu/71VdfyYgRI6Rv375yyimnyMyZM+u0rICTxnMzczkAAAAQA6F70qRJsmjRIpk2bZrccccd8vjjj8snn3yy1/0WL14s1157rZx++unyzjvvyNlnny033HCD2Q6g6lbvyDPnbRqm2F0UAAAAICbE27Xj/Px8mTFjhjz99NPSo0cPc1q6dKlMnz5djj/++DL3/eCDD+TQQw+VCy64wFxv27atzJo1Sz7++GPp2rWrTa8AiD5rdhSYc1q6AQAAgLphW+jWVmqPx2O6i1v69+8vkydPFp/PJ273nkb40047TUpKSvZ6jtzc3Grv1+v1Vvu+1XkMIhN1WWrN9tKW7lYNkqP6vaA+nYO6dBbq0zmoS2ehPp2DuowsVa0H20L31q1bJTMzUxITEwPbGjdubMZ5Z2dnS8OGDQPbO3bsWOax2iI+Z84c0828uhYuXFgnj0FkiuW69Pr9sm73mO7cTatkfs5aiXaxXJ9OQ106C/XpHNSls1CfzkFdRhfbQndBQUGZwK2s68XFpesIh7Jjxw657rrrpF+/fnL00UdXe789e/aUuLi4Kh+50A90dR6DyERdiqzPKhCPf7MkxLnkqEP7SZzbJdGK+nQO6tJZqE/noC6dhfp0DuoyMusjYkN3UlLSXuHaup6cnBzyMdu2bZOLLrpI/H6/PProo2W6oFeVfjir+wGtyWMQmWK5LtftLDTnrTJTJTHBtq9+rYrl+nQa6tJZqE/noC6dhfp0Duoyutg2e3mzZs0kKyvLjOsO7nKugTsjI2Ov+2/evFlGjx5tgvkLL7xQpvs5gMqxXBgAAAAQQ6G7W7duEh8fL/Pnzw9smzt3rukqUb4FW2c6v/TSS832l156yQR2ANWzhtANAAAAxE7oTklJkZEjR8r48ePlt99+ky+++EKmTp0aWBZMW70LC0u7w06ZMkXWrFkjEydODNymp5rMXg7EKpYLAwAAAOqerQM7x44da0L3mDFjJC0tzUyQNnz4cHPb0KFDZcKECTJq1Cj59NNPTQA/88wzyzxelxK7//77bSo9EJ3LhbUmdAMAAACxEbq1tVtbr60W7GBLliwJXP7kk0/quGSAc7uXt21E6AYAAAAc370cQN3JKSyRrPwSc5mWbgAAAKDuELqBGJq5vFG9RElLcsZyYQAAAEA0IHQDMWDN9tLQTSs3AAAAULcI3UAMYDw3AAAAYA9CNxADWKMbAAAAsAehG4ih0E33cgAAAKBuEbqBGEBLNwAAAGAPQjfgcB6vT9ZnFZjLhG4AAACgbhG6AYfbuLNQPD6/JMa55YCMZLuLAwAAAMQUQjcQI2t0t2qYIm63y+7iAAAAADGF0A043GrGcwMAAAC2IXQDDsckagAAAIB9CN2AwxG6AQAAAPsQuoEYGdNN6AYAAADqHqEbcLjV23eH7kaEbgAAAKCuEboBB9uZXyI7C0rM5daZhG4AAACgrhG6AQdbm1Xayt04LUnqJcXbXRwAAAAg5hC6gZiYRC3F7qIAAAAAMYnQDTgYM5cDAAAA9iJ0A7EwiRqhGwAAALAFoRuIheXCGtWzuygAAABATCJ0Aw5G93IAAADAXoRuwKE8Xp+szy4wlwndAAAAgD0I3YBDbcguFK/PL4nxbmmanmR3cQAAAICYROgGYqBrudvtsrs4AAAAQEwidAMOxXhuAAAAwH6EbsChCN0AAACA/QjdgEOt2ZFnzlsTugEAAADbELoBh7d0tyV0AwAAALYhdAMOtWb77u7ljQjdAAAAgF0I3YAD7cwvkZxCj7ncOpPQDQAAANiF0A040Ord47mbpCdJSmKc3cUBAAAAYhahG3AgZi4HAAAAIgOhG3AgJlEDAAAAIgOhG3CgtbtDN8uFAQAAAPYidAMORPdyAAAAIDIQugEHWs1yYQAAAEBEIHQDDlPi9cmG7AJzmTHdAAAAgL0I3YDDaOD2+UWS4t1myTAAAAAA9iF0Aw4ez+1yuewuDgAAABDTCN2AU8dz07UcAAAAsB2hG3DocmFMogYAAADYj9ANOAzLhQEAAACRg9ANOAyhGwAAAIgchG7AQfx+v6xhTDcAAAAQMQjdgINk55dIbpHHXG5N6AYAAABsR+gGHNi1vFlGkiQnxNldHAAAACDmEboBB2E8NwAAABBZCN2Ag2zJLZQDm6VL1+bpdhcFAAAAgIjE210AALWjoNgjowe2leHdD5Am6UmSX+yR1ES+4gAAAICd+EUOOEBRiVcmf71Cnpu9UnIKPJKREi8XDW4vVw/rKEmM7QYAAABsQ+gGHNDCrYH7kZlLA9s0eFvXrziiAy3eAAAAgE0Y0w1EuTi327Rwh6Lb4918zQEAAAC78GsciHK5hSWmZTsU3a63AwAAALAHoRuIcunJCWYMdyi6XW8HAAAAYA9CNxDlcgpLZMygdiFv08nUPD5fnZcJAAAAQClCNxDFtOv4/72+QC4c3E6uP6pToMVbz284urOZvZxJ1AAAAAD78GsciFJ+v19ufvM3+eqvrXLNy/NkynkD5NqjOpsgrl3KtYWb5cIAAAAAexG6gSj17Hcr5aOFmyQhziU3Hd9V6qeWjt1ulJZkzhPpyAIAAADYjl/lQBT6aeUOmfDxYnP53yd1l35tMu0uEgAAAIAQCN1AlNmSWyjXvjxPvD6/nNq7hVwwqK3dRQIAAACwD4RuIIp4vD657uVfZUtukXRumiYTRvUUl8tld7EAAAAA7AOhG4giD3y2RH5cuUPqJcbJk+f1l3pJTMsAAAAARDJCNxAlPlm0SaZ8vcJcnnRGb+nUNM3uIgEAAACoBKEbiAIrt+XJv2YsMJcvGdpeTurV3O4iAQAAAKgCQjcQ4QqKvXLVS3Mlt8gjA9pmyi0ndLW7SAAAAACqiNANRDC/3y+3vr1QFm/KlcZpifLE6H6SEMfXFgAAAIgW/HoHItjLP62Rt35dL26XyGPn9JNmGcl2FwkAAABANRC6gQi1YG223PneH+byTcd3lUEdG9ldJAAAAADVROgGIlBWXrFcPX2eFHt9Mrx7M7ni8A52FwkAAABADRC6gQjj9fnlhtfmy/rsAmnXKFUePKu3uFwuu4sFAAAAoAYI3UCEeWzWUvnmr62SnOCWJ8/rLxnJCXYXCQAAAEANEbqBCPLVki3yyMyl5vK9I3tKt+YZdhcJAAAAwH4gdAMRYl1Wvvz9tfni94ucO7CNnN6/ld1FAgAAALCfCN1ABCjyeM3Eadn5JdKrVX25/eTudhcJAAAAQC0gdAMR4K73/5Df1u2UBqkJ8sS5/SQ5Ic7uIgEAAACoBYRuwGZvzl0n039cIzpB+cN/6yOtG6baXSQAAAAAtYTQDdjoz405cus7C83l64/qLMMObGp3kQAAAADUIkI3YJOcwhK56qW5Uljik8O7NJHrj+5sd5EAAAAA1DJCN2ADv98v//f6Alm1PV9aNkgx3crj3C67iwUAAACglhG6ARs89c0K+eyPzZIY55b/je4nDesl2l0kAAAAAGFA6Abq2A8rtsukT5eYy7ef0l16t25gd5EAAAAAhAmhG6hDW3IK5dqXfxWvzy+j+raU0QPb2F0kAAAAAGFE6AbqSInXJ9e8PE+27SqSrgeky72n9RSXrhMGAAAAwLEI3RGkoNgjxR6fbN9VZM7ziz12Fwm1aNIni+XnVVmSnhQvT57XX1IS4+wuEgAAAIAwiw/3DlA1RSVemfz1Cnlu9krJKfBIRkq8XDS4vVw9rKMkJcSFLeTHud2SW1gi6ckJ4vH5JDWRj0Q4fLRwozz97Upz+YEze0v7xvXsLhIAAAAAp7d0FxUVybhx42TAgAEydOhQmTp16j7v+8cff8iZZ54pvXv3ltNPP10WLVokTqHh939fLZdHZi41gVvpuV7X7buKSsTn84cl5A+493Ppf88X5nzK1yvMdqdKTk62Zb8rt+2Sm974zVy+4vAOcvxBB9hSDgAAAAB1z9ZmzUmTJpnwPG3aNNmwYYPcfPPN0qJFCzn++OPL3C8/P18uv/xyOeWUU+T++++XV155Ra644gr5/PPPJTU1VaKdtjZrC3couv2KIzrIgHu/MC3SusSUtnwnxbslMd4ddB63+zZrW9n7mNt3Xx7eo5m8v2CDPDpzWWA/VshXlwxtL2lJ8eIOw7rRdrSuW/ts0rqDeP0uKSr21Nk+cwpL5ICMFHnorN7y8aJN8q/jDgzrfgEAAABEFttCtwbpGTNmyNNPPy09evQwp6VLl8r06dP3Ct0fffSRJCUlyU033WQmnrr11lvlm2++kU8++URGjRol0U4DqNXCXZ5u35FXLE3Sksx5idcrecU1b43W9aAvGtJOnp+9qsKQf/B9X5hx5fVTEswpI3n3eUr8nm1Bt5Vejg9s05AfCV3oI2WfYwa1k/tG9ZT4OKZRAAAAAGKJbaF78eLF4vF4pG/fvoFt/fv3l8mTJ4vP5xO3e084WbBggbnNmulZz/v16yfz5893ROjWFl8NZqGCt25vmp4sr15+qBR6vCYIF3l8u8+95vKe6z4T+Iq9eu4LOvcGrmemJEp2fuUhv3G9JFmyOVdyCz2yLqug2q9JW9SDg/nYE7rKN39tlUdn7d267he/nNKrhXy5ZIvUpiMPbCrv/xa6Rb+u9/nYrGXidrnMAQ3GzQMAAACxw7Zf/1u3bpXMzExJTEwMbGvcuLEZ552dnS0NGzYsc99OnTqVeXyjRo1My3h1eb3eat+3Oo+pCY/XZ1pfre7dwXS7x+uVjOQ4yZDaaZnVLtaVhfwXLxkgOzWcF3pkZ0GJOWkA13NrW07QZW2t31ngMd2p/X4xBwC25BaZk7aud2+RIRdP+zlkebTV/cojOprWYQ38tUH3ed6hbffZom/HPrXl+5ojO4X98xQL6uq7ifCjLp2F+nQO6tJZqE/noC4jS1XrwbbQXVBQUCZwK+t6cXFxle5b/n5VsXDhwjp5THUn+Lri8C4i4pfnZq8K6gbdTq44vL2sXPaXFBYW1tr+WrXtYJ77kaDWWItu35GdLetX7xljXn/3SZJ2nwK050HC7lMpn98vBR6/5BX7ZFexX/JKfJKUlCI784srbF3Pzi+WE7uky7odebXzGhvWk+y8yNvnzvwi2bJ2Ra3WZywL93cTdYe6dBbq0zmoS2ehPp2DuowutoVuHaNdPjRb18vPMr2v+9ZkNuqePXtKXFxclY9c6Ae6Oo/ZHzqz9TVHdg5MMqbjt7WbdteuXWt9X1cNyzChOdRY53i3SJPMPrW6v8pa1xunJcudZxzs+H3WT02ShmGoz1hT199NhA916SzUp3NQl85CfToHdRmZ9RGxobtZs2aSlZVlxnXHx8cHupFrkM7IyNjrvtu2bSuzTa83bdq02vvVD2d1P6A1eUxNpO7eR6O00uZknW08XHRXOr5YuzsHzyQersnFios9FXeh9/kksZbHOsfKPmNZXX03EX7UpbNQn85BXToL9ekc1GV0sW0q5W7dupmwrZOhWebOnWuO2gRPoqZ0be5ff/1V/DpYWDth+/0yb948sx01pxN6abDXkK/n4ZzgKyUx3rSi33B0Z9Piq/Rcr+v2cOw7VvYJAAAAIHLZlgBSUlJk5MiRMn78eLnvvvtky5YtMnXqVJkwYUKg1Ts9Pd20fOsSYv/5z3/k3nvvlbPPPlteffVVM877hBNOsKv4qAFtRa/L1vXy+9Tx1Nq9uy73WVevEwAAAEBksnXR4LFjx5r1uceMGSN33nmnXHfddTJ8+HBz29ChQ8363CotLU2mTJliWsJ1iTBdQuypp56S1NRUO4uPCG9dD95nnMtvJjDT87raZ12/TgAAAACRx9YkoK3dEydONKfylixZUuZ6r1695O23367D0sFpmDEcAAAAQEy1dAMAAAAA4GSEbgAAAAAAwoTQDQAAAABAmBC6AQAAAAAIE0I3AAAAAABhQugGAAAAACBMCN0AAAAAAIQJoRsAAAAAgDAhdAMAAAAAECaEbgAAAAAAwoTQDQAAAABAmBC6AQAAAAAIE0I3AAAAAABhQugGAAAAACBM4iVG+P1+c+71eqv8GOu+1XkMIhN16SzUp3NQl85CfToHdeks1KdzUJeRxaoHK2vui8tf2T0cori4WBYuXGh3MQAAAAAADtKzZ09JTEzc5+0xE7p9Pp94PB5xu93icrnsLg4AAAAAIIpplNacGR8fb3KmxHroBgAAAACgrjGRGgAAAAAAYULoBgAAAAAgTAjdAAAAAACECaEbAAAAAIAwIXQDAAAAABAmhG4AAAAAAMKE0A0AAAAAQJgQukMoKiqScePGyYABA2To0KEydepUu4uECmzevFmuv/56OeSQQ+Swww6TCRMmmDpUa9eulQsvvFD69OkjJ554onz33XdlHjt79mw5+eSTpXfv3nLBBReY+yMyXH755XLLLbcErv/xxx9y5plnmro6/fTTZdGiRWXu/8EHH8gxxxxjbr/mmmtkx44dNpQawYqLi+XOO++Ugw8+WAYPHiwPPfSQ+P1+cxv1GX02btwoV1xxhfTr10+OOuooef755wO3UZ/R853U//N+/PHHwLb9/X9SPwf6f2/fvn3Nb6eCgoI6ez2xLlR9zp8/X84++2xTH8cdd5zMmDGjzGOoz+ipS0tubq6pk7feeqvKf1f1/9oHH3xQDj30UPP7eNKkSeLz+erktSA0QncI+sHUHwzTpk2TO+64Qx5//HH55JNP7C4WQtA/Khq49T+F6dOny3//+1/58ssv5eGHHza36R+hxo0by5tvvikjRoyQa6+9VjZs2GAeq+d6+6hRo+SNN96Qhg0bytVXXx0IBbDPhx9+KF9//XXgen5+vgnheiBM/9PRHwP641+3q99++01uvfVWU7+vvfaa5OTkyNixY218BVD33HOP+YH37LPPyn/+8x95/fXXTf1Qn9Hp73//u6Smppo60x/j+nf2888/pz6jhB6MvvHGG2Xp0qWBbfv7/+Snn35qfiPddddd5jfTggUL5IEHHrDtNcZ6fW7dulUuu+wyE7Lefvtt8/vo7rvvlq+++srcTn1GT10G0zrYsmVLmW2V/V197rnnTCjX+nz00Ufl/fffN9tgIz/KyMvL8/fs2dP/ww8/BLY98cQT/vPOO8/WciG0ZcuW+bt06eLfunVrYNv777/vHzp0qH/27Nn+Pn36mDq1jBkzxv/oo4+ayw8//HCZes3Pz/f37du3TN2j7mVlZfkPP/xw/+mnn+6/+eabzbYZM2b4jzrqKL/P5zPX9fzYY4/1v/nmm+b6v/71r8B91YYNG/wHHnigf82aNTa9Cmg9du/e3f/jjz8Gtk2ZMsV/yy23UJ9RKDs72/ytXbJkSWDbtdde67/zzjupzyiwdOlS/6mnnuo/5ZRTTD1a/8/t7/+T5557buC+6ueff/b36tXL3A91X58vv/yy//jjjy9z39tuu81/4403msvUZ/TUZXAd6N/TIUOGBP6mVuXv6hFHHFHm/u+8847/yCOPrJPXhNBo6S5n8eLF4vF4zJF6S//+/c3RPrplRJ4mTZrIM888Y47SB9u1a5eps+7du5uWmeC61K5XSm/XlhlLSkqK9OjRI3A77DFx4kTT2tKpU6fANq0rrTuXy2Wu67l2cd1XXTZv3lxatGhhtsMec+fOlbS0NNPiYtHWUB3+QX1Gn+TkZPM3UluyS0pKZMWKFTJv3jzp1q0b9RkFfvrpJxk4cKBpEQu2P/9Per1eWbhwYZnbtYu6fj70txTqvj6tIXbl6W8iRX1GT11aXc5vu+02uf322yUxMbHMbRX9XdVhlzocSId2BX+v169fv1eLOepOfB3uKypo15zMzMwyH24NdNr1Izs723TFQeTIyMgw/8lY9MDISy+9ZMawaF02bdq0zP0bNWokmzZtMpcrux11b86cOfLLL7+YblDjx48PbNe6Cg7hVl1ZXbH0PxHqMrLoOMGWLVvKO++8I5MnTzY/3LRL41VXXUV9RqGkpCTzw0+7qr7wwgvmB7rWp47jnjlzJvUZ4c4999yQ2/fn/0ntzqq/jYJvj4+PlwYNGlC3NtVnq1atzMmyfft2M1zruuuuM9epz+ipS6X/d+pBMZ1fqryK/q5qPavg263GKb29/ONQNwjd5ejY4PJHk6zresQJkU3HveiEPjpWSScDCVWXVj3uq66pZ3vof/Y6h4L+sNdWtWCV1VVhYSF1GWF0PO/q1avl1VdfNS0v+iNA61ZbVqjP6LR8+XI58sgj5aKLLjKBWgP4oEGDqM8oVlndVXS71qt1fV+Ph320fjRsa9j629/+ZrZRn9Fj2bJl5v/P9957L+TtFf1dDVWXZBn7EbpDHM0v/4G0rpcPAoi8wK0Tf+hkal26dDF1qb0TytelVY/7qmttPUfd08k+DjrooDI9Fyz7qqvK6lIDHuyhLSTapVEnUNMWb2sSn1deeUXatm1LfUZhLxQ9mKkTHGo99ezZ03RhfPLJJ6V169bUZ5Tan/8n9TbrevnbqVt75eXlmQnSVq1aJS+//HKgPqjP6KAT2/373/82E+GVHz5pqejvanDALl+v1KV9GNNdTrNmzSQrK8uM67ZoC43+B0QYi1za4qKzMmrw1iUyrLrctm1bmfvpdatbzb5u13HiqHvaBe6LL74w8ynoSbuY60kvU5fRR997/c/eCtyqffv2ZpwZ9Rl9dEUPPVgSfPBZuz3qgRTqM3rtT91pt2P9jgffrr+dNMRTt/bRg52XXHKJ6Y2iDRHt2rUL3EZ9Rgf9u/rrr7+aOW6s30S6TXsDXnrppZXWpd6mrG7mwZepS/sQusvRSWG0hSZ4Mi2dEEiP6rvdvF2R2kKqXXB0DeCTTjopsF3XLfz9998D3WysutTt1u163aLdrrRrunU76taLL75oQraOAdaTrgOsJ72sdaL/AVnLmui5TuK0r7rUYKcn6tI++t7rkIGVK1cGtunkWxrCqc/ooyFMhwsEt6xofer4Ueozeu3P/5P6m0h/GwXfrr+d9DdU165d6/iVwJrXRpeQWrdunfk/tXPnzmVupz6jg4bmzz77LPB7SE/6N1hbvu+9995K/67q43VSteDb9bJuYzy3fUiR5Wi3i5EjR5pJnHQNPG15mzp1qlxwwQV2Fw37GGP4v//9z6xLqTMz6pE866SzJutsjrpuoR7xfeqpp0ydnnHGGeaxp59+uvlhqNv1dr2f/oDUWSRR9zSMaUuadapXr5456eXjjz/eTPKi/9noOCc91x8LJ5xwgnnsOeecI++++67MmDHDzLJ60003ybBhw0y3V9ijQ4cOpg70e6V18u2335rvmtYV9Rl99ABYQkKC6fKoB1JmzZplJvk5//zzqc8otr//T+okUM8++6z5raSP099OZ511Fl1YbaJDQH788Ue55557TO9M6/eQNYSA+owOeqAj+PeQnnSbTpRmtWJX9ndVb3/wwQfN50FPOtSLLGOzfSwlFtN0PcKbbrrJrF2p6z0/99xzdhcJ+6Dr/uq6hqFOatWqVf7Ro0f7DzroIP9JJ53k//7778s8/quvvvIPHz7crEOpa5Oybmzk0PUng9egXLBggX/kyJH+nj17+s844wz/77//Xub+uh6lrkup39trrrnGv2PHDhtKjWA5OTlmLVGtk0GDBvkfe+yxwFrO1Gd0rid74YUX+vv16+c/5phjzP+N1Gf0Kb8W8P7+P6n/D+v3u3///v6xY8f6CwsL6+y1oGx9XnzxxSF/DwWvzU19Rq5Q63RbdI3t4HW3K/u76vF4/Pfdd59/wIAB/oEDB/ofeOCBwN9r2MOl/9gd/AEAAAAAcCK6lwMAAAAAECaEbgAAAAAAwoTQDQAAAABAmBC6AQAAAAAIE0I3AAAAAABhQugGAAAAACBMCN0AAAAAAIQJoRsAAAAAgDAhdAMAosJRRx0lBx54YODUo0cPOf744+X5558XJ/r+++/l3HPPlb59+5rX27VrV3n44YfFib788ksZO3as+P1+mTBhgsyYMSPs+4yl9xcAYK94m/cPAECVjRs3Tk488URz2ePxyA8//CC33nqrNGjQQEaOHClO8eeff8qNN95oXm/v3r0lLS1NUlJSpF69euJEQ4cOlSlTppgDKR07dpTrrrsurPuLtfcXAGAvQjcAIGqkp6dLkyZNAtdPO+00+eCDD+Szzz5zVOh+44035OKLL5YRI0ZILEhISJBXXnlFtm3bJo0aNRK3O7wd8WLt/QUA2Ivu5QCAqBYfH29Cm5o5c6YJ3z179pQBAwaY1sy8vDxz2/bt2+WSSy6RPn36yPDhw2XWrFlm+7p160z3Yr2/tp5bXnzxRbP9scceC2x79dVXTTd37ZJ8/vnny5IlSwK36Xbt6n7KKaeYfVx++eWydevWfZb7119/lXPOOcfcVx+roTO4JbZFixZy6aWXSq9evUx5P/74Y3Pbk08+afYRbOrUqaar9FtvvWWeK5iW03oNu3btMt24Bw0aJAcddJDpnv/FF18E7quv98cffzSX165dK5dddpl5rUcccYRMnz49cD99Pn3eql7/66+/zHV9Lccdd1zI53K5XOaAyrx580w59LWEEjzEQFupL7zwQlO3ofa7r/ehovdX+Xw+eeaZZ+Too482t5eva923doE/5phjzPvzz3/+M/A5C66DzZs3m9ert+v7qo+z5ObmysCBA+WWW24JWV4AgHMQugEAUamkpMS0cOvYXA1Ha9askRtuuMGETw1QOj539uzZ8vrrr5v733vvvWbM8DvvvGPCrgah4uLiMuFdA59FnzspKSlwXUP6448/Lrfddpu8/fbb0r9/f7ngggtk586dgftoqNMg99prr0lBQcE+u0kvX75cxowZIwcffLAJaXq/iRMnyueff25u37Fjh9x3333SrVs3U15tlf3Xv/4lixYtkpNOOsmE2JUrVwaeT1+vbq+Mvgf6OA3p2kNADzRo9/zg90Hp+6TvZU5OjjkYcPvtt8uDDz4oX331lVRXYWGhCe/6fr333nty8803y//+9z/zukLR/VRG3+dvv/3WlE2Drb6e6qjo/VVPPPGEeU7tfq513bJlS1Ov+fn5ged45JFH5N///re88MILpj70PSpv8uTJJliHuu3pp5+W7OzsapUbABCdCN0AgKhxxx13mJZFPWkLpAY4Da+nnnqqaZ3UEHTWWWdJq1atzDjhwYMHy9KlS81j9TYNSu3atZNmzZqJ1+s1J8thhx0mX3/9dSCULVu2zIwxtmjL5xVXXCFHHnmkeY6///3vJoxpkLScfvrppsuytmhqqNPWbA1k5emBgO7du5uW+A4dOphu8uedd57Zh3VAoXnz5ubAgN5+9tlnm7Hszz33nLRp08a89k8++cTcd/369fLHH3+YVuuMjIxAi2soGvLvuusuEzb1NWjY1OBntRRb9LX//vvvJnTqBGN6UENflx5MqK7333/fdBnX90v3qa3AV155pQmr5Wmru4Z0bYWuSP369aVp06bSunVrSUxMNNero6L3Vw84vPTSS+agg75uHWN+9913S1xcXJm61gMJw4YNM70q9MCFHvjQ1mvLqlWrzP31M1O+fHqgQN9L/XwCAJyPMd0AgKhx/fXXm67ASluhtTuyhiGlgU4DmHa/1qCtJw2P1rjdhg0bmnMN49rtW7sl6+RZFg1Q2jKpLZ4a/vS6dj0Pbp1+4IEH5KGHHgpsKyoqMuHK0q9fv8BlDYQ6wZs+rkuXLmVeh27T4BxMDyRo93WlryP4uZTe35rVW1u1tQX2qquuMmHvkEMOMcFWw762vGvQ1S7o2kU8Kysr8Bza9V5fm4b+FStWmGCtgg8+aJi0BHeH7tSpk/z8889SXbqfxYsXm9dn0f1Z9Ra8Td9b7f6uB1cqomXUx2tA10nQRo0aFbjtl19+MfvSz0f79u3l6quvNgdUglX0/uoBCD0QoV3XLTp8Qbvja71Zgh+vt2n5rd4HGzZsMAdB/u///s8cmClPW9L14FBFww8AAM5B6AYARA0Nlm3btg15mwY77TauLanabVpD9bRp0/a638svv2zG144fP960cFrjwTV06UReGpi0a/no0aPLdFvWUKUtvzoeOpiGvuAu6sH0MaEmBQvutm7Rlnor/OrrtMoV3Dqr91HaKqvd0VevXi2ffvqpCXBW0NfWWw2uOlY4OTk58Bh10003mdZ3PRCh75UetPjb3/5WZj/33HOPpKamyjXXXFNmjLsqX6aq0OfQ9yxUF+tg2s1eW6/LB+RQtIwairX7u7ZC/+c//zFLjVkBWLuoayDXngsauj/66KMyj6/o/Q1VN0rrJvi9DH68td2qa30dul8tl4Zv7XkRfBBC5x7Qngra3R8A4Hx0LwcAOMK7775ruk9r0NFx3RqiNZRqd2ENVBqYteVau2efeeaZpiu2Tqhl0Ym8tBVcxzovXLhQhgwZUub5tdV006ZNJvRbJ20Znz9/fpngb9F9a3fj4Nbi4OdasGBBmW0ahnW70m7t5W/XVmbt6m2FOm3dfvPNN80+rdZ/qxVYDyroGPSffvrJhFBrEjV9bf/9739Nj4Fjjz02MB5d3yOLdr3X8df6fgRPHqbd5PW9qy59TdoCrMHTet/0PdOJ6oJ7DGjrr7YMV4WWUZ9Hu3affPLJZepADzTobfq+62R2egBBu98Hq+j91RnyGzduXOY59fOjvQKs+lHBnx0dC64h3LpdD77oAR092FB+jLrONaDjw3U/AIDYQOgGADiCduXWkPjbb7+ZkHf//feb8KyThGkg0tCordva0qjdiDVwlg/E2qVcu6dr4NYuyMEuuugi03KuE2/ppG3a1Vy7duuYX4uOU9ZWTA3CGvL1ebTbe3l6UEBDm3an1rJqV3FtgdfWdaXjuzUo6hh0La/Oiv7NN9+YidssGjZ1u+6j/JhhXW9ag2lwF259PdqdXlvx9eCDTkSm47tV+YnUMjMzTSjX16jvqb5OHZ8c3CquQVS7R+tJJxgLdV3Hl+t4e2111pZu7Z6trc/awqutzRYNwNpd2zpAUBmtO92PDh/Q5wvu/WCVQ7vW6yzpeuCjc+fOZR5f2furvSQeffRRc+BCy6yT5+mBAWuNeKW360ENLbu2vOu4/PLrfOsEefp+Bx+80IBu1TMAIDbQvRwA4Ai6rJMGKQ1M2kVYW721i/SHH35obtcWRw1POv5Xx3drt2QNzMHjtrWlW8OVBs7yNHBp93MNW3quY5w1oAeHag1eGqS1i7ous3XnnXeGLKtOFDZlyhSZNGmS6cKu17U7uE7EZnUT1xm+tQv5s88+KwcccIAJwNqya9HWbT2IEBwEK6KhW59Dn1NbmbXlWceEa8urHgAIPnigdFy1ThB2xhlnmBD+j3/8o0zrv7bM6/sVrPx1fW0aPHWmbp1YTseU68ERDZ06wZhFD4ro81eVNSu81rO+JzpJXvly6QEHfY0a8HWytGCVvb86wZz2DNDPi57rGHF9z6x5AZS+Fq0z7eKuY+z1vSpPw74uGRa8lJn2Mih/QAcA4Gwuf3CfMgAAUCM6lvzaa68tM6lXOOkEbhr8dMm08i2skcBaE3tfy6ZFM+0hob0adDkwAAAqQ0s3AABRRFtev/vuO7PklLawRmLgVjqWGgAAELoBAIg62p1aJzXTLtGR6pJLLrG7CAAARAS6lwMAAAAAECbMXg4AAAAAQJgQugEAAAAACBNCNwAAAAAAYULoBgAAAAAgTAjdAAAAAACECaEbAAAAAIAwIXQDAAAAABAmhG4AAAAAACQ8/h+d93cMx4La7gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Финальный оставшийся датасет сохранен в remaining_dataset_final.csv\n",
            "Размер финального датасета: 2543 сообщений\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "NER-модель обучена успешно!\n",
            "\n",
            "=== Начинаем обучение RE-модели ===\n",
            "\n",
            "[RE] Этап 1: Подготовка данных\n",
            "[RE] Используется тренировочный json: PollenNER_TRAIN_1500.json\n",
            "\n",
            "[RE] Этап 2: Подготовка датасетов\n",
            "\n",
            "[RE] Статистика распределения классов:\n",
            "Train (после сэмплирования): Counter({'has_symptom': 1460, 'no_relation': 1176, 'has_medicine': 82})\n",
            "Test: Counter({'has_symptom': 56, 'no_relation': 41, 'has_medicine': 4})\n",
            "\n",
            "[RE] Этап 3: Токенизация\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69a2ffebedb14d4f94ca5238e379a550",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2718 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63f9378721db43b6922e2881cf793bae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/101 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[RE] Этап 4: Обучение модели\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1700' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1700/1700 23:29, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.640424</td>\n",
              "      <td>0.544935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.533800</td>\n",
              "      <td>0.503452</td>\n",
              "      <td>0.809627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.395200</td>\n",
              "      <td>0.435498</td>\n",
              "      <td>0.857122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.395200</td>\n",
              "      <td>0.402472</td>\n",
              "      <td>0.935938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.235700</td>\n",
              "      <td>0.473528</td>\n",
              "      <td>0.929588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RE-модель: Macro F1 = 0.9359\n",
            "RE-модель сохранена в models/pollen_re_model\n",
            "\n",
            "[RE] Результаты обучения:\n",
            "Macro F1 на тесте: 0.9359\n",
            "\n",
            "[RE] Этап 5: Детальный анализ результатов\n",
            "\n",
            "[RE] Подробный отчет по целевым классам:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " has_symptom     0.8983    0.9464    0.9217        56\n",
            "has_medicine     1.0000    1.0000    1.0000         4\n",
            "\n",
            "   micro avg     0.9048    0.9500    0.9268        60\n",
            "   macro avg     0.9492    0.9732    0.9609        60\n",
            "weighted avg     0.9051    0.9500    0.9270        60\n",
            "\n",
            "\n",
            "=== Финальное тестирование на тестовых примерах ===\n",
            "\n",
            "Тестовый пример 1:\n",
            "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
            "\n",
            "Результаты анализа:\n",
            "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
            "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
            "SYMPTOM: глаза потекли, нос потекли, глаза чешутся, уши чешутся, уши течет, нос течет, глаза слезятся\n",
            "ALLERGEN: пыльцу, березы, ольхи\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    Основной блок выполнения программы.\n",
        "    Последовательно запускаем все этапы обработки данных и обучения моделей.\n",
        "    \"\"\"\n",
        "    # ===============================\n",
        "    # 1. Обучение NER-модели\n",
        "    # ===============================\n",
        "    print(\"\\n=== Начинаем обучение NER-модели ===\")\n",
        "    # Запускаем цикл обучения NER с активным обучением\n",
        "    last_ner_model = run_cycle('dataset_v1.csv', sizes)\n",
        "    print(\"\\nNER-модель обучена успешно!\")\n",
        "\n",
        "    # ===============================\n",
        "    # 2. Обучение RE-модели\n",
        "    # ===============================\n",
        "    print(\"\\n=== Начинаем обучение RE-модели ===\")\n",
        "\n",
        "    # 2.1. Подготовка данных\n",
        "    print('\\n[RE] Этап 1: Подготовка данных')\n",
        "    # Ищем последний существующий TRAIN json для обучения\n",
        "    last_train_json = None\n",
        "    for size in reversed(sizes):\n",
        "        candidate = f'PollenNER_TRAIN_{size}.json'\n",
        "        if os.path.exists(candidate):\n",
        "            last_train_json = candidate\n",
        "            break\n",
        "    if last_train_json is None:\n",
        "        raise FileNotFoundError('Не найден ни один TRAIN json для RE!')\n",
        "    print(f'[RE] Используется тренировочный json: {last_train_json}')\n",
        "\n",
        "    # Парсим разметку из JSON файлов\n",
        "    train_parsed = parse_labelstudio_json(last_train_json)\n",
        "    test_parsed = parse_labelstudio_json('PollenNER_TEST.json')\n",
        "\n",
        "    # 2.2. Подготовка датасетов\n",
        "    print('\\n[RE] Этап 2: Подготовка датасетов')\n",
        "    # Балансируем классы и применяем oversampling для has_medicine\n",
        "    re_train, rel_labels = prepare_re_dataset(\n",
        "        train_parsed,\n",
        "        relation_labels=RE_RELATION_LABELS,\n",
        "        max_no_relation_ratio=1,\n",
        "        oversample_medicine=True\n",
        "    )\n",
        "    re_test, _ = prepare_re_dataset(\n",
        "        test_parsed,\n",
        "        relation_labels=RE_RELATION_LABELS + ['no_relation'],\n",
        "        max_no_relation_ratio=1,\n",
        "        oversample_medicine=False\n",
        "    )\n",
        "\n",
        "    # Выводим статистику распределения классов\n",
        "    print('\\n[RE] Статистика распределения классов:')\n",
        "    print('Train (после сэмплирования):', Counter([ex['relation'] for ex in re_train]))\n",
        "    print('Test:', Counter([ex['relation'] for ex in re_test]))\n",
        "\n",
        "    # Создаем словари для преобразования меток\n",
        "    rel_label2id = {l: i for i, l in enumerate(rel_labels)}\n",
        "    rel_id2label = {i: l for l, i in rel_label2id.items()}\n",
        "\n",
        "    # 2.3. Токенизация\n",
        "    print('\\n[RE] Этап 3: Токенизация')\n",
        "    re_train_ds = prepare_hf_re_dataset(re_train,\n",
        "                                        TOKENIZER,\n",
        "                                        rel_label2id)\n",
        "    re_test_ds = prepare_hf_re_dataset(re_test,\n",
        "                                       TOKENIZER,\n",
        "                                       rel_label2id)\n",
        "\n",
        "    # 2.4. Обучение модели\n",
        "    print('\\n[RE] Этап 4: Обучение модели')\n",
        "    trainer_re, eval_results_re = train_and_eval_re_model(\n",
        "        train_ds=re_train_ds,\n",
        "        test_ds=re_test_ds,\n",
        "        num_labels=len(rel_labels),\n",
        "        label2id=rel_label2id,\n",
        "        id2label=rel_id2label,\n",
        "        tokenizer=TOKENIZER,\n",
        "        hf_token=HF_TOKEN,\n",
        "        output_dir='models/pollen_re_model',\n",
        "        epochs=5\n",
        "    )\n",
        "    print(f\"\\n[RE] Результаты обучения:\")\n",
        "    print(f\"Macro F1 на тесте: {eval_results_re['eval_f1']:.4f}\")\n",
        "\n",
        "    # 2.5. Детальный анализ результатов\n",
        "    print('\\n[RE] Этап 5: Детальный анализ результатов')\n",
        "    # Получаем предсказания для тестового набора\n",
        "    re_test_preds = trainer_re.predict(re_test_ds)\n",
        "    y_true = re_test_preds.label_ids\n",
        "    y_pred = re_test_preds.predictions.argmax(-1)\n",
        "\n",
        "    # Преобразуем индексы в метки\n",
        "    y_true_labels = [rel_id2label[i] for i in y_true]\n",
        "    y_pred_labels = [rel_id2label[i] for i in y_pred]\n",
        "\n",
        "    # Выводим подробный отчет по целевым классам\n",
        "    target_labels = [l for l in rel_labels if l != 'no_relation']\n",
        "    print(\"\\n[RE] Подробный отчет по целевым классам:\")\n",
        "    print(classification_report(y_true_labels,\n",
        "                                y_pred_labels,\n",
        "                                labels=target_labels,\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 3. Финальное тестирование\n",
        "    # ===============================\n",
        "    print('\\n=== Финальное тестирование на тестовых примерах ===')\n",
        "    for i, text in enumerate(TEST_EXAMPLES, 1):\n",
        "        print(f'\\nТестовый пример {i}:')\n",
        "        print(f'Текст: {text}')\n",
        "\n",
        "        # Извлекаем сущности и отношения\n",
        "        entities, relations = infer_ner_re_on_text(text,\n",
        "                                                   last_ner_model,\n",
        "                                                   trainer_re.model,\n",
        "                                                   TOKENIZER,\n",
        "                                                   ID2LABEL,\n",
        "                                                   rel_id2label)\n",
        "\n",
        "        # Собираем симптомы из отношений has_symptom\n",
        "        symptoms_from_relations = []\n",
        "        for rel in relations:\n",
        "            if rel['relation'] == 'has_symptom':\n",
        "                head = rel['head']['text']\n",
        "                tail = rel['tail']['text']\n",
        "                symptoms_from_relations.append(f'{head} {tail}')\n",
        "\n",
        "        # Группируем сущности по типу (исключая BODY_PART)\n",
        "        ent_by_type = {label: [] for label in LABELS if label != 'BODY_PART'}\n",
        "        for ent in entities:\n",
        "            if ent['label'] in ent_by_type:\n",
        "                if ent['label'] != 'SYMPTOM':\n",
        "                    # Для остальных сущностей используем все найденные\n",
        "                    ent_by_type[ent['label']].append(ent['text'])\n",
        "\n",
        "        # Для SYMPTOM записываем данные из has_symptom\n",
        "        for symptom in symptoms_from_relations:\n",
        "            ent_by_type['SYMPTOM'].append(symptom)\n",
        "\n",
        "        # Выводим результаты\n",
        "        print('\\nРезультаты анализа:')\n",
        "        for label in ent_by_type.keys():\n",
        "            if ent_by_type[label]:\n",
        "                ents_str = ', '.join(ent_by_type[label])\n",
        "                print(f'{label}: {ents_str}')\n",
        "            else:\n",
        "                print(f'{label}: не найдено')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiv5i_R4vFd7"
      },
      "source": [
        "## Вывод\n",
        "\n",
        "Проведённые эксперименты показали, что внедрение отдельного модуля для оценки отношений (RE) существенно повысило точность выделения и классификации симптомов, устранив ложные срабатывания на упоминания частей тела. Уже с 500 размеченными сообщениями наблюдался заметный рост F1‑метрики, а к 1450 примерам модель достигла стабильного уровня в 0.9, демонстрируя зрелость и надёжность алгоритма.\n",
        "\n",
        "Интеграция NER и RE модулей в единую NLP‑конвейерную архитектуру позволяет в реальном времени автоматически обрабатывать пользовательские сообщения Пыльца Club, извлекая топонимы, симптомы, препараты и аллергены и устанавливая между ними семантические связи.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:project]",
      "language": "python",
      "name": "conda-env-project-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}