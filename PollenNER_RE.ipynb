{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXtM17W9kr52"
   },
   "source": [
    "# **PollenNER** — извлечения сущностей для анализа сообщений Пыльца Club\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Заказчик\n",
    "\n",
    "[Пыльца Club](https://pollen.club/) — краудсорсинговый сервис для людей с пыльцевой аллергией. Платформа объединяет тысячи пользователей, информируя их о текущем уровне аллергенов в воздухе и рисках для здоровья. Данные о концентрации пыльцевых частиц и прогнозах доступны через веб-интерфейс и мобильное приложение, что помогает планировать активность и корректировать терапию.\n",
    "\n",
    "\n",
    "\n",
    "## Исполнитель\n",
    "\n",
    "\n",
    "\n",
    "[Мельник Даниил](https://github.com/DanielNRU/)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Описание проекта\n",
    "\n",
    "\n",
    "\n",
    "Цель — создать и обучить NLP-систему, способную извлекать из пользовательских сообщений ключевую информацию о:\n",
    "\n",
    "\n",
    "\n",
    "* **Топонимах**\n",
    "\n",
    "* **Симптомах**\n",
    "\n",
    "* **Медицинских препаратах**\n",
    "\n",
    "* **Аллергенах**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Задачи\n",
    "\n",
    "\n",
    "\n",
    "1. **Подготовка и разметка данных**\n",
    "\n",
    "\n",
    "\n",
    " * Загрузка исторических сообщений пользователей\n",
    "\n",
    " * Очистка и нормализация текста\n",
    "\n",
    " * Аннотирование сущностей в Label Studio\n",
    "\n",
    " * Формирование тренировочной и тестовой выборок\n",
    "\n",
    "\n",
    "\n",
    "2. **Разработка NER-модуля**\n",
    "\n",
    "\n",
    "\n",
    " * Использование предобученной модели **DeepPavlov/rubert-base-cased**\n",
    "\n",
    " * Активное обучение для оптимального расширения аннотаций\n",
    "\n",
    " * Оценка неопределённости для отбора самых информативных примеров\n",
    "\n",
    " * PEFT и LoRA для экономии ресурсов при тонкой настройке\n",
    "\n",
    "\n",
    "\n",
    "3. **Построение RE-модуля**\n",
    "\n",
    "\n",
    "\n",
    " * Модель для классификации отношений между сущностями\n",
    "\n",
    " * Балансировка классов, оптимизация метрик качества\n",
    "\n",
    " * Интеграция в единый пайплайн с NER-модулем\n",
    "\n",
    "\n",
    "\n",
    "4. **Тестирование и внедрение**\n",
    "\n",
    "\n",
    "\n",
    " * Валидация на тестовой выборке\n",
    "\n",
    " * Анализ ошибок и доработка сложных кейсов\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Технологический стек\n",
    "\n",
    "\n",
    "\n",
    "* **Языки и библиотеки**: Python, Pandas, NumPy, scikit-learn\n",
    "\n",
    "* **ML-фреймворки**: PyTorch, Transformers (Hugging Face), PEFT (LoRA)\n",
    "\n",
    "* **Разметка**: Label Studio\n",
    "\n",
    "* **Подходы**: Active Learning, Parameter-Efficient Fine-Tuning\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWRORxG3uHU8"
   },
   "source": [
    "## Импорты библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P7jsWDDntzgf"
   },
   "outputs": [],
   "source": [
    "# Стандартные библиотеки Python\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Научные вычисления и обработка данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import multiprocessing\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Hugging Face и трансформеры\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Внешние API и сервисы\n",
    "import requests\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "from dotenv import load_dotenv\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9mQVwTSuXw8"
   },
   "source": [
    "## Настройка окружения и константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7fT3StR0u1NF"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "RANDOM_STATE = 42\n",
    "LABEL_CONFIG = '''<View>\n",
    "  <Labels name=\"label\" toName=\"text\">\n",
    "    <Label value=\"TOPONYM\" background=\"#ff0d00\"/>\n",
    "    <Label value=\"MEDICINE\" background=\"#022bf7\"/>\n",
    "    <Label value=\"SYMPTOM\" background=\"#ffd500\"/>\n",
    "    <Label value=\"ALLERGEN\" background=\"#00ff55\"/>\n",
    "    <Label value=\"BODY_PART\" background=\"#ff00ff\"/>\n",
    "  </Labels>\n",
    "\n",
    "  <Relations>\n",
    "    <Relation value=\"has_symptom\" />\n",
    "    <Relation value=\"has_medicine\" />\n",
    "  </Relations>\n",
    "\n",
    "  <Text name=\"text\" value=\"$text\" granularity=\"word\"/>\n",
    "</View>'''\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UtqVftZ-ugG3"
   },
   "outputs": [],
   "source": [
    "n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = str(n_jobs)\n",
    "\n",
    "# Подавляем лишние предупреждения, чтобы не засорять вывод.\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', message='No label_names provided for model class')\n",
    "warnings.filterwarnings('ignore', message='Could not find the number of physical cores')\n",
    "\n",
    "# Загружаем переменные окружения из .env файла (токены, URL и т.д.)\n",
    "# Для начинающих: .env файл - это файл с конфиденциальными данными (токены, пароли),\n",
    "# которые не должны попадать в репозиторий кода\n",
    "load_dotenv()\n",
    "LS_TOKEN = os.getenv('LS_LEGACY_TOKEN')  # Токен для Label Studio\n",
    "LS_URL = os.getenv('LS_URL', 'http://localhost:8080')  # URL сервера Label Studio\n",
    "HF_TOKEN = os.getenv('HUGGINGFACE_HUB_TOKEN')  # Токен для HuggingFace Hub\n",
    "assert LS_TOKEN and HF_TOKEN, 'Установите LS_LEGACY_TOKEN и HUGGINGFACE_HUB_TOKEN в .env'\n",
    "\n",
    "# Инициализация клиента для работы с Label Studio через API\n",
    "ls = LabelStudio(base_url=LS_URL, api_key=LS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NdGm9zH4vjwF"
   },
   "outputs": [],
   "source": [
    "## Конфигурация меток и токенизатора\n",
    "# Список всех сущностей, которые мы хотим распознавать.\n",
    "LABELS = ['TOPONYM', 'MEDICINE', 'SYMPTOM', 'ALLERGEN', 'BODY_PART']\n",
    "# Словари для преобразования между строковыми и числовыми метками.\n",
    "LABEL2ID = {'O': 0, **{f'B-{l}': i*2+1 for i, l in enumerate(LABELS)}, **{f'I-{l}': i*2+2 for i, l in enumerate(LABELS)}}\n",
    "ID2LABEL = {v: k for k, v in LABEL2ID.items()}\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "\n",
    "# Список размеров обучающих выборок для активного обучения.\n",
    "sizes = list(range(50, 2001, 50))\n",
    "\n",
    "# Список допустимых отношений между сущностями для задачи RE.\n",
    "RE_RELATION_LABELS = ['has_symptom', 'has_medicine']\n",
    "\n",
    "# Тестовый пример\n",
    "TEST_EXAMPLES = [\n",
    "    \"В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\",\n",
    "]\n",
    "\n",
    "# Определяем функцию для вычисления метрик\n",
    "metric = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K6E1Sofu8xn"
   },
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "J06OxELJvT0n"
   },
   "outputs": [],
   "source": [
    "def bulk_import_via_http(project_id: int,\n",
    "                         tasks_list: List[Dict],\n",
    "                         ls_url: str,\n",
    "                         ls_token: str,\n",
    "                         chunk_size: int = 100,\n",
    "                         max_retries: int = 3):\n",
    "    \"\"\"\n",
    "    Импорт списка задач в Label Studio через HTTP-эндпоинт /import.\n",
    "\n",
    "    Параметры:\n",
    "    - project_id: ID проекта в Label Studio\n",
    "    - tasks_list: список задач для импорта\n",
    "    - ls_url: URL сервера Label Studio\n",
    "    - ls_token: токен доступа\n",
    "    - chunk_size: размер чанка для импорта\n",
    "    - max_retries: максимальное количество попыток при ошибке\n",
    "\n",
    "    Процесс:\n",
    "    1. Разбивает список задач на чанки\n",
    "    2. Отправляет каждый чанк через API\n",
    "    3. При ошибке делает повторные попытки с экспоненциальной задержкой\n",
    "    \"\"\"\n",
    "    url = f\"{ls_url}/api/projects/{project_id}/import\"\n",
    "    headers = {'Authorization': f'Token {ls_token}', 'Content-Type': 'application/json'}\n",
    "    total = len(tasks_list)\n",
    "\n",
    "    # Проходим по списку чанков\n",
    "    for i in range(0, total, chunk_size):\n",
    "        chunk = tasks_list[i:i + chunk_size]\n",
    "        start, end = i + 1, min(i + chunk_size, total)\n",
    "\n",
    "        # Пытаемся отправить с ретрай\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            resp = requests.post(url, headers=headers, json=chunk)\n",
    "            if resp.ok:\n",
    "                print(f\"Импортировано задач {start}–{end} из {total}\")\n",
    "                break\n",
    "            print(f\"Ошибка импорта {start}–{end}: {resp.status_code}. Попытка {attempt}/{max_retries}\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(2 ** attempt)  # Экспоненциальная задержка\n",
    "            else:\n",
    "                print(f\"Не удалось импортировать {start}–{end} после {max_retries} попыток.\")\n",
    "\n",
    "def calculate_uncertainty_scores(model, texts, tokenizer, batch_size=8):\n",
    "    \"\"\"\n",
    "    Рассчитывает оценки неопределенности для каждого текста на основе энтропии предсказаний модели.\n",
    "\n",
    "    Параметры:\n",
    "    - model: модель для предсказаний\n",
    "    - texts: список текстов для оценки\n",
    "    - tokenizer: токенизатор для обработки текстов\n",
    "    - batch_size: размер батча для обработки\n",
    "\n",
    "    Возвращает:\n",
    "    - список оценок неопределенности для каждого текста\n",
    "    \"\"\"\n",
    "    uncertainties = []\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Обработка текстов батчами\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts,\n",
    "                           padding=True,\n",
    "                           truncation=True,\n",
    "                           max_length=512,\n",
    "                           return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # Вычисляем вероятности через softmax\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            # Рассчитываем энтропию как меру неопределенности\n",
    "            entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=-1)\n",
    "            # Усредняем энтропию по всем токенам в тексте\n",
    "            avg_entropy = entropy.mean(dim=1)\n",
    "            uncertainties.extend(avg_entropy.cpu().numpy())\n",
    "\n",
    "        # Очищаем память GPU\n",
    "        del outputs, logits, probs, entropy, avg_entropy\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return uncertainties\n",
    "\n",
    "def retry_on_error(func, max_retries=5, delay=2):\n",
    "    \"\"\"\n",
    "    Декоратор для повторных попыток выполнения функции при ошибках.\n",
    "\n",
    "    Параметры:\n",
    "    - func: функция для выполнения\n",
    "    - max_retries: максимальное количество попыток\n",
    "    - delay: начальная задержка между попытками\n",
    "\n",
    "    Возвращает:\n",
    "    - результат выполнения функции или None при неудаче\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise e\n",
    "                print(f\"Ошибка при выполнении {func.__name__}: {str(e)}. Попытка {attempt + 1}/{max_retries}\")\n",
    "                time.sleep(delay * (2 ** attempt))  # Экспоненциальная задержка\n",
    "        return None\n",
    "    return wrapper\n",
    "\n",
    "@retry_on_error\n",
    "def create_task(ls_client, project_id, text, text_id):\n",
    "    \"\"\"\n",
    "    Создание задачи в Label Studio с повторными попытками.\n",
    "    \"\"\"\n",
    "    return ls_client.tasks.create(\n",
    "        project=project_id,\n",
    "        data={\n",
    "            'text': text,\n",
    "            'meta': {\n",
    "                'id': str(text_id)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "@retry_on_error\n",
    "def delete_task(ls_client, task_id):\n",
    "    \"\"\"\n",
    "    Удаление задачи в Label Studio с повторными попытками.\n",
    "    \"\"\"\n",
    "    return ls_client.tasks.delete(task_id)\n",
    "\n",
    "@retry_on_error\n",
    "def get_project_tasks(ls_client, project_id):\n",
    "    \"\"\"\n",
    "    Получение списка задач проекта с повторными попытками.\n",
    "    \"\"\"\n",
    "    return list(ls_client.tasks.list(project=project_id, fields=['data', 'is_labeled']))\n",
    "\n",
    "@retry_on_error\n",
    "def export_project(ls_client, project_id):\n",
    "    \"\"\"\n",
    "    Экспорт проекта с повторными попытками.\n",
    "    \"\"\"\n",
    "    resp = requests.get(\n",
    "        f\"{LS_URL}/api/projects/{project_id}/export?exportType=JSON&download_all_tasks=true\",\n",
    "        headers={'Authorization': f'Token {LS_TOKEN}'}\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "@retry_on_error\n",
    "def get_or_create_project(ls_client, title, label_config):\n",
    "    \"\"\"\n",
    "    Получение существующего проекта или создание нового с повторными попытками.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        proj = next((p for p in ls_client.projects.list() if p.title == title), None)\n",
    "        if not proj:\n",
    "            proj = ls_client.projects.create(title=title, label_config=label_config)\n",
    "            print(f\"Создан проект '{title}' (ID={proj.id})\")\n",
    "        return proj\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при работе с проектом '{title}': {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def ensure_project(texts_with_ids, title, export_path, import_prev_json=None):\n",
    "    \"\"\"\n",
    "    Убеждаемся, что в Label Studio есть проект с нужными текстами.\n",
    "\n",
    "    Параметры:\n",
    "    - texts_with_ids: список кортежей (id, text)\n",
    "    - title: название проекта\n",
    "    - export_path: путь для сохранения экспортированных данных\n",
    "    - import_prev_json: путь к файлу с предыдущими аннотациями\n",
    "\n",
    "    Процесс:\n",
    "    1. Проверяет существование проекта\n",
    "    2. Создает новый или использует существующий\n",
    "    3. Импортирует тексты и аннотации\n",
    "    4. Экспортирует размеченные данные\n",
    "\n",
    "    Возвращает:\n",
    "    - список примеров с аннотациями\n",
    "    \"\"\"\n",
    "    # Находим или создаём проект\n",
    "    proj = get_or_create_project(ls, title, LABEL_CONFIG)\n",
    "\n",
    "    # Получаем таски с повторными попытками\n",
    "    tasks = get_project_tasks(ls, proj.id)\n",
    "\n",
    "    # Если число совпадает\n",
    "    if len(tasks) == len(texts_with_ids):\n",
    "        labeled = sum(t.is_labeled for t in tasks)\n",
    "        if labeled == len(texts_with_ids):\n",
    "            print(f\"Все {len(texts_with_ids)} задач размечены в '{title}', экспорт\")\n",
    "            data = export_project(ls, proj.id)\n",
    "            with open(export_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "            examples = []\n",
    "            # Парсим аннотации в нужный формат\n",
    "            for item in data:\n",
    "                tags = []\n",
    "                for ann in item.get('annotations', []):\n",
    "                    for r in ann.get('result', []):\n",
    "                        v = r.get('value')\n",
    "                        if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                            tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "                examples.append({'text': item['data']['text'], 'tags': tags})\n",
    "            print(f\"Экспортировано {len(examples)} примеров в {export_path}\")\n",
    "            return examples\n",
    "        # Если есть неразмеченные — ждём\n",
    "        print(f\"В '{title}' размечено {labeled}/{len(texts_with_ids)}. Заверши разметку.\")\n",
    "        input(\"Нажми Enter после разметки...\")\n",
    "        return ensure_project(texts_with_ids, title, export_path, import_prev_json)\n",
    "\n",
    "    # Иначе — удаляем и создаём заново\n",
    "    if tasks:\n",
    "        for t in tasks:\n",
    "            delete_task(ls, t.id)\n",
    "        print(f\"Очистили {len(tasks)} задач в '{title}'\")\n",
    "\n",
    "    existing = []\n",
    "    # Импорт предыдущих аннотаций, если есть\n",
    "    if import_prev_json and os.path.exists(import_prev_json):\n",
    "        prev = json.load(open(import_prev_json, 'r', encoding='utf-8'))\n",
    "        bulk_import_via_http(proj.id, prev, LS_URL, LS_TOKEN, chunk_size=100)\n",
    "        existing = [i['data']['text'] for i in prev]\n",
    "\n",
    "    # Создаём новые таски для оставшихся текстов\n",
    "    for text_id, text in texts_with_ids:\n",
    "        if text not in existing:\n",
    "            create_task(ls, proj.id, text, text_id)\n",
    "\n",
    "    print(f\"Созданы {len(texts_with_ids) - len(existing)} новых задач в '{title}'\")\n",
    "    input(f\"Разметь их и нажми Enter...\")\n",
    "\n",
    "    # Экспорт и разбираем аннотации\n",
    "    data = export_project(ls, proj.id)\n",
    "    with open(export_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    examples = []\n",
    "    for item in data:\n",
    "        tags = []\n",
    "        for ann in item.get('annotations', []):\n",
    "            for r in ann.get('result', []):\n",
    "                v = r.get('value')\n",
    "                if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                    tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "        examples.append({'text': item['data']['text'], 'tags': tags})\n",
    "\n",
    "    print(f\"Экспортировано {len(examples)} примеров в {export_path}\")\n",
    "    return examples\n",
    "\n",
    "def align_labels(example):\n",
    "    \"\"\"\n",
    "    Привязывает аннотации к токенам текста.\n",
    "\n",
    "    Параметры:\n",
    "    - example: пример с текстом и аннотациями\n",
    "\n",
    "    Возвращает:\n",
    "    - список ID меток для каждого токена\n",
    "    \"\"\"\n",
    "    tok = TOKENIZER(example['text'], return_offsets_mapping=True, truncation=True, max_length=512)\n",
    "    labels = ['O'] * len(tok['offset_mapping'])\n",
    "\n",
    "    # Для каждой аннотации находим соответствующие токены\n",
    "    for tag in example.get('tags', []):\n",
    "        for i, (s, e) in enumerate(tok['offset_mapping']):\n",
    "            if s >= tag['start'] and e <= tag['end']:\n",
    "                # B- для начала сущности, I- для продолжения\n",
    "                labels[i] = ('B-' if s == tag['start'] else 'I-') + tag['label']\n",
    "\n",
    "    return [LABEL2ID[l] for l in labels]\n",
    "\n",
    "def to_hf_dataset(examples):\n",
    "    \"\"\"\n",
    "    Преобразует примеры в формат HuggingFace Dataset.\n",
    "\n",
    "    Параметры:\n",
    "    - examples: список примеров с текстами и аннотациями\n",
    "\n",
    "    Возвращает:\n",
    "    - датасет в формате HuggingFace\n",
    "    - коллатор для батчей\n",
    "    - список текстов\n",
    "    \"\"\"\n",
    "    if not examples: return None, None, []\n",
    "\n",
    "    # Преобразуем в DataFrame\n",
    "    df = pd.DataFrame(examples)\n",
    "    ds = Dataset.from_pandas(df)\n",
    "\n",
    "    # Сохраняем тексты для последующего анализа\n",
    "    texts = df['text'].tolist()\n",
    "\n",
    "    def fn(ex):\n",
    "        # Токенизация и выравнивание меток\n",
    "        tok = TOKENIZER(ex['text'], truncation=True, padding='max_length', max_length=512)\n",
    "        aligned = align_labels(ex)\n",
    "        tok['labels'] = aligned + [-100] * (512 - len(aligned))  # -100 для padding\n",
    "        return tok\n",
    "\n",
    "    ds = ds.map(fn, batched=False, remove_columns=['text','tags'])\n",
    "    return ds, DataCollatorForTokenClassification(TOKENIZER), texts\n",
    "\n",
    "def update_remaining_dataset(remaining_df, json_file):\n",
    "    \"\"\"\n",
    "    Обновляет оставшийся датасет, удаляя из него сообщения, которые были размечены.\n",
    "    Args:\n",
    "        remaining_df: DataFrame с оставшимися сообщениями\n",
    "        json_file: путь к JSON файлу с размеченными данными\n",
    "    Returns:\n",
    "        Обновленный DataFrame с оставшимися сообщениями\n",
    "    \"\"\"\n",
    "    # Удаляем все print, связанные с размером датасета и совпадениями\n",
    "    # Загружаем размеченные данные\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        labeled_data = json.load(f)\n",
    "    # Получаем ID сообщений из JSON файла\n",
    "    labeled_ids = []\n",
    "    for item in labeled_data:\n",
    "        if 'data' in item and 'meta' in item['data'] and 'id' in item['data']['meta']:\n",
    "            labeled_ids.append(str(item['data']['meta']['id']))\n",
    "    if labeled_ids:\n",
    "        # Проверяем, есть ли совпадения ID\n",
    "        matching_ids = remaining_df.index.astype(str).isin(labeled_ids)\n",
    "        # Удаляем строки, где индекс совпадает с ID из JSON\n",
    "        remaining_df = remaining_df[~remaining_df.index.astype(str).isin(labeled_ids)]\n",
    "    return remaining_df\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Вычисляет метрики для оценки модели NER.\n",
    "    \"\"\"\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    refs, hyps = [], []\n",
    "    for pr, gt in zip(preds, p.label_ids):\n",
    "        r_seq, h_seq = [], []\n",
    "        for pi, gi in zip(pr, gt):\n",
    "            if gi == -100:\n",
    "                continue\n",
    "            r_seq.append(ID2LABEL[gi])\n",
    "            h_seq.append(ID2LABEL[pi])\n",
    "        refs.append(r_seq)\n",
    "        hyps.append(h_seq)\n",
    "    out = metric.compute(predictions=hyps, references=refs)\n",
    "    return {\n",
    "        'precision': out['overall_precision'],\n",
    "        'recall': out['overall_recall'],\n",
    "        'f1': out['overall_f1']\n",
    "    }\n",
    "\n",
    "def predict_entities(text: str, model, tokenizer, id2label: Dict[int, str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Извлекает именованные сущности из текста с помощью обученной модели.\n",
    "\n",
    "    Args:\n",
    "        text (str): Входной текст для анализа\n",
    "        model: Обученная модель NER\n",
    "        tokenizer: Токенизатор для обработки текста\n",
    "        id2label (Dict[int, str]): Словарь для преобразования ID в метки\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Список словарей с найденными сущностями в формате:\n",
    "            [{'text': 'текст сущности', 'label': 'тип сущности', 'start': начало, 'end': конец}]\n",
    "    \"\"\"\n",
    "    # Определяем устройство для вычислений (GPU/CPU)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Токенизация текста с сохранением маппинга позиций\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    offset_mapping = inputs.pop('offset_mapping')[0]\n",
    "\n",
    "    # Перенос входных данных на нужное устройство\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Получение предсказаний модели\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = outputs.logits.argmax(-1)[0]\n",
    "\n",
    "    # Перенос предсказаний обратно на CPU для обработки\n",
    "    predictions = predictions.cpu()\n",
    "\n",
    "    # Обработка предсказаний и сбор сущностей\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    # Проходим по всем токенам и их позициям\n",
    "    for pred, (start, end) in zip(predictions, offset_mapping):\n",
    "        # Пропускаем специальные токены (CLS, SEP, PAD)\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "\n",
    "        # Получаем метку для текущего токена\n",
    "        label = id2label[pred.item()]\n",
    "\n",
    "        if label.startswith('B-'):\n",
    "            # Если встретили начало новой сущности\n",
    "            if current_entity:\n",
    "                # Сохраняем предыдущую сущность\n",
    "                entities.append(current_entity)\n",
    "            # Создаем новую сущность\n",
    "            current_entity = {\n",
    "                'text': text[start:end],\n",
    "                'label': label[2:],  # Убираем префикс B-\n",
    "                'start': start,\n",
    "                'end': end\n",
    "            }\n",
    "        elif label.startswith('I-') and current_entity and label[2:] == current_entity['label']:\n",
    "            # Продолжаем текущую сущность\n",
    "            current_entity['text'] += text[start:end]\n",
    "            current_entity['end'] = end\n",
    "        else:\n",
    "            # Если встретили токен вне сущности\n",
    "            if current_entity:\n",
    "                # Сохраняем текущую сущность\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "\n",
    "    # Добавляем последнюю сущность, если она есть\n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "\n",
    "    return entities\n",
    "\n",
    "def test_model_on_example(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    Тестирует только NER модель на одном примере и выводит результаты разметки в унифицированном формате.\n",
    "    Выводит все определенные сущности.\n",
    "    \"\"\"\n",
    "    print(f\"\\nТестовый пример:\")\n",
    "    print(f\"Текст: {text}\")\n",
    "\n",
    "    # Получаем предсказанные сущности\n",
    "    entities = predict_entities(text, model, tokenizer, ID2LABEL)\n",
    "\n",
    "    # Группируем сущности по типу\n",
    "    ent_by_type = {label: [] for label in LABELS}\n",
    "    for ent in entities:\n",
    "        if ent['label'] in ent_by_type:\n",
    "            ent_by_type[ent['label']].append(ent['text'])\n",
    "\n",
    "    # Выводим результаты NER\n",
    "    print(\"\\n[NER] Результаты анализа:\")\n",
    "    for label in LABELS:\n",
    "        if ent_by_type[label]:\n",
    "            print(f\"{label}: {', '.join(ent_by_type[label])}\")\n",
    "        else:\n",
    "            print(f\"{label}: не найдено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NFJexHKPktqv"
   },
   "outputs": [],
   "source": [
    "def run_cycle(df_path: str, sizes, start_size: Optional[int] = None) -> None:\n",
    "    \"\"\"\n",
    "    Запускает цикл обучения модели NER с активным обучением.\n",
    "\n",
    "    Args:\n",
    "        df_path (str): Путь к исходному датасету\n",
    "        start_size (Optional[int]): Размер выборки, с которой начать обучение\n",
    "    \"\"\"\n",
    "    # Загружаем датасет и создаем копию для оставшихся сообщений\n",
    "    df = pd.read_csv(df_path, sep=';', index_col=0)\n",
    "    print(f\"Загружен исходный датасет размером {len(df)} сообщений\")\n",
    "    print(\"Первые 5 строк исходного датасета:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Если указан start_size, находим его индекс в списке sizes\n",
    "    start_index = 0\n",
    "    if start_size is not None:\n",
    "        try:\n",
    "            start_index = sizes.index(start_size)\n",
    "            print(f\"Начинаем с итерации {start_index + 1} (размер выборки {start_size})\")\n",
    "        except ValueError:\n",
    "            print(f\"Ошибка: размер выборки {start_size} не найден в списке допустимых размеров\")\n",
    "            return\n",
    "\n",
    "    # Проверяем существование тестового проекта\n",
    "    test_project_title = 'PollenNER TEST'\n",
    "    test_project = get_or_create_project(ls, test_project_title, LABEL_CONFIG)\n",
    "    test_tasks = get_project_tasks(ls, test_project.id)\n",
    "\n",
    "    # Если тестовый проект пустой или не существует, создаем его\n",
    "    if not test_tasks:\n",
    "        print(\"\\nСоздание тестового проекта из случайных записей\")\n",
    "        # Выбираем 100 случайных записей с фиксированным seed\n",
    "        test_df = df.sample(n=100, random_state=SEED)\n",
    "        test_texts_with_ids = [(idx, text) for idx, text in zip(test_df.index, test_df['text'])]\n",
    "\n",
    "        # Создаем задачи в Label Studio\n",
    "        for text_id, text in test_texts_with_ids:\n",
    "            create_task(ls, test_project.id, text, text_id)\n",
    "\n",
    "        print(f\"Создано {len(test_texts_with_ids)} тестовых задач\")\n",
    "        print(\"Пожалуйста, разместите тестовые данные в Label Studio\")\n",
    "        input(\"Нажмите Enter после завершения разметки...\")\n",
    "\n",
    "        # Экспортируем размеченные данные\n",
    "        test_data = export_project(ls, test_project.id)\n",
    "        with open('PollenNER_TEST.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # Преобразуем данные в формат для обучения\n",
    "        test_ex = []\n",
    "        for item in test_data:\n",
    "            tags = []\n",
    "            for ann in item.get('annotations', []):\n",
    "                for r in ann.get('result', []):\n",
    "                    v = r.get('value')\n",
    "                    if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                        tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "            test_ex.append({'text': item['data']['text'], 'tags': tags})\n",
    "\n",
    "        # Создаем тестовый датасет\n",
    "        test_ds, _, _ = to_hf_dataset(test_ex)\n",
    "\n",
    "        # Обновляем оставшийся датасет\n",
    "        test_ids = [str(item['data']['meta']['id']) for item in test_data]\n",
    "        remaining_df = df[~df.index.astype(str).isin(test_ids)]\n",
    "        print(f\"Размер оставшегося датасета после создания тестового: {len(remaining_df)}\")\n",
    "    else:\n",
    "        print(\"\\nТестовый проект уже существует, загружаем данные\")\n",
    "        # Загружаем существующие тестовые данные\n",
    "        with open('PollenNER_TEST.json', 'r', encoding='utf-8') as f:\n",
    "            test_data = json.load(f)\n",
    "\n",
    "        # Преобразуем данные в формат для обучения\n",
    "        test_ex = []\n",
    "        for item in test_data:\n",
    "            tags = []\n",
    "            for ann in item.get('annotations', []):\n",
    "                for r in ann.get('result', []):\n",
    "                    v = r.get('value')\n",
    "                    if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                        tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "            test_ex.append({'text': item['data']['text'], 'tags': tags})\n",
    "\n",
    "        test_ds, _, _ = to_hf_dataset(test_ex)\n",
    "        test_ids = [str(item['data']['meta']['id']) for item in test_data]\n",
    "        remaining_df = df[~df.index.astype(str).isin(test_ids)]\n",
    "        print(f\"Размер оставшегося датасета: {len(remaining_df)}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # --- Инициализация базовой модели с dropout через конфиг ---\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        'DeepPavlov/rubert-base-cased',\n",
    "        hidden_dropout_prob=0.3,  # Dropout для регуляризации\n",
    "        attention_probs_dropout_prob=0.3,  # Dropout на внимании\n",
    "        id2label=ID2LABEL,\n",
    "        label2id=LABEL2ID\n",
    "    )\n",
    "    base_model = AutoModelForTokenClassification.from_pretrained('DeepPavlov/rubert-base-cased', config=config)\n",
    "\n",
    "    # Если начинаем не с начала, загружаем последнюю обученную модель\n",
    "    if start_index > 0:\n",
    "        prev_size = sizes[start_index - 1]\n",
    "        model_path = f'models/pollen_ner_{prev_size}'\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Загружаем модель из {model_path}\")\n",
    "            model = get_peft_model(base_model,\n",
    "                                   LoraConfig(task_type='TOKEN_CLS',\n",
    "                                              r=16,\n",
    "                                              lora_alpha=32,\n",
    "                                              lora_dropout=0.1))\n",
    "            model.load_adapter(model_path, adapter_name=\"default\")\n",
    "            # Перемещаем модель на GPU, если доступен\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = model.to(device)\n",
    "            print(f\"Модель перемещена на {device}\")\n",
    "        else:\n",
    "            print(f\"Ошибка: модель {model_path} не найдена\")\n",
    "            return\n",
    "    else:\n",
    "        model = get_peft_model(base_model, LoraConfig(task_type='TOKEN_CLS',\n",
    "                                                      r=16,\n",
    "                                                      lora_alpha=32,\n",
    "                                                      lora_dropout=0.1))\n",
    "        # Перемещаем модель на GPU, если доступен\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"Модель перемещена на {device}\")\n",
    "\n",
    "    # Продолжаем с указанной итерации\n",
    "    for i, size in enumerate(sizes[start_index:], start_index):\n",
    "        if start_size and size < start_size:\n",
    "            continue\n",
    "        print(f\"\\n[NER] Начинаем итерацию с размером выборки {size}\")\n",
    "\n",
    "        # Проверяем наличие существующего проекта для текущего размера\n",
    "        title = f'PollenNER TRAIN {size}'\n",
    "        export_file = f'PollenNER_TRAIN_{size}.json'\n",
    "\n",
    "        # Проверяем, существует ли проект и все ли задачи размечены\n",
    "        proj = get_or_create_project(ls, title, LABEL_CONFIG)\n",
    "        tasks = get_project_tasks(ls, proj.id)\n",
    "\n",
    "        if tasks and all(t.is_labeled for t in tasks):\n",
    "            print(f\"Найден существующий размеченный проект для размера {size}\")\n",
    "            # Экспортируем размеченные данные\n",
    "            data = export_project(ls, proj.id)\n",
    "            with open(export_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            # Преобразуем данные в формат для обучения\n",
    "            train_ex = []\n",
    "            for item in data:\n",
    "                tags = []\n",
    "                for ann in item.get('annotations', []):\n",
    "                    for r in ann.get('result', []):\n",
    "                        v = r.get('value')\n",
    "                        if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                            tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "                train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
    "        else:\n",
    "            # Если это первая итерация и проект пустой, создаем его с нуля\n",
    "            if i == start_index and not tasks:\n",
    "                print(f\"\\nСоздание первого тренировочного проекта с размером {size}\")\n",
    "                # Выбираем случайные записи с фиксированным seed\n",
    "                train_df = remaining_df.sample(n=size, random_state=SEED)\n",
    "                train_texts_with_ids = [(idx, text) for idx, text in zip(train_df.index, train_df['text'])]\n",
    "\n",
    "                # Создаем задачи в Label Studio\n",
    "                for text_id, text in train_texts_with_ids:\n",
    "                    create_task(ls, proj.id, text, text_id)\n",
    "\n",
    "                print(f\"Создано {len(train_texts_with_ids)} тренировочных задач\")\n",
    "                print(\"Пожалуйста, разместите тренировочные данные в Label Studio\")\n",
    "                input(\"Нажмите Enter после завершения разметки...\")\n",
    "\n",
    "                # Экспортируем размеченные данные\n",
    "                data = export_project(ls, proj.id)\n",
    "                with open(export_file, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "                # Преобразуем данные в формат для обучения\n",
    "                train_ex = []\n",
    "                for item in data:\n",
    "                    tags = []\n",
    "                    for ann in item.get('annotations', []):\n",
    "                        for r in ann.get('result', []):\n",
    "                            v = r.get('value')\n",
    "                            if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                                tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "                    train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
    "            else:\n",
    "                # Загружаем размеченные данные из предыдущей итерации\n",
    "                prev_size = sizes[i-1] if i > 0 else 0\n",
    "                prev_json = f'PollenNER_TRAIN_{prev_size}.json'\n",
    "                if os.path.exists(prev_json):\n",
    "                    print(f\"Загружаем размеченные данные из {prev_json}\")\n",
    "                    with open(prev_json, 'r', encoding='utf-8') as f:\n",
    "                        prev_data = json.load(f)\n",
    "\n",
    "                    # Создаем список задач для импорта\n",
    "                    tasks_list = []\n",
    "\n",
    "                    # Добавляем размеченные данные из предыдущей итерации\n",
    "                    for item in prev_data:\n",
    "                        tasks_list.append({\n",
    "                            'data': {\n",
    "                                'text': item['data']['text'],\n",
    "                                'meta': {\n",
    "                                    'id': item['data']['meta']['id']\n",
    "                                }\n",
    "                            },\n",
    "                            'annotations': item.get('annotations', [])\n",
    "                        })\n",
    "\n",
    "                    # Импортируем размеченные данные\n",
    "                    if tasks_list:\n",
    "                        print(f\"Импортируем {len(tasks_list)} размеченных сообщений из предыдущей итерации\")\n",
    "                        bulk_import_via_http(proj.id, tasks_list, LS_URL, LS_TOKEN)\n",
    "\n",
    "                # Выбираем наименее уверенные примеры из оставшегося датасета\n",
    "                if len(remaining_df) > 0:\n",
    "                    # Получаем оценки неопределенности для всех оставшихся сообщений\n",
    "                    uncertainties = calculate_uncertainty_scores(model,\n",
    "                                                                 remaining_df['text'].tolist(),\n",
    "                                                                 TOKENIZER)\n",
    "\n",
    "                    # Выбираем сообщения с наивысшей неопределенностью\n",
    "                    # Количество новых примеров = текущий размер - предыдущий размер\n",
    "                    n_new_samples = size - prev_size\n",
    "                    selected_indices = select_samples_improved(\n",
    "                        model,\n",
    "                        remaining_df['text'].tolist(),\n",
    "                        TOKENIZER,\n",
    "                        n_samples=n_new_samples,\n",
    "                        remaining_texts=remaining_df['text'].tolist(),\n",
    "                        current_iteration=i\n",
    "                    )\n",
    "\n",
    "                    # Получаем выбранные сообщения с их ID\n",
    "                    selected_df = remaining_df.iloc[selected_indices]\n",
    "                    train_texts = [(idx, text) for idx, text in zip(selected_df.index, selected_df['text'])]\n",
    "\n",
    "                    # Добавляем новые сообщения в проект\n",
    "                    print(f\"Добавляем {len(train_texts)} новых сообщений для разметки\")\n",
    "                    for text_id, text in train_texts:\n",
    "                        create_task(ls, proj.id, text, text_id)\n",
    "\n",
    "                    # Ждем разметки новых данных\n",
    "                    print(f\"\\nРазметьте {len(train_texts)} новых сообщений в Label Studio\")\n",
    "                    input(\"Нажмите Enter после завершения разметки...\")\n",
    "\n",
    "                    # Экспортируем все размеченные данные\n",
    "                    data = export_project(ls, proj.id)\n",
    "                    with open(export_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "                    # Преобразуем данные в формат для обучения\n",
    "                    train_ex = []\n",
    "                    for item in data:\n",
    "                        tags = []\n",
    "                        for ann in item.get('annotations', []):\n",
    "                            for r in ann.get('result', []):\n",
    "                                v = r.get('value')\n",
    "                                if v and isinstance(v, dict) and 'start' in v and 'end' in v and 'labels' in v:\n",
    "                                    tags.append({'start': v['start'], 'end': v['end'], 'label': v['labels'][0]})\n",
    "                        train_ex.append({'text': item['data']['text'], 'tags': tags})\n",
    "                else:\n",
    "                    print(\"Больше нет доступных сообщений для обучения\")\n",
    "                    break\n",
    "\n",
    "        # Обновляем оставшийся датасет\n",
    "        remaining_df = update_remaining_dataset(remaining_df, export_file)\n",
    "\n",
    "        print(f\"После итерации {i+1} осталось {len(remaining_df)} сообщений\")\n",
    "\n",
    "        train_ds, coll, train_texts = to_hf_dataset(train_ex)\n",
    "\n",
    "        # Настройка аргументов тренировки\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        run_name = f\"pollen_ner_{size}_{timestamp}\"\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=f'runs/train_{size}',\n",
    "            run_name=run_name,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=10,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='eval_f1',\n",
    "            greater_is_better=True,\n",
    "            eval_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit=2,\n",
    "            push_to_hub=True,\n",
    "            hub_model_id=f'pollen-ner-{size}',\n",
    "            hub_token=HF_TOKEN,\n",
    "            no_cuda=not torch.cuda.is_available(),\n",
    "            weight_decay=0.01  # L2-регуляризация для борьбы с переобучением\n",
    "        )\n",
    "\n",
    "        # Создаем trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=train_ds,\n",
    "            eval_dataset=test_ds,\n",
    "            data_collator=coll,\n",
    "            tokenizer=TOKENIZER,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(\n",
    "                early_stopping_patience=2,\n",
    "                early_stopping_threshold=0.001\n",
    "            )]\n",
    "        )\n",
    "\n",
    "        print(f\"[NER] Обучение на {size} примерах\")\n",
    "        trainer.train()\n",
    "        ev = trainer.evaluate()\n",
    "        print(f\"[NER] Результаты: F1 = {ev['eval_f1']:.4f}\")\n",
    "\n",
    "        # Получаем предсказания для тестового набора\n",
    "        predictions = trainer.predict(test_ds)\n",
    "        preds = predictions.predictions.argmax(-1)\n",
    "        labels = predictions.label_ids\n",
    "\n",
    "        # Подготавливаем списки для эталонных и предсказанных последовательностей\n",
    "        refs, hyps = [], []\n",
    "        for pr, gt in zip(preds, labels):\n",
    "            r_seq, h_seq = [], []\n",
    "            for pi, gi in zip(pr, gt):\n",
    "                if gi == -100:\n",
    "                    continue\n",
    "                r_seq.append(ID2LABEL[gi])\n",
    "                h_seq.append(ID2LABEL[pi])\n",
    "            refs.append(r_seq)\n",
    "            hyps.append(h_seq)\n",
    "\n",
    "        # Преобразуем последовательности в плоский формат для classification_report\n",
    "        flat_refs = []\n",
    "        flat_hyps = []\n",
    "        for r_seq, h_seq in zip(refs, hyps):\n",
    "            flat_refs.extend(r_seq)\n",
    "            flat_hyps.extend(h_seq)\n",
    "\n",
    "        # Выводим подробный отчет о классификации\n",
    "        print(\"\\n[NER] Подробный отчет о классификации:\")\n",
    "        print(classification_report(flat_refs,\n",
    "                                    flat_hyps,\n",
    "                                    digits=4))\n",
    "\n",
    "        # Сохраняем лучшую модель\n",
    "        model_save_path = f'models/pollen_ner_{size}'\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        trainer.save_model(model_save_path)\n",
    "        print(f\"[NER] Модель сохранена в {model_save_path}\")\n",
    "\n",
    "        # --- Сохраняем только лучшую и одну финальную модель NER ---\n",
    "        best_f1 = -1\n",
    "        best_model_path = 'models/pollen_ner_best'\n",
    "\n",
    "        if ev['eval_f1'] > best_f1:\n",
    "            best_f1 = ev['eval_f1']\n",
    "            os.makedirs(best_model_path, exist_ok=True)\n",
    "            trainer.save_model(best_model_path)\n",
    "            TOKENIZER.save_pretrained(best_model_path)\n",
    "            print(f\"[NER] Лучшая модель за все итерации сохранена в {best_model_path}\")\n",
    "\n",
    "        # Тестируем модель на примерах после каждой итерации\n",
    "        print(\"\\n[NER] Тестирование модели после обучения:\")\n",
    "        test_model_on_example(model, TOKENIZER, TEST_EXAMPLES[0])\n",
    "\n",
    "        results.append({'size': size, 'f1': ev['eval_f1']})\n",
    "\n",
    "        # Загружаем лучшую модель для следующей итерации\n",
    "        model = get_peft_model(base_model,\n",
    "                               LoraConfig(task_type='TOKEN_CLS',\n",
    "                                          r=16,\n",
    "                                          lora_alpha=32,\n",
    "                                          lora_dropout=0.1))\n",
    "        model.load_adapter(model_save_path, adapter_name=\"default\")\n",
    "        # Перемещаем модель на GPU, если доступен\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"Модель перемещена на {device}\")\n",
    "\n",
    "        # После каждой итерации выводим статистику распределения классов по train_texts\n",
    "        from collections import Counter\n",
    "        print(f\"\\nСтатистика распределения классов в тренировочном датасете после итерации {i+1}:\")\n",
    "        all_labels = []\n",
    "        for ex in train_texts:\n",
    "            # Для каждого текста можно получить предсказания NER, но если train_texts — это список текстов, то статистика по ним\n",
    "            # Если нужно по меткам, то train_ex содержит 'tags'\n",
    "            pass  # Можно доработать, если нужно по меткам\n",
    "        # Если train_ex доступен, можно посчитать по меткам:\n",
    "        if 'train_ex' in locals():\n",
    "            for ex in train_ex:\n",
    "                for tag in ex.get('tags', []):\n",
    "                    all_labels.append(tag['label'])\n",
    "            print(Counter(all_labels))\n",
    "        else:\n",
    "            print('Нет данных для подсчёта статистики по меткам.')\n",
    "\n",
    "    # Визуализация результатов\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    ax = plt.gca()\n",
    "    sns.lineplot(data=results_df, x='size', y='f1', marker='o', ax=ax)\n",
    "    ax.set_title('Зависимость F1 от размера выборки', pad=20)\n",
    "    ax.set_xlabel('Размер обучающей выборки')\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    # Подпись только у максимального значения F1\n",
    "    max_idx = results_df['f1'].idxmax()\n",
    "    max_x = results_df.loc[max_idx, 'size']\n",
    "    max_y = results_df.loc[max_idx, 'f1']\n",
    "    ax.annotate(f'{max_y:.3f}', (max_x, max_y),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(0,10),\n",
    "                ha='center',\n",
    "                color='red',\n",
    "                fontsize=12,\n",
    "                fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Сохраняем график на диск\n",
    "    plt.savefig('learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Выводим график на экран\n",
    "    plt.show()\n",
    "\n",
    "    # Закрываем график после сохранения и отображения\n",
    "    plt.close()\n",
    "\n",
    "    # Сохраняем финальный оставшийся датасет\n",
    "    remaining_df.to_csv('remaining_dataset_final.csv', sep=';')\n",
    "    print(f\"\\nФинальный оставшийся датасет сохранен в remaining_dataset_final.csv\")\n",
    "    print(f\"Размер финального датасета: {len(remaining_df)} сообщений\")\n",
    "\n",
    "    # После цикла обучения NER:\n",
    "    last_ner_model = model  # Сохраняем последнюю обученную NER-модель\n",
    "\n",
    "    # Загружаем последнюю сохранённую модель из директории\n",
    "    last_size = sizes[-1] if start_size is None else sizes[start_index + len(results) - 1]\n",
    "    model_save_path = f'models/pollen_ner_{last_size}'\n",
    "    base_model = AutoModelForTokenClassification.from_pretrained('DeepPavlov/rubert-base-cased',\n",
    "                                                                 id2label=ID2LABEL,\n",
    "                                                                 label2id=LABEL2ID)\n",
    "    last_ner_model = get_peft_model(base_model,\n",
    "                                    LoraConfig(task_type='TOKEN_CLS',\n",
    "                                               r=16,\n",
    "                                               lora_alpha=32,\n",
    "                                               lora_dropout=0.1))\n",
    "    last_ner_model.load_adapter(model_save_path,\n",
    "                                adapter_name=\"default\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    last_ner_model = last_ner_model.to(device)\n",
    "    return last_ner_model\n",
    "\n",
    "def calculate_text_diversity(texts, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Рассчитывает разнообразие текстов с помощью кластеризации TF-IDF.\n",
    "\n",
    "    Параметры:\n",
    "    - texts: список текстов\n",
    "    - n_clusters: количество кластеров для кластеризации\n",
    "\n",
    "    Возвращает:\n",
    "    - оценку разнообразия текстов (0-1)\n",
    "    \"\"\"\n",
    "    with parallel_backend('loky', n_jobs=n_jobs):\n",
    "        # Векторизация текстов\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "        # Кластеризация текстов\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=min(n_clusters, len(texts)),\n",
    "            random_state=42\n",
    "        )\n",
    "        clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "        # Анализ распределения текстов по кластерам\n",
    "        cluster_counts = Counter(clusters)\n",
    "\n",
    "        # Нормализация счетчиков для получения оценки разнообразия\n",
    "        total = len(texts)\n",
    "        diversity_scores = [1 - (count/total) for count in cluster_counts.values()]\n",
    "\n",
    "        return np.mean(diversity_scores)\n",
    "\n",
    "def calculate_class_distribution(texts, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Рассчитывает распределение классов в наборе текстов.\n",
    "\n",
    "    Параметры:\n",
    "    - texts: список текстов\n",
    "    - tokenizer: токенизатор\n",
    "    - model: модель для предсказаний\n",
    "\n",
    "    Возвращает:\n",
    "    - словарь с распределением классов\n",
    "    \"\"\"\n",
    "    class_counts = Counter()\n",
    "    total_tokens = 0\n",
    "\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(next(model.parameters()).device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = outputs.logits.argmax(-1)[0]\n",
    "\n",
    "        for pred in predictions:\n",
    "            label = ID2LABEL[pred.item()]\n",
    "            if label != 'O':\n",
    "                class_counts[label.split('-')[1]] += 1\n",
    "                total_tokens += 1\n",
    "\n",
    "    return {k: v/total_tokens for k, v in class_counts.items()} if total_tokens > 0 else {}\n",
    "\n",
    "def calculate_class_balance_score(class_distribution):\n",
    "    \"\"\"\n",
    "    Рассчитывает оценку баланса классов.\n",
    "\n",
    "    Параметры:\n",
    "    - class_distribution: распределение классов\n",
    "\n",
    "    Возвращает:\n",
    "    - оценку баланса (0-1)\n",
    "    \"\"\"\n",
    "    if not class_distribution:\n",
    "        return 0\n",
    "\n",
    "    # Расчет энтропии распределения\n",
    "    probs = list(class_distribution.values())\n",
    "    entropy = -sum(p * np.log(p) for p in probs)\n",
    "\n",
    "    # Нормализация энтропии\n",
    "    max_entropy = np.log(len(LABELS))\n",
    "    return entropy / max_entropy if max_entropy > 0 else 0\n",
    "\n",
    "def select_samples_improved(model,\n",
    "                            texts,\n",
    "                            tokenizer,\n",
    "                            n_samples=50,\n",
    "                            remaining_texts=None,\n",
    "                            current_iteration=0):\n",
    "    \"\"\"\n",
    "    Улучшенная стратегия отбора сообщений для активного обучения.\n",
    "    Учитывает неопределенность модели, разнообразие текстов и баланс классов.\n",
    "\n",
    "    Параметры:\n",
    "    - model: текущая модель\n",
    "    - texts: список текстов для отбора\n",
    "    - tokenizer: токенизатор\n",
    "    - n_samples: количество сообщений для отбора\n",
    "    - remaining_texts: оставшиеся тексты для учета разнообразия\n",
    "    - current_iteration: текущая итерация обучения\n",
    "\n",
    "    Возвращает:\n",
    "    - индексы отобранных сообщений\n",
    "    \"\"\"\n",
    "    # Веса для метрик\n",
    "    weights = {\n",
    "        'uncertainty': 0.5,      # Неопределенность модели\n",
    "        'text_diversity': 0.2,   # Разнообразие текстов\n",
    "        'class_balance': 0.3     # Баланс классов\n",
    "    }\n",
    "\n",
    "    # Получаем оценки неопределенности\n",
    "    uncertainties = calculate_uncertainty_scores(model, texts, tokenizer)\n",
    "\n",
    "    # Рассчитываем разнообразие текстов\n",
    "    n_clusters = min(5, max(2, len(texts) // 10))\n",
    "    if remaining_texts:\n",
    "        text_diversity = calculate_text_diversity(texts + remaining_texts, n_clusters=n_clusters)\n",
    "    else:\n",
    "        text_diversity = calculate_text_diversity(texts, n_clusters=n_clusters)\n",
    "\n",
    "    # Рассчитываем текущее распределение классов\n",
    "    current_distribution = calculate_class_distribution(texts, tokenizer, model)\n",
    "    class_balance = calculate_class_balance_score(current_distribution)\n",
    "\n",
    "    # Нормализация неопределенности\n",
    "    uncertainties = np.array(uncertainties)\n",
    "    uncertainties = (uncertainties - uncertainties.min()) / (uncertainties.max() - uncertainties.min() + 1e-10)\n",
    "\n",
    "    # Комбинирование метрик с весами\n",
    "    combined_scores = (\n",
    "        weights['uncertainty'] * uncertainties +\n",
    "        weights['text_diversity'] * text_diversity +\n",
    "        weights['class_balance'] * class_balance\n",
    "    )\n",
    "\n",
    "    # Выбор сообщений с наивысшими комбинированными оценками\n",
    "    selected_indices = np.argsort(combined_scores)[-n_samples:]\n",
    "\n",
    "    # Вывод подробной статистики\n",
    "    print(\"\\nСтатистика отобранных сообщений:\")\n",
    "    print(f\"Итерация: {current_iteration}\")\n",
    "    print(f\"Веса метрик:\")\n",
    "    for metric, weight in weights.items():\n",
    "        print(f\"- {metric}: {weight:.3f}\")\n",
    "    print(f\"Средняя неопределенность: {np.mean(uncertainties[selected_indices]):.4f}\")\n",
    "    print(f\"Разнообразие текстов: {text_diversity:.4f}\")\n",
    "    print(f\"Баланс классов: {class_balance:.4f}\")\n",
    "    print(\"\\nРаспределение классов:\")\n",
    "    for label, prob in current_distribution.items():\n",
    "        print(f\"- {label}: {prob:.3f}\")\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "def parse_labelstudio_json(json_path):\n",
    "    \"\"\"\n",
    "    Извлекает сущности и отношения из разметки Label Studio (JSON).\n",
    "    Поддерживает только отношения из RE_RELATION_LABELS.\n",
    "    Пропускает примеры без сущностей или с одной сущностью.\n",
    "\n",
    "    Важно: для RE критично, чтобы id в отношениях (from_id, to_id) совпадали с id сущностей.\n",
    "    Также важно учитывать направленность отношений (from_id -> to_id).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for item in data:\n",
    "        text = item['data']['text']\n",
    "        ann = item['annotations'][0]['result'] if item['annotations'] and 'result' in item['annotations'][0] else []\n",
    "        entities = []\n",
    "        relations = []\n",
    "        for obj in ann:\n",
    "            if obj.get('type') == 'labels':\n",
    "                ent = {\n",
    "                    'id': obj['id'],\n",
    "                    'start': obj['value']['start'],\n",
    "                    'end': obj['value']['end'],\n",
    "                    'label': obj['value']['labels'][0],\n",
    "                    'text': obj['value']['text']\n",
    "                }\n",
    "                entities.append(ent)\n",
    "        for obj in ann:\n",
    "            if obj.get('type') == 'relation':\n",
    "                if 'labels' in obj:\n",
    "                    rel_label = obj['labels'][0]\n",
    "                elif 'label' in obj:\n",
    "                    rel_label = obj['label']\n",
    "                else:\n",
    "                    rel_label = 'unknown_relation'\n",
    "                if rel_label in RE_RELATION_LABELS:\n",
    "                    rel = {\n",
    "                        'from_id': obj['from_id'],\n",
    "                        'to_id': obj['to_id'],\n",
    "                        'label': rel_label\n",
    "                    }\n",
    "                    relations.append(rel)\n",
    "        # Пропускаем примеры без сущностей или с одной сущностью\n",
    "        if len(entities) < 2:\n",
    "            continue\n",
    "        results.append({'text': text, 'entities': entities, 'relations': relations})\n",
    "    return results\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Разбивает текст на предложения по точкам, восклицательным и вопросительным знакам.\n",
    "    Можно заменить на более продвинутый токенизатор (например, nltk), если потребуется.\n",
    "    \"\"\"\n",
    "    return [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
    "\n",
    "def prepare_re_dataset(parsed_data,\n",
    "                       relation_labels=None,\n",
    "                       max_no_relation_ratio=3,\n",
    "                       oversample_medicine=False):\n",
    "    \"\"\"\n",
    "    Формирует датасет для обучения модели извлечения отношений (RE) с балансировкой класса 'no_relation'.\n",
    "    Использует только отношения из RE_RELATION_LABELS.\n",
    "    Пропускает примеры с одной сущностью.\n",
    "    max_no_relation_ratio: максимальное соотношение 'no_relation' к числу позитивных примеров (например, 3:1).\n",
    "    Теперь пары формируются только между сущностями, находящимися в одном предложении.\n",
    "    oversample_medicine: если True, увеличивает число примеров has_medicine до числа has_symptom (дублированием)\n",
    "    \"\"\"\n",
    "    if relation_labels is None:\n",
    "        relation_labels = RE_RELATION_LABELS.copy()\n",
    "    relation_labels = relation_labels + ['no_relation']\n",
    "\n",
    "    re_examples = []\n",
    "    for item in parsed_data:\n",
    "        text = item['text']\n",
    "        entities = item['entities']\n",
    "        relations = item['relations']\n",
    "        if len(entities) < 2:\n",
    "            continue\n",
    "        # Разбиваем текст на предложения\n",
    "        sentences = split_sentences(text)\n",
    "        # Для каждого предложения ищем сущности, которые в него попадают\n",
    "        for sent in sentences:\n",
    "            sent_start = text.find(sent)\n",
    "            sent_end = sent_start + len(sent)\n",
    "            ents_in_sent = [e for e in entities if e['start'] >= sent_start and e['end'] <= sent_end]\n",
    "            # Генерируем пары только внутри предложения\n",
    "            positive, negative = [], []\n",
    "            for i, ent1 in enumerate(ents_in_sent):\n",
    "                for j, ent2 in enumerate(ents_in_sent):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    # Фильтруем только осмысленные пары:\n",
    "                    # BODY_PART–SYMPTOM (has_symptom) и BODY_PART–MEDICINE (has_medicine)\n",
    "                    if ent1['label'] == 'BODY_PART' and ent2['label'] == 'SYMPTOM':\n",
    "                        rel_label = None\n",
    "                        for rel in relations:\n",
    "                            if rel['from_id'] == ent1['id'] and rel['to_id'] == ent2['id']:\n",
    "                                rel_label = rel['label']\n",
    "                                break\n",
    "                        rel_label = rel_label if rel_label in relation_labels else 'no_relation'\n",
    "                        ex = {\n",
    "                            'text': text,\n",
    "                            'entity1': ent1,\n",
    "                            'entity2': ent2,\n",
    "                            'relation': rel_label\n",
    "                        }\n",
    "                        if ex['relation'] == 'no_relation':\n",
    "                            negative.append(ex)\n",
    "                        else:\n",
    "                            positive.append(ex)\n",
    "                    elif ent1['label'] == 'BODY_PART' and ent2['label'] == 'MEDICINE':\n",
    "                        rel_label = None\n",
    "                        for rel in relations:\n",
    "                            if rel['from_id'] == ent1['id'] and rel['to_id'] == ent2['id']:\n",
    "                                rel_label = rel['label']\n",
    "                                break\n",
    "                        rel_label = rel_label if rel_label in relation_labels else 'no_relation'\n",
    "                        ex = {\n",
    "                            'text': text,\n",
    "                            'entity1': ent1,\n",
    "                            'entity2': ent2,\n",
    "                            'relation': rel_label\n",
    "                        }\n",
    "                        if ex['relation'] == 'no_relation':\n",
    "                            negative.append(ex)\n",
    "                        else:\n",
    "                            positive.append(ex)\n",
    "            # Балансируем: не больше max_no_relation_ratio * positive\n",
    "            if max_no_relation_ratio is not None and positive:\n",
    "                negative = random.sample(negative,\n",
    "                                         min(len(negative),\n",
    "                                             max_no_relation_ratio * len(positive)))\n",
    "            # --- Oversample has_medicine ---\n",
    "            if oversample_medicine:\n",
    "                medicine_pos = [ex for ex in positive if ex['relation'] == 'has_medicine']\n",
    "                symptom_count = len([ex for ex in positive if ex['relation'] == 'has_symptom'])\n",
    "                if medicine_pos and symptom_count > 0:\n",
    "                    repeats = max(1, symptom_count // len(medicine_pos))\n",
    "                    positive += medicine_pos * (repeats - 1)\n",
    "            re_examples.extend(positive + negative)\n",
    "    return re_examples, relation_labels\n",
    "\n",
    "def insert_entity_markers(text, ent1, ent2):\n",
    "    \"\"\"\n",
    "    Вставляет специальные маркеры вокруг двух сущностей с указанием их типа.\n",
    "    Теперь маркеры имеют вид [TYPE]...[/TYPE], где TYPE — тип сущности (например, BODY_PART, SYMPTOM).\n",
    "    Это помогает RE-модели лучше различать роли сущностей в паре.\n",
    "    \"\"\"\n",
    "    # Определяем порядок: сначала более ранняя сущность\n",
    "    if ent1['start'] < ent2['start']:\n",
    "        first, second = ent1, ent2\n",
    "    else:\n",
    "        first, second = ent2, ent1\n",
    "    # Формируем маркеры с типом сущности\n",
    "    first_tag = f'[{first[\"label\"]}]'\n",
    "    first_end_tag = f'[/{first[\"label\"]}]'\n",
    "    second_tag = f'[{second[\"label\"]}]'\n",
    "    second_end_tag = f'[/{second[\"label\"]}]'\n",
    "    # Вставляем маркеры с конца, чтобы не сбить индексы\n",
    "    text_marked = (\n",
    "        text[:second['start']] + second_tag +\n",
    "        text[second['start']:second['end']] + second_end_tag +\n",
    "        text[second['end']:] )\n",
    "    text_marked = (\n",
    "        text_marked[:first['start']] + first_tag +\n",
    "        text_marked[first['start']:first['end']] + first_end_tag +\n",
    "        text_marked[first['end']:] )\n",
    "    return text_marked\n",
    "\n",
    "def prepare_hf_re_dataset(re_examples, tokenizer, label2id, max_length=256):\n",
    "    \"\"\"\n",
    "    Преобразует список примеров RE в HuggingFace Dataset.\n",
    "    Теперь не добавляет признак distance, так как он не используется стандартной моделью.\n",
    "    Пропускает примеры с relation == 'unknown_relation'.\n",
    "    Пропускает пустые примеры.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for ex in re_examples:\n",
    "        if ex['relation'] == 'unknown_relation':\n",
    "            continue\n",
    "        if not ex['entity1']['text'].strip() or not ex['entity2']['text'].strip():\n",
    "            continue\n",
    "        text_marked = insert_entity_markers(ex['text'], ex['entity1'], ex['entity2'])\n",
    "        rows.append({\n",
    "            'text': text_marked,\n",
    "            'label': label2id[ex['relation']]\n",
    "        })\n",
    "    if not rows:\n",
    "        raise ValueError('Нет валидных примеров для RE!')\n",
    "    df = pd.DataFrame(rows)\n",
    "    def tokenize_fn(ex):\n",
    "        return tokenizer(\n",
    "            ex['text'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length\n",
    "        )\n",
    "    ds = Dataset.from_pandas(df)\n",
    "    ds = ds.map(tokenize_fn, batched=False)\n",
    "    return ds\n",
    "\n",
    "def train_and_eval_re_model(train_ds,\n",
    "                            test_ds,\n",
    "                            num_labels,\n",
    "                            label2id,\n",
    "                            id2label,\n",
    "                            tokenizer,\n",
    "                            hf_token=None,\n",
    "                            output_dir='re_model',\n",
    "                            epochs=5):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модель для извлечения отношений (RE) на основе BERT.\n",
    "\n",
    "    Параметры:\n",
    "        train_ds: HuggingFace Dataset для обучения\n",
    "        test_ds: HuggingFace Dataset для теста\n",
    "        num_labels: число классов (отношений)\n",
    "        label2id, id2label: словари метка<->id\n",
    "        tokenizer: токенизатор\n",
    "        hf_token: токен для HuggingFace Hub (если нужен пуш)\n",
    "        output_dir: директория для сохранения модели\n",
    "        epochs: число эпох обучения\n",
    "\n",
    "    Возвращает:\n",
    "        trainer, eval_results: Trainer и результаты оценки\n",
    "    \"\"\"\n",
    "    # Загружаем базовую модель (ruBERT)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'DeepPavlov/rubert-base-cased',\n",
    "        num_labels=num_labels,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    # Аргументы тренировки для RE\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_name = f\"pollen_re_{timestamp}\"\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        run_name=run_name,  # Уникальное имя для каждого запуска\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_f1',\n",
    "        greater_is_better=True,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=2,\n",
    "        push_to_hub=bool(hf_token),\n",
    "        hub_model_id='pollen-re-model',\n",
    "        hub_token=hf_token,\n",
    "        no_cuda=not torch.cuda.is_available(),\n",
    "        weight_decay=0.01  # L2-регуляризация для RE\n",
    "    )\n",
    "    # Метрика\n",
    "    metric = evaluate.load('f1')\n",
    "    def compute_metrics_re(p):\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "        return metric.compute(predictions=preds,\n",
    "                              references=p.label_ids,\n",
    "                              average='macro')\n",
    "    # Trainer с EarlyStopping для RE\n",
    "    from transformers import EarlyStoppingCallback\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics_re,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    # Обучение\n",
    "    trainer.train()\n",
    "    # Оценка\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"\\nRE-модель: Macro F1 = {eval_results['eval_f1']:.4f}\")\n",
    "    # Сохраняем модель\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    trainer.save_model(output_dir)\n",
    "    print(f\"RE-модель сохранена в {output_dir}\")\n",
    "    return trainer, eval_results\n",
    "\n",
    "def infer_ner_re_on_text(text,\n",
    "                         ner_model,\n",
    "                         re_model,\n",
    "                         tokenizer,\n",
    "                         id2label_ner,\n",
    "                         id2label_re):\n",
    "    \"\"\"\n",
    "    Извлекает сущности и отношения из текста с помощью обученных моделей NER и RE.\n",
    "    Возвращает список сущностей и отношений.\n",
    "    Теперь перебирает только допустимые пары (BODY_PART–SYMPTOM и BODY_PART–MEDICINE) и только внутри одного предложения.\n",
    "    \"\"\"\n",
    "    # 1. Извлекаем сущности\n",
    "    entities = predict_entities(text, ner_model,\n",
    "                                tokenizer,\n",
    "                                id2label_ner)\n",
    "    # 2. Разбиваем текст на предложения\n",
    "    sentences = split_sentences(text)\n",
    "    relations = []\n",
    "    for sent in sentences:\n",
    "        sent_start = text.find(sent)\n",
    "        sent_end = sent_start + len(sent)\n",
    "        ents_in_sent = [e for e in entities if e['start'] >= sent_start and e['end'] <= sent_end]\n",
    "        # 3. Перебираем только допустимые пары внутри предложения\n",
    "        for ent1 in ents_in_sent:\n",
    "            for ent2 in ents_in_sent:\n",
    "                if ent1 == ent2:\n",
    "                    continue\n",
    "                # Только BODY_PART–SYMPTOM и BODY_PART–MEDICINE\n",
    "                if ent1['label'] == 'BODY_PART' and ent2['label'] == 'SYMPTOM':\n",
    "                    marked_text = insert_entity_markers(text, ent1, ent2)\n",
    "                    inputs = tokenizer(marked_text,\n",
    "                                       return_tensors='pt',\n",
    "                                       truncation=True,\n",
    "                                       max_length=256)\n",
    "                    inputs = {k: v.to(next(re_model.parameters()).device) for k, v in inputs.items()}\n",
    "                    with torch.no_grad():\n",
    "                        logits = re_model(**inputs).logits\n",
    "                        pred = logits.argmax(-1).item()\n",
    "                        rel_label = id2label_re[pred]\n",
    "                    if rel_label != 'no_relation':\n",
    "                        relations.append({'head': ent1,\n",
    "                                          'tail': ent2,\n",
    "                                          'relation': rel_label})\n",
    "                elif ent1['label'] == 'BODY_PART' and ent2['label'] == 'MEDICINE':\n",
    "                    marked_text = insert_entity_markers(text, ent1, ent2)\n",
    "                    inputs = tokenizer(marked_text,\n",
    "                                       return_tensors='pt',\n",
    "                                       truncation=True,\n",
    "                                       max_length=256)\n",
    "                    inputs = {k: v.to(next(re_model.parameters()).device) for k, v in inputs.items()}\n",
    "                    with torch.no_grad():\n",
    "                        logits = re_model(**inputs).logits\n",
    "                        pred = logits.argmax(-1).item()\n",
    "                        rel_label = id2label_re[pred]\n",
    "                    if rel_label != 'no_relation':\n",
    "                        relations.append({'head': ent1, 'tail': ent2, 'relation': rel_label})\n",
    "    return entities, relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC07XiJqwxsI"
   },
   "source": [
    "## Запуск пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "02e8f391af0840bfa4b91c67ccccc26d",
      "8c3be57727c4488eaef0ed20ca992223",
      "5e38ee2aa5fd4e2e9eaf4dbc217ef36e",
      "b4e7409dedab44009fc499fef5e8225a",
      "2b6b7931dfb34a2bb75fdf2a16ae7bce",
      "8b2debe2397f4a1fa2ebc08e1382c7b5",
      "cc766c1f11684d529103dd543052f857",
      "4ae82eaeb1fb429eb76e4a271c4aa826",
      "0ddec7ecc42f487ab1b14ff2024aec1a",
      "17dfdb822eab45cda405d63cddb832f6",
      "fc69fd6e2ad34795a477eb026bd60db6",
      "2c255f175fee4e348bef52f0c349672b",
      "7877df69b9844b1da4712e7c51f1d0e8",
      "a7d4b586c05d4ca38e43db9e773cc7a6",
      "b9fcf6d3b58c4179bd825016ef760455",
      "958a1af987c042f99903938a0cce10bb",
      "2b7007a54fa5453bbe1a9c4e84b5fe66",
      "2bbeab8b5db144c3b324f2e631f01dc4",
      "73ced4c5fe094a10a84bfd9cbf5dd4db",
      "51df127576174a228c6608d9736547ef",
      "8cb7acba16214dbcb582c94757698ea2",
      "c0cde6b7ca0e496ba4300f4773cd18a4",
      "f1587d9d0f324d4d88e770bb08ea5698",
      "9aa2970bd6d044629cd96d137dd02167",
      "51c2c2d4a375459d841643eca087bf13",
      "961cd81f23574200982195e954fb803e",
      "8b5644da55e346e88c6e8aee3b3cd8f2",
      "90796c4afe734738b635ccad8bb3701e",
      "5ec8ad785441485eaf358ae3c61ac33d",
      "178ceca309fb4f329a4a4821c8ebcd2b",
      "ebf39451fd1f446bb9e23624f4bcde60",
      "69a2ffebedb14d4f94ca5238e379a550",
      "63f9378721db43b6922e2881cf793bae"
     ]
    },
    "id": "5ImiWGcivFd7",
    "outputId": "2725df0b-0cfc-4722-916a-03111d8fbf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Начинаем обучение NER-модели ===\n",
      "Загружен исходный датасет размером 4143 сообщений\n",
      "Первые 5 строк исходного датасета:\n",
      "                                                text\n",
      "0             Утром проснулась с отекшими глазами)))\n",
      "1  Открывала окна без спандбонда, нормально, ниче...\n",
      "2  Пока изменений в худшую сторону нет. Каникулы,...\n",
      "3  Я сегодня еле разодрала глаза и до сих сдуться...\n",
      "4  Я тоже сегодня опухшая, надутая, глаза дерет, ...\n",
      "\n",
      "Тестовый проект уже существует, загружаем данные\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cd050b0110405ca562ad8797494ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер оставшегося датасета: 4043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель перемещена на cuda\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 50\n",
      "Найден существующий размеченный проект для размера 50\n",
      "После итерации 1 осталось 3993 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1be2814aea47abb3ed7ae8d248ec0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 50 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/70 00:18 < 00:47, 1.02 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.326650</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.017155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.205613</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.013295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.086585</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.011746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0172\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0199    0.1594    0.0354        69\n",
      " B-BODY_PART     0.0362    0.1039    0.0537        77\n",
      "  B-MEDICINE     0.0714    0.0784    0.0748        51\n",
      "   B-SYMPTOM     0.0508    0.0891    0.0647       101\n",
      "   B-TOPONYM     0.0227    0.0357    0.0278       196\n",
      "  I-ALLERGEN     0.0114    0.1000    0.0205        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.0641    0.2619    0.1030        84\n",
      "   I-SYMPTOM     0.0121    0.0164    0.0139       122\n",
      "   I-TOPONYM     0.0383    0.2045    0.0645        44\n",
      "           O     0.7521    0.1701    0.2775      2604\n",
      "\n",
      "    accuracy                         0.1518      3445\n",
      "   macro avg     0.0981    0.1109    0.0669      3445\n",
      "weighted avg     0.5763    0.1518    0.2205      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: ,, аю, Наз\n",
      "MEDICINE: Зиртек, но\n",
      "SYMPTOM: началась, ., ., сильная, .\n",
      "ALLERGEN: меня, ия, цу, приним, оне, цвете, принимаю\n",
      "BODY_PART: Наз\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 1:\n",
      "Counter({'SYMPTOM': 52, 'TOPONYM': 50, 'BODY_PART': 33, 'ALLERGEN': 32, 'MEDICINE': 29})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 100\n",
      "После итерации 2 осталось 3943 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c913c1f83a4336aa055c5a8e73c188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 100 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/130 00:27 < 01:08, 1.33 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.079891</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.011924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.817392</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.006826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.562923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0119\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0197    0.0870    0.0321        69\n",
      " B-BODY_PART     0.0244    0.0390    0.0300        77\n",
      "  B-MEDICINE     0.1379    0.0784    0.1000        51\n",
      "   B-SYMPTOM     0.0510    0.0495    0.0503       101\n",
      "   B-TOPONYM     0.0069    0.0051    0.0059       196\n",
      "  I-ALLERGEN     0.0112    0.0500    0.0183        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.0806    0.2024    0.1153        84\n",
      "   I-SYMPTOM     0.0083    0.0082    0.0082       122\n",
      "   I-TOPONYM     0.0161    0.0455    0.0238        44\n",
      "           O     0.7612    0.5534    0.6409      2604\n",
      "\n",
      "    accuracy                         0.4308      3445\n",
      "   macro avg     0.1016    0.1017    0.0932      3445\n",
      "weighted avg     0.5830    0.4308    0.4929      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: аю, Наз\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: началась, сильная, Эри\n",
      "ALLERGEN: меня, цу, приним, оне, принимаю\n",
      "BODY_PART: Наз\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 2:\n",
      "Counter({'TOPONYM': 66, 'SYMPTOM': 60, 'ALLERGEN': 40, 'BODY_PART': 37, 'MEDICINE': 30})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при выполнении get_project_tasks: status_code: 500, body: {'id': '34f36a6c-17da-4dd2-a468-aca0fa111efc', 'status_code': 500, 'version': '1.18.0', 'detail': 'connection already closed', 'exc_info': 'Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\views.py\", line 506, in dispatch\\n    response = handler(request, *args, **kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\utils\\\\decorators.py\", line 48, in _wrapper\\n    return bound_method(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 315, in get\\n    page = self.paginate_queryset(queryset)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\generics.py\", line 175, in paginate_queryset\\n    return self.paginator.paginate_queryset(queryset, self.request, view=self)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 240, in paginate_queryset\\n    return self.paginate_totals_queryset(queryset, request, view)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 230, in paginate_totals_queryset\\n    totals = queryset.values(\\'id\\').aggregate(\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 604, in aggregate\\n    return self.query.chain().get_aggregation(self.db, kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\sql\\\\query.py\", line 616, in get_aggregation\\n    result = compiler.execute_sql(SINGLE)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\sql\\\\compiler.py\", line 1574, in execute_sql\\n    cursor.execute(sql, params)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\utils.py\", line 1788, in runner\\n    return sentry_patched_function(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 652, in execute\\n    _set_db_data(span, self)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 717, in _set_db_data\\n    connection_params = cursor_or_db.connection.get_dsn_parameters()\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\npsycopg2.InterfaceError: connection already closed\\n'}. Попытка 1/5\n",
      "Найден существующий размеченный проект для размера 150\n",
      "После итерации 3 осталось 3893 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1643453a184e43bdb53d212b190aeaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 150 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 57/190 00:37 < 01:29, 1.49 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.710369</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.357767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.151297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0028\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
      " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
      "  B-MEDICINE     0.3333    0.0196    0.0370        51\n",
      "   B-SYMPTOM     0.0909    0.0099    0.0179       101\n",
      "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
      "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.1892    0.0833    0.1157        84\n",
      "   I-SYMPTOM     0.0222    0.0082    0.0120       122\n",
      "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
      "           O     0.7635    0.9424    0.8436      2604\n",
      "\n",
      "    accuracy                         0.7152      3445\n",
      "   macro avg     0.1272    0.0967    0.0933      3445\n",
      "weighted avg     0.5901    0.7152    0.6420      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: аю\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: не найдено\n",
      "ALLERGEN: меня\n",
      "BODY_PART: не найдено\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 3:\n",
      "Counter({'TOPONYM': 83, 'SYMPTOM': 61, 'ALLERGEN': 43, 'BODY_PART': 37, 'MEDICINE': 31})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 200\n",
      "После итерации 4 осталось 3843 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d33d0e308f478cb8e164fc99b57f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 200 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 75/250 00:46 < 01:50, 1.58 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.255394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.095546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.067458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0000\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
      " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
      "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
      "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
      "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
      "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
      "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
      "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
      "           O     0.7560    0.9969    0.8599      2604\n",
      "\n",
      "    accuracy                         0.7536      3445\n",
      "   macro avg     0.0687    0.0906    0.0782      3445\n",
      "weighted avg     0.5714    0.7536    0.6500      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: не найдено\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: не найдено\n",
      "ALLERGEN: не найдено\n",
      "BODY_PART: не найдено\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 4:\n",
      "Counter({'TOPONYM': 119, 'SYMPTOM': 92, 'ALLERGEN': 63, 'BODY_PART': 62, 'MEDICINE': 53})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 250\n",
      "После итерации 5 осталось 3793 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d648a31d18f4c58b7d778a37848b4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 250 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/320 00:55 < 02:12, 1.69 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.074276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.048084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.014652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
      " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
      "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
      "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
      "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
      "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
      "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
      "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
      "           O     0.7559    1.0000    0.8610      2604\n",
      "\n",
      "    accuracy                         0.7559      3445\n",
      "   macro avg     0.0687    0.0909    0.0783      3445\n",
      "weighted avg     0.5714    0.7559    0.6508      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: не найдено\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: не найдено\n",
      "ALLERGEN: не найдено\n",
      "BODY_PART: не найдено\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 5:\n",
      "Counter({'TOPONYM': 179, 'SYMPTOM': 166, 'BODY_PART': 109, 'ALLERGEN': 102, 'MEDICINE': 101})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 300\n",
      "После итерации 6 осталось 3743 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e56c6b35574c2f9f976242b506c067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 300 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/380 01:05 < 02:35, 1.71 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.046641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.006633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.974680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.0000\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
      " B-BODY_PART     0.0000    0.0000    0.0000        77\n",
      "  B-MEDICINE     0.0000    0.0000    0.0000        51\n",
      "   B-SYMPTOM     0.0000    0.0000    0.0000       101\n",
      "   B-TOPONYM     0.0000    0.0000    0.0000       196\n",
      "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.0000    0.0000    0.0000        84\n",
      "   I-SYMPTOM     0.0000    0.0000    0.0000       122\n",
      "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
      "           O     0.7561    1.0000    0.8611      2604\n",
      "\n",
      "    accuracy                         0.7559      3445\n",
      "   macro avg     0.0687    0.0909    0.0783      3445\n",
      "weighted avg     0.5715    0.7559    0.6509      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: не найдено\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: не найдено\n",
      "ALLERGEN: не найдено\n",
      "BODY_PART: не найдено\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 6:\n",
      "Counter({'SYMPTOM': 262, 'TOPONYM': 251, 'BODY_PART': 172, 'MEDICINE': 136, 'ALLERGEN': 122})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 350\n",
      "После итерации 7 осталось 3693 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8022083d0db849f89d42d56dfbec6207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 350 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 04:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.998308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.959294</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.015504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.878324</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.033835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.842981</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.036430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.811744</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.050201</td>\n",
       "      <td>0.085179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.790820</td>\n",
       "      <td>0.299213</td>\n",
       "      <td>0.076305</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.776179</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761162</td>\n",
       "      <td>0.302013</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.139104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.100402</td>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.1515\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.0000    0.0000    0.0000        69\n",
      " B-BODY_PART     0.8056    0.3766    0.5133        77\n",
      "  B-MEDICINE     1.0000    0.1569    0.2712        51\n",
      "   B-SYMPTOM     0.5500    0.3267    0.4099       101\n",
      "   B-TOPONYM     0.5714    0.0816    0.1429       196\n",
      "  I-ALLERGEN     0.0000    0.0000    0.0000        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.7368    0.3333    0.4590        84\n",
      "   I-SYMPTOM     0.4706    0.0656    0.1151       122\n",
      "   I-TOPONYM     0.0000    0.0000    0.0000        44\n",
      "           O     0.7897    0.9881    0.8779      2604\n",
      "\n",
      "    accuracy                         0.7823      3445\n",
      "   macro avg     0.4477    0.2117    0.2536      3445\n",
      "weighted avg     0.7130    0.7823    0.7145      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: не найдено\n",
      "MEDICINE: не найдено\n",
      "SYMPTOM: пот, слез\n",
      "ALLERGEN: не найдено\n",
      "BODY_PART: глаза, нос, глаза, уши, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 7:\n",
      "Counter({'SYMPTOM': 385, 'TOPONYM': 314, 'BODY_PART': 247, 'MEDICINE': 173, 'ALLERGEN': 135})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 400\n",
      "После итерации 8 осталось 3643 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f78811ab27a46c8b8f3ffebcac3a0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 400 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 04:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701246</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.206827</td>\n",
       "      <td>0.270341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.652081</td>\n",
       "      <td>0.425134</td>\n",
       "      <td>0.319277</td>\n",
       "      <td>0.364679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.623924</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.443077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.577853</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.468938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.564276</td>\n",
       "      <td>0.456294</td>\n",
       "      <td>0.524096</td>\n",
       "      <td>0.487850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.550945</td>\n",
       "      <td>0.448505</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.490909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530452</td>\n",
       "      <td>0.462057</td>\n",
       "      <td>0.550201</td>\n",
       "      <td>0.502291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.463295</td>\n",
       "      <td>0.570281</td>\n",
       "      <td>0.511251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.461290</td>\n",
       "      <td>0.574297</td>\n",
       "      <td>0.511628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.519775</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.513369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.5134\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8250    0.4783    0.6055        69\n",
      " B-BODY_PART     0.7065    0.8442    0.7692        77\n",
      "  B-MEDICINE     0.7500    0.4706    0.5783        51\n",
      "   B-SYMPTOM     0.5139    0.7327    0.6041       101\n",
      "   B-TOPONYM     0.5934    0.7296    0.6545       196\n",
      "  I-ALLERGEN     1.0000    0.0750    0.1395        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.6633    0.7738    0.7143        84\n",
      "   I-SYMPTOM     0.4923    0.7869    0.6057       122\n",
      "   I-TOPONYM     1.0000    0.0455    0.0870        44\n",
      "           O     0.9264    0.9232    0.9248      2604\n",
      "\n",
      "    accuracy                         0.8453      3445\n",
      "   macro avg     0.6792    0.5327    0.5166      3445\n",
      "weighted avg     0.8621    0.8453    0.8351      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: .\n",
      "MEDICINE: Зиртек, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: пыльцу, потекли, Наз, чешутся, течет, слезятся\n",
      "ALLERGEN: берез, ы, оль\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 8:\n",
      "Counter({'SYMPTOM': 497, 'TOPONYM': 366, 'BODY_PART': 331, 'MEDICINE': 204, 'ALLERGEN': 144})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 450\n",
      "После итерации 9 осталось 3593 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b890c72eea040b79762a9a6bd104082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 450 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 05:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486102</td>\n",
       "      <td>0.492936</td>\n",
       "      <td>0.630522</td>\n",
       "      <td>0.553304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472945</td>\n",
       "      <td>0.484352</td>\n",
       "      <td>0.652610</td>\n",
       "      <td>0.556031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455163</td>\n",
       "      <td>0.487699</td>\n",
       "      <td>0.676707</td>\n",
       "      <td>0.566863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434806</td>\n",
       "      <td>0.510324</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.588435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.422223</td>\n",
       "      <td>0.522963</td>\n",
       "      <td>0.708835</td>\n",
       "      <td>0.601876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.407766</td>\n",
       "      <td>0.535552</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.610871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.616438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.401464</td>\n",
       "      <td>0.548580</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.628963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.396952</td>\n",
       "      <td>0.551360</td>\n",
       "      <td>0.732932</td>\n",
       "      <td>0.629310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.395573</td>\n",
       "      <td>0.553869</td>\n",
       "      <td>0.732932</td>\n",
       "      <td>0.630942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.6309\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7547    0.5797    0.6557        69\n",
      " B-BODY_PART     0.7283    0.8701    0.7929        77\n",
      "  B-MEDICINE     0.6596    0.6078    0.6327        51\n",
      "   B-SYMPTOM     0.5827    0.8020    0.6750       101\n",
      "   B-TOPONYM     0.6667    0.9388    0.7797       196\n",
      "  I-ALLERGEN     1.0000    0.2875    0.4466        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.6900    0.8214    0.7500        84\n",
      "   I-SYMPTOM     0.4739    0.8197    0.6006       122\n",
      "   I-TOPONYM     1.0000    0.5909    0.7429        44\n",
      "           O     0.9605    0.9140    0.9366      2604\n",
      "\n",
      "    accuracy                         0.8711      3445\n",
      "   macro avg     0.6833    0.6574    0.6375      3445\n",
      "weighted avg     0.8918    0.8711    0.8718      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московской, ., Новокузнецке, .\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: пыльцу, потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 9:\n",
      "Counter({'SYMPTOM': 571, 'TOPONYM': 416, 'BODY_PART': 388, 'MEDICINE': 222, 'ALLERGEN': 164})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 500\n",
      "После итерации 10 осталось 3543 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4955baffee41159bcf000ced660a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 500 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 05:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.382078</td>\n",
       "      <td>0.550445</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.633106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378969</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.639594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.365513</td>\n",
       "      <td>0.568657</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.652397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.364889</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.779116</td>\n",
       "      <td>0.659303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.337904</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.785141</td>\n",
       "      <td>0.684764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341193</td>\n",
       "      <td>0.601527</td>\n",
       "      <td>0.791165</td>\n",
       "      <td>0.683435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>0.607088</td>\n",
       "      <td>0.791165</td>\n",
       "      <td>0.687010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.335462</td>\n",
       "      <td>0.607034</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.689236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.332145</td>\n",
       "      <td>0.614198</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.694590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.331252</td>\n",
       "      <td>0.616099</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.695804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.6958\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7361    0.7681    0.7518        69\n",
      " B-BODY_PART     0.7614    0.8701    0.8121        77\n",
      "  B-MEDICINE     0.6604    0.6863    0.6731        51\n",
      "   B-SYMPTOM     0.6412    0.8317    0.7241       101\n",
      "   B-TOPONYM     0.7083    0.9541    0.8130       196\n",
      "  I-ALLERGEN     0.9792    0.5875    0.7344        80\n",
      " I-BODY_PART     0.0000    0.0000    0.0000        17\n",
      "  I-MEDICINE     0.7340    0.8214    0.7753        84\n",
      "   I-SYMPTOM     0.5258    0.8361    0.6456       122\n",
      "   I-TOPONYM     0.8780    0.8182    0.8471        44\n",
      "           O     0.9687    0.9151    0.9412      2604\n",
      "\n",
      "    accuracy                         0.8891      3445\n",
      "   macro avg     0.6903    0.7353    0.7016      3445\n",
      "weighted avg     0.9033    0.8891    0.8917      3445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Модель сохранена в models/pollen_ner_500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московской, Новокузнецке, .\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 10:\n",
      "Counter({'SYMPTOM': 627, 'TOPONYM': 465, 'BODY_PART': 422, 'MEDICINE': 245, 'ALLERGEN': 189})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 550\n",
      "После итерации 11 осталось 3493 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501dfcd9ada543abb3f41c5aa20829f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/550 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 550 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='621' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [621/690 05:36 < 00:37, 1.84 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311787</td>\n",
       "      <td>0.633648</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.710758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295272</td>\n",
       "      <td>0.653094</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.721223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301376</td>\n",
       "      <td>0.646130</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.723254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299421</td>\n",
       "      <td>0.646782</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.725991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289205</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.726790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285090</td>\n",
       "      <td>0.659744</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.734875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272591</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.747731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.275135</td>\n",
       "      <td>0.674304</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.743012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.279685</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.741472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.7477\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7639    0.7971    0.7801        69\n",
      " B-BODY_PART     0.8193    0.8831    0.8500        77\n",
      "  B-MEDICINE     0.7222    0.7647    0.7429        51\n",
      "   B-SYMPTOM     0.6905    0.8614    0.7665       101\n",
      "   B-TOPONYM     0.7746    0.9643    0.8591       196\n",
      "  I-ALLERGEN     0.9649    0.6875    0.8029        80\n",
      " I-BODY_PART     0.7500    0.1765    0.2857        17\n",
      "  I-MEDICINE     0.7556    0.8095    0.7816        84\n",
      "   I-SYMPTOM     0.5862    0.8361    0.6892       122\n",
      "   I-TOPONYM     0.8636    0.8636    0.8636        44\n",
      "           O     0.9708    0.9309    0.9504      2604\n",
      "\n",
      "    accuracy                         0.9080      3445\n",
      "   macro avg     0.7874    0.7795    0.7611      3445\n",
      "weighted avg     0.9187    0.9080    0.9099      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 11:\n",
      "Counter({'SYMPTOM': 685, 'TOPONYM': 514, 'BODY_PART': 457, 'MEDICINE': 274, 'ALLERGEN': 207})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 600\n",
      "После итерации 12 осталось 3443 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f17901579fc4f358246fa1c12a4db5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 600 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/750 04:42 < 02:01, 1.85 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267017</td>\n",
       "      <td>0.678748</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.745701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260539</td>\n",
       "      <td>0.687603</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.754306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252973</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.761644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263259</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.758497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252761</td>\n",
       "      <td>0.709732</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.773309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252328</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.773017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.253066</td>\n",
       "      <td>0.705193</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.768950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.7733\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7733    0.8406    0.8056        69\n",
      " B-BODY_PART     0.8434    0.9091    0.8750        77\n",
      "  B-MEDICINE     0.7586    0.8627    0.8073        51\n",
      "   B-SYMPTOM     0.6769    0.8713    0.7619       101\n",
      "   B-TOPONYM     0.8289    0.9643    0.8915       196\n",
      "  I-ALLERGEN     0.9661    0.7125    0.8201        80\n",
      " I-BODY_PART     0.8571    0.3529    0.5000        17\n",
      "  I-MEDICINE     0.7582    0.8214    0.7886        84\n",
      "   I-SYMPTOM     0.5965    0.8361    0.6962       122\n",
      "   I-TOPONYM     0.8636    0.8636    0.8636        44\n",
      "           O     0.9740    0.9347    0.9539      2604\n",
      "\n",
      "    accuracy                         0.9158      3445\n",
      "   macro avg     0.8088    0.8154    0.7967      3445\n",
      "weighted avg     0.9261    0.9158    0.9182      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 12:\n",
      "Counter({'SYMPTOM': 777, 'TOPONYM': 561, 'BODY_PART': 521, 'MEDICINE': 304, 'ALLERGEN': 232})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 650\n",
      "После итерации 13 осталось 3393 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c6277df85940c4b06fbca5ced984e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 650 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='410' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [410/820 03:37 < 03:38, 1.88 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254825</td>\n",
       "      <td>0.694943</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.766877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248789</td>\n",
       "      <td>0.711409</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.775137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.230686</td>\n",
       "      <td>0.742215</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.797398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242279</td>\n",
       "      <td>0.714524</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.780310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241419</td>\n",
       "      <td>0.724080</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.790146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.7974\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7838    0.8406    0.8112        69\n",
      " B-BODY_PART     0.8537    0.9091    0.8805        77\n",
      "  B-MEDICINE     0.7458    0.8627    0.8000        51\n",
      "   B-SYMPTOM     0.6992    0.8515    0.7679       101\n",
      "   B-TOPONYM     0.8527    0.9745    0.9095       196\n",
      "  I-ALLERGEN     0.9538    0.7750    0.8552        80\n",
      " I-BODY_PART     0.8571    0.3529    0.5000        17\n",
      "  I-MEDICINE     0.7609    0.8333    0.7955        84\n",
      "   I-SYMPTOM     0.6497    0.8361    0.7312       122\n",
      "   I-TOPONYM     0.8636    0.8636    0.8636        44\n",
      "           O     0.9750    0.9428    0.9586      2604\n",
      "\n",
      "    accuracy                         0.9237      3445\n",
      "   macro avg     0.8177    0.8220    0.8066      3445\n",
      "weighted avg     0.9308    0.9237    0.9253      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, в, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 13:\n",
      "Counter({'SYMPTOM': 859, 'TOPONYM': 610, 'BODY_PART': 579, 'MEDICINE': 349, 'ALLERGEN': 262})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 700\n",
      "После итерации 14 осталось 3343 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf1cf03ac24d74a470a4c586ac1053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 700 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='880' max='880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [880/880 07:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.746946</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.799253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.217379</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.809031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221575</td>\n",
       "      <td>0.760070</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.811974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.215565</td>\n",
       "      <td>0.769094</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.816211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.226703</td>\n",
       "      <td>0.742321</td>\n",
       "      <td>0.873494</td>\n",
       "      <td>0.802583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>0.770870</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.818096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.211781</td>\n",
       "      <td>0.772647</td>\n",
       "      <td>0.873494</td>\n",
       "      <td>0.819981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.207548</td>\n",
       "      <td>0.771681</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.820320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.205599</td>\n",
       "      <td>0.777184</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.823418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.209094</td>\n",
       "      <td>0.770723</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.820657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8234\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7922    0.8841    0.8356        69\n",
      " B-BODY_PART     0.9211    0.9091    0.9150        77\n",
      "  B-MEDICINE     0.7857    0.8627    0.8224        51\n",
      "   B-SYMPTOM     0.7016    0.8614    0.7733       101\n",
      "   B-TOPONYM     0.8967    0.9745    0.9340       196\n",
      "  I-ALLERGEN     0.9118    0.7750    0.8378        80\n",
      " I-BODY_PART     1.0000    0.7059    0.8276        17\n",
      "  I-MEDICINE     0.7609    0.8333    0.7955        84\n",
      "   I-SYMPTOM     0.6755    0.8361    0.7473       122\n",
      "   I-TOPONYM     0.8837    0.8636    0.8736        44\n",
      "           O     0.9747    0.9482    0.9613      2604\n",
      "\n",
      "    accuracy                         0.9306      3445\n",
      "   macro avg     0.8458    0.8594    0.8476      3445\n",
      "weighted avg     0.9363    0.9306    0.9323      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цветение, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 14:\n",
      "Counter({'SYMPTOM': 928, 'TOPONYM': 650, 'BODY_PART': 626, 'MEDICINE': 367, 'ALLERGEN': 285})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 750\n",
      "После итерации 15 осталось 3293 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23682de9cd74465ab8707b23de4bc8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 750 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='658' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [658/940 05:49 < 02:30, 1.88 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.197889</td>\n",
       "      <td>0.780180</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.822412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206329</td>\n",
       "      <td>0.758261</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.812675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199125</td>\n",
       "      <td>0.776991</td>\n",
       "      <td>0.881526</td>\n",
       "      <td>0.825964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196862</td>\n",
       "      <td>0.782531</td>\n",
       "      <td>0.881526</td>\n",
       "      <td>0.829084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193072</td>\n",
       "      <td>0.795332</td>\n",
       "      <td>0.889558</td>\n",
       "      <td>0.839810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.187259</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.839201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.194998</td>\n",
       "      <td>0.780919</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.830827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8398\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7831    0.9420    0.8553        69\n",
      " B-BODY_PART     0.9333    0.9091    0.9211        77\n",
      "  B-MEDICINE     0.7857    0.8627    0.8224        51\n",
      "   B-SYMPTOM     0.7768    0.8614    0.8169       101\n",
      "   B-TOPONYM     0.9095    0.9745    0.9409       196\n",
      "  I-ALLERGEN     0.8684    0.8250    0.8462        80\n",
      " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
      "  I-MEDICINE     0.7692    0.8333    0.8000        84\n",
      "   I-SYMPTOM     0.7376    0.8525    0.7909       122\n",
      "   I-TOPONYM     0.8837    0.8636    0.8736        44\n",
      "           O     0.9760    0.9531    0.9644      2604\n",
      "\n",
      "    accuracy                         0.9379      3445\n",
      "   macro avg     0.8506    0.8819    0.8642      3445\n",
      "weighted avg     0.9414    0.9379    0.9390      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цветение, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 15:\n",
      "Counter({'SYMPTOM': 1000, 'TOPONYM': 706, 'BODY_PART': 684, 'MEDICINE': 391, 'ALLERGEN': 323})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 800\n",
      "После итерации 16 осталось 3243 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1db2c12cda749cab9288bee5d0a4825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 800 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 600/1000 05:18 < 03:32, 1.88 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.186665</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.835227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.799639</td>\n",
       "      <td>0.889558</td>\n",
       "      <td>0.842205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180135</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.847328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.178704</td>\n",
       "      <td>0.807971</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.849524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>0.182947</td>\n",
       "      <td>0.800360</td>\n",
       "      <td>0.893574</td>\n",
       "      <td>0.844402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>0.182408</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.893574</td>\n",
       "      <td>0.845204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8495\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7831    0.9420    0.8553        69\n",
      " B-BODY_PART     0.9351    0.9351    0.9351        77\n",
      "  B-MEDICINE     0.8182    0.8824    0.8491        51\n",
      "   B-SYMPTOM     0.8056    0.8614    0.8325       101\n",
      "   B-TOPONYM     0.9183    0.9745    0.9455       196\n",
      "  I-ALLERGEN     0.8816    0.8375    0.8590        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.7865    0.8333    0.8092        84\n",
      "   I-SYMPTOM     0.7536    0.8525    0.8000       122\n",
      "   I-TOPONYM     0.9070    0.8864    0.8966        44\n",
      "           O     0.9777    0.9589    0.9682      2604\n",
      "\n",
      "    accuracy                         0.9437      3445\n",
      "   macro avg     0.8697    0.8898    0.8776      3445\n",
      "weighted avg     0.9464    0.9437    0.9446      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цветение, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 16:\n",
      "Counter({'SYMPTOM': 1095, 'TOPONYM': 758, 'BODY_PART': 748, 'MEDICINE': 438, 'ALLERGEN': 352})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 850\n",
      "После итерации 17 осталось 3193 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f4b478ca074336925998f01ee50cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 850 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 642/1070 05:36 < 03:45, 1.90 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.188829</td>\n",
       "      <td>0.797153</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.845283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174602</td>\n",
       "      <td>0.813528</td>\n",
       "      <td>0.893574</td>\n",
       "      <td>0.851675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168981</td>\n",
       "      <td>0.824953</td>\n",
       "      <td>0.889558</td>\n",
       "      <td>0.856039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172850</td>\n",
       "      <td>0.819013</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.857416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>0.805009</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.851466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>0.182888</td>\n",
       "      <td>0.796099</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.845574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8574\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8049    0.9565    0.8742        69\n",
      " B-BODY_PART     0.9351    0.9351    0.9351        77\n",
      "  B-MEDICINE     0.8182    0.8824    0.8491        51\n",
      "   B-SYMPTOM     0.8286    0.8614    0.8447       101\n",
      "   B-TOPONYM     0.9183    0.9745    0.9455       196\n",
      "  I-ALLERGEN     0.9067    0.8500    0.8774        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8046    0.8333    0.8187        84\n",
      "   I-SYMPTOM     0.7664    0.8607    0.8108       122\n",
      "   I-TOPONYM     0.9048    0.8636    0.8837        44\n",
      "           O     0.9778    0.9624    0.9700      2604\n",
      "\n",
      "    accuracy                         0.9469      3445\n",
      "   macro avg     0.8787    0.8912    0.8829      3445\n",
      "weighted avg     0.9490    0.9469    0.9475      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 17:\n",
      "Counter({'SYMPTOM': 1190, 'TOPONYM': 811, 'BODY_PART': 809, 'MEDICINE': 476, 'ALLERGEN': 376})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 900\n",
      "После итерации 18 осталось 3143 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c4133baa6e4559abd65f0a99575c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 900 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='339' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 339/1130 02:57 < 06:55, 1.90 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.173326</td>\n",
       "      <td>0.816697</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.857960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172147</td>\n",
       "      <td>0.809353</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.853890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172418</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.854701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8580\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.7882    0.9710    0.8701        69\n",
      " B-BODY_PART     0.9351    0.9351    0.9351        77\n",
      "  B-MEDICINE     0.8036    0.8824    0.8411        51\n",
      "   B-SYMPTOM     0.8208    0.8614    0.8406       101\n",
      "   B-TOPONYM     0.9183    0.9745    0.9455       196\n",
      "  I-ALLERGEN     0.9091    0.8750    0.8917        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.7912    0.8571    0.8229        84\n",
      "   I-SYMPTOM     0.7609    0.8607    0.8077       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9800    0.9593    0.9695      2604\n",
      "\n",
      "    accuracy                         0.9466      3445\n",
      "   macro avg     0.8742    0.9008    0.8851      3445\n",
      "weighted avg     0.9495    0.9466    0.9475      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, цвете, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 18:\n",
      "Counter({'SYMPTOM': 1266, 'TOPONYM': 854, 'BODY_PART': 841, 'MEDICINE': 511, 'ALLERGEN': 403})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 950\n",
      "После итерации 19 осталось 3093 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39c0f777d464784bc2aa805d6c83310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 950 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='595' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 595/1190 05:11 < 05:12, 1.90 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.173894</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.855513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.178790</td>\n",
       "      <td>0.797153</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.845283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172289</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.164387</td>\n",
       "      <td>0.816697</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.857960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.164319</td>\n",
       "      <td>0.814079</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.857414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8580\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8000    0.9855    0.8831        69\n",
      " B-BODY_PART     0.9351    0.9351    0.9351        77\n",
      "  B-MEDICINE     0.8036    0.8824    0.8411        51\n",
      "   B-SYMPTOM     0.8148    0.8713    0.8421       101\n",
      "   B-TOPONYM     0.9227    0.9745    0.9479       196\n",
      "  I-ALLERGEN     0.9231    0.9000    0.9114        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.7912    0.8571    0.8229        84\n",
      "   I-SYMPTOM     0.7778    0.8607    0.8171       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9816    0.9612    0.9713      2604\n",
      "\n",
      "    accuracy                         0.9492      3445\n",
      "   macro avg     0.8781    0.9055    0.8895      3445\n",
      "weighted avg     0.9520    0.9492    0.9501      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 19:\n",
      "Counter({'SYMPTOM': 1330, 'TOPONYM': 910, 'BODY_PART': 880, 'MEDICINE': 530, 'ALLERGEN': 435})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1000\n",
      "После итерации 20 осталось 3043 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48fcdb19531453a89d925c60e01bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1000 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 625/1250 05:27 < 05:28, 1.91 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.157524</td>\n",
       "      <td>0.834879</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.867888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167124</td>\n",
       "      <td>0.817690</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.861217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.833948</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.869231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.155575</td>\n",
       "      <td>0.830571</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.866475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0.827839</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.865900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8692\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8095    0.9855    0.8889        69\n",
      " B-BODY_PART     0.9600    0.9351    0.9474        77\n",
      "  B-MEDICINE     0.8364    0.9020    0.8679        51\n",
      "   B-SYMPTOM     0.8462    0.8713    0.8585       101\n",
      "   B-TOPONYM     0.9272    0.9745    0.9502       196\n",
      "  I-ALLERGEN     0.9231    0.9000    0.9114        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8090    0.8571    0.8324        84\n",
      "   I-SYMPTOM     0.8281    0.8689    0.8480       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9825    0.9689    0.9756      2604\n",
      "\n",
      "    accuracy                         0.9556      3445\n",
      "   macro avg     0.8937    0.9087    0.8993      3445\n",
      "weighted avg     0.9573    0.9556    0.9561      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 20:\n",
      "Counter({'SYMPTOM': 1410, 'TOPONYM': 961, 'BODY_PART': 948, 'MEDICINE': 565, 'ALLERGEN': 457})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1050\n",
      "После итерации 21 осталось 2993 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b170199ec664ce2a5a9a885017871fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1050 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1050 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='396' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 396/1320 03:25 < 08:01, 1.92 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.159408</td>\n",
       "      <td>0.828467</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.868069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163260</td>\n",
       "      <td>0.826958</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.867240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.160566</td>\n",
       "      <td>0.826642</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.866157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8681\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8095    0.9855    0.8889        69\n",
      " B-BODY_PART     0.9359    0.9481    0.9419        77\n",
      "  B-MEDICINE     0.8214    0.9020    0.8598        51\n",
      "   B-SYMPTOM     0.8447    0.8614    0.8529       101\n",
      "   B-TOPONYM     0.9227    0.9745    0.9479       196\n",
      "  I-ALLERGEN     0.9125    0.9125    0.9125        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8090    0.8571    0.8324        84\n",
      "   I-SYMPTOM     0.7786    0.8934    0.8321       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9835    0.9631    0.9732      2604\n",
      "\n",
      "    accuracy                         0.9524      3445\n",
      "   macro avg     0.8843    0.9118    0.8958      3445\n",
      "weighted avg     0.9550    0.9524    0.9532      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, ., Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 21:\n",
      "Counter({'SYMPTOM': 1555, 'BODY_PART': 1027, 'TOPONYM': 1013, 'MEDICINE': 598, 'ALLERGEN': 474})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при выполнении get_project_tasks: status_code: 500, body: {'id': '16ffec2b-01bc-424d-b2a1-96b5e9f05d4d', 'status_code': 500, 'version': '1.18.0', 'detail': 'connection already closed', 'exc_info': 'Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\views.py\", line 506, in dispatch\\n    response = handler(request, *args, **kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\utils\\\\decorators.py\", line 48, in _wrapper\\n    return bound_method(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 352, in get\\n    return self.get_paginated_response(serializer.data)\\n                                       ^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 795, in data\\n    ret = super().data\\n          ^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 249, in data\\n    self._data = self.to_representation(self.instance)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 714, in to_representation\\n    self.child.to_representation(item) for item in iterable\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\serializers.py\", line 370, in to_representation\\n    ret = super(DataManagerTaskSerializer, self).to_representation(obj)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\tasks\\\\serializers.py\", line 193, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_flex_fields\\\\serializers.py\", line 64, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 538, in to_representation\\n    ret[field.field_name] = field.to_representation(attribute)\\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\relations.py\", line 566, in to_representation\\n    for value in iterable\\n                 ^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 400, in __iter__\\n    self._fetch_all()\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 1928, in _fetch_all\\n    self._result_cache = list(self._iterable_class(self))\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 91, in __iter__\\n    results = compiler.execute_sql(\\n              ^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\sql\\\\compiler.py\", line 1574, in execute_sql\\n    cursor.execute(sql, params)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\utils.py\", line 1788, in runner\\n    return sentry_patched_function(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 652, in execute\\n    _set_db_data(span, self)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 717, in _set_db_data\\n    connection_params = cursor_or_db.connection.get_dsn_parameters()\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\npsycopg2.InterfaceError: connection already closed\\n'}. Попытка 1/5\n",
      "Найден существующий размеченный проект для размера 1100\n",
      "После итерации 22 осталось 2943 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63dfef3f789741d5bace9949c12c153e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1100 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='552' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 552/1380 04:46 < 07:10, 1.92 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.151078</td>\n",
       "      <td>0.841418</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150853</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.878993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155730</td>\n",
       "      <td>0.836697</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.874401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8790\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8095    0.9855    0.8889        69\n",
      " B-BODY_PART     0.9367    0.9610    0.9487        77\n",
      "  B-MEDICINE     0.8364    0.9020    0.8679        51\n",
      "   B-SYMPTOM     0.8286    0.8614    0.8447       101\n",
      "   B-TOPONYM     0.9409    0.9745    0.9574       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8372    0.8571    0.8471        84\n",
      "   I-SYMPTOM     0.8346    0.8689    0.8514       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9837    0.9712    0.9774      2604\n",
      "\n",
      "    accuracy                         0.9579      3445\n",
      "   macro avg     0.8968    0.9115    0.9023      3445\n",
      "weighted avg     0.9594    0.9579    0.9583      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 22:\n",
      "Counter({'SYMPTOM': 1634, 'BODY_PART': 1099, 'TOPONYM': 1071, 'MEDICINE': 615, 'ALLERGEN': 482})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1150\n",
      "После итерации 23 осталось 2893 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaa3eb5fd9843008db2cb399e96553c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1150 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='864' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 864/1440 07:28 < 04:59, 1.92 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.152933</td>\n",
       "      <td>0.848881</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.880077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.855805</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.885659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149908</td>\n",
       "      <td>0.854478</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.885880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.146455</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.888241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.156602</td>\n",
       "      <td>0.839122</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.878469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.151417</td>\n",
       "      <td>0.854478</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.885880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8882\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8193    0.9855    0.8947        69\n",
      " B-BODY_PART     0.9487    0.9610    0.9548        77\n",
      "  B-MEDICINE     0.8246    0.9216    0.8704        51\n",
      "   B-SYMPTOM     0.8614    0.8614    0.8614       101\n",
      "   B-TOPONYM     0.9550    0.9745    0.9646       196\n",
      "  I-ALLERGEN     0.9605    0.9125    0.9359        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8182    0.8571    0.8372        84\n",
      "   I-SYMPTOM     0.8385    0.8934    0.8651       122\n",
      "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
      "           O     0.9848    0.9731    0.9789      2604\n",
      "\n",
      "    accuracy                         0.9608      3445\n",
      "   macro avg     0.9020    0.9178    0.9080      3445\n",
      "weighted avg     0.9623    0.9608    0.9613      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 23:\n",
      "Counter({'SYMPTOM': 1718, 'BODY_PART': 1158, 'TOPONYM': 1128, 'MEDICINE': 641, 'ALLERGEN': 497})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1200\n",
      "После итерации 24 осталось 2843 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c83592846e4468ca86f8fa4c97ce4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1200 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 13:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140117</td>\n",
       "      <td>0.860377</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.887160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.881159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.140879</td>\n",
       "      <td>0.860640</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.888241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.143825</td>\n",
       "      <td>0.855535</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.884578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.140381</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.892788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.142893</td>\n",
       "      <td>0.865530</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.890838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.138565</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.258300</td>\n",
       "      <td>0.140343</td>\n",
       "      <td>0.867675</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.893866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.140914</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.891051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8945\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9487    0.9610    0.9548        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8544    0.8713    0.8627       101\n",
      "   B-TOPONYM     0.9598    0.9745    0.9671       196\n",
      "  I-ALLERGEN     0.9605    0.9125    0.9359        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8721    0.8929    0.8824        84\n",
      "   I-SYMPTOM     0.8492    0.8770    0.8629       122\n",
      "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
      "           O     0.9857    0.9770    0.9813      2604\n",
      "\n",
      "    accuracy                         0.9643      3445\n",
      "   macro avg     0.9114    0.9208    0.9145      3445\n",
      "weighted avg     0.9654    0.9643    0.9646      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 24:\n",
      "Counter({'SYMPTOM': 1790, 'BODY_PART': 1220, 'TOPONYM': 1181, 'MEDICINE': 663, 'ALLERGEN': 507})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1250\n",
      "После итерации 25 осталось 2793 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6917d33436634ebba07a1ed1fd6a4322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1250 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 471/1570 04:02 < 09:28, 1.93 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145527</td>\n",
       "      <td>0.861423</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.891473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140582</td>\n",
       "      <td>0.862524</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.890185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141999</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.889535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8915\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9487    0.9610    0.9548        77\n",
      "  B-MEDICINE     0.8246    0.9216    0.8704        51\n",
      "   B-SYMPTOM     0.8318    0.8812    0.8558       101\n",
      "   B-TOPONYM     0.9598    0.9745    0.9671       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8352    0.9048    0.8686        84\n",
      "   I-SYMPTOM     0.8258    0.8934    0.8583       122\n",
      "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
      "           O     0.9867    0.9712    0.9789      2604\n",
      "\n",
      "    accuracy                         0.9611      3445\n",
      "   macro avg     0.9001    0.9237    0.9099      3445\n",
      "weighted avg     0.9631    0.9611    0.9617      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 25:\n",
      "Counter({'SYMPTOM': 1883, 'BODY_PART': 1279, 'TOPONYM': 1231, 'MEDICINE': 682, 'ALLERGEN': 537})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1300\n",
      "После итерации 26 осталось 2743 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fed8609c6b04fb08f9a152ad8e8c3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1300 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='489' max='1630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 489/1630 04:11 < 09:50, 1.93 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136530</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.895201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>0.863894</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.889971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136911</td>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.892578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8952\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9481    0.9481    0.9481        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8713    0.8713    0.8713       101\n",
      "   B-TOPONYM     0.9646    0.9745    0.9695       196\n",
      "  I-ALLERGEN     0.9605    0.9125    0.9359        80\n",
      " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
      "  I-MEDICINE     0.8621    0.8929    0.8772        84\n",
      "   I-SYMPTOM     0.8640    0.8852    0.8745       122\n",
      "   I-TOPONYM     0.9091    0.9091    0.9091        44\n",
      "           O     0.9853    0.9781    0.9817      2604\n",
      "\n",
      "    accuracy                         0.9649      3445\n",
      "   macro avg     0.9075    0.9184    0.9118      3445\n",
      "weighted avg     0.9658    0.9649    0.9651      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 26:\n",
      "Counter({'SYMPTOM': 1965, 'BODY_PART': 1340, 'TOPONYM': 1295, 'MEDICINE': 718, 'ALLERGEN': 553})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при выполнении get_project_tasks: status_code: 500, body: {'id': 'cdba6f81-9944-4495-bcde-f7925b0dc374', 'status_code': 500, 'version': '1.18.0', 'detail': 'connection already closed', 'exc_info': 'Traceback (most recent call last):\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\views.py\", line 506, in dispatch\\n    response = handler(request, *args, **kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\utils\\\\decorators.py\", line 48, in _wrapper\\n    return bound_method(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\api.py\", line 352, in get\\n    return self.get_paginated_response(serializer.data)\\n                                       ^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 795, in data\\n    ret = super().data\\n          ^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 249, in data\\n    self._data = self.to_representation(self.instance)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 714, in to_representation\\n    self.child.to_representation(item) for item in iterable\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\data_manager\\\\serializers.py\", line 370, in to_representation\\n    ret = super(DataManagerTaskSerializer, self).to_representation(obj)\\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\label_studio\\\\tasks\\\\serializers.py\", line 193, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_flex_fields\\\\serializers.py\", line 64, in to_representation\\n    return super().to_representation(instance)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\serializers.py\", line 538, in to_representation\\n    ret[field.field_name] = field.to_representation(attribute)\\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\rest_framework\\\\relations.py\", line 566, in to_representation\\n    for value in iterable\\n                 ^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 400, in __iter__\\n    self._fetch_all()\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 1928, in _fetch_all\\n    self._result_cache = list(self._iterable_class(self))\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\query.py\", line 91, in __iter__\\n    results = compiler.execute_sql(\\n              ^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\django\\\\db\\\\models\\\\sql\\\\compiler.py\", line 1574, in execute_sql\\n    cursor.execute(sql, params)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\utils.py\", line 1788, in runner\\n    return sentry_patched_function(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 652, in execute\\n    _set_db_data(span, self)\\n  File \"C:\\\\Users\\\\ivanm\\\\anaconda3\\\\Lib\\\\site-packages\\\\sentry_sdk\\\\integrations\\\\django\\\\__init__.py\", line 717, in _set_db_data\\n    connection_params = cursor_or_db.connection.get_dsn_parameters()\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\npsycopg2.InterfaceError: connection already closed\\n'}. Попытка 1/5\n",
      "Найден существующий размеченный проект для размера 1350\n",
      "После итерации 27 осталось 2693 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58469fbf907d45a4be073b78f1a4e4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1350 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='845' max='1690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 845/1690 07:16 < 07:17, 1.93 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140392</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.888458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137651</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.892128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241800</td>\n",
       "      <td>0.133709</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.895813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241800</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.894942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241800</td>\n",
       "      <td>0.128706</td>\n",
       "      <td>0.872381</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.895406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8958\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9610    0.9610    0.9610        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8476    0.8812    0.8641       101\n",
      "   B-TOPONYM     0.9646    0.9745    0.9695       196\n",
      "  I-ALLERGEN     0.9605    0.9125    0.9359        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8261    0.9048    0.8636        84\n",
      "   I-SYMPTOM     0.8504    0.8852    0.8675       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9868    0.9750    0.9809      2604\n",
      "\n",
      "    accuracy                         0.9640      3445\n",
      "   macro avg     0.9085    0.9254    0.9151      3445\n",
      "weighted avg     0.9655    0.9640    0.9645      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 27:\n",
      "Counter({'SYMPTOM': 2081, 'BODY_PART': 1424, 'TOPONYM': 1359, 'MEDICINE': 758, 'ALLERGEN': 587})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1400\n",
      "После итерации 28 осталось 2643 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e23c9aa179740608b0656268b2c6f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1400 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='1750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 700/1750 06:01 < 09:03, 1.93 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138054</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.892128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.132594</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.134266</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.131526</td>\n",
       "      <td>0.866038</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.892996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8984\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9487    0.9610    0.9548        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8558    0.8812    0.8683       101\n",
      "   B-TOPONYM     0.9646    0.9745    0.9695       196\n",
      "  I-ALLERGEN     0.9733    0.9125    0.9419        80\n",
      " I-BODY_PART     1.0000    0.8235    0.9032        17\n",
      "  I-MEDICINE     0.8621    0.8929    0.8772        84\n",
      "   I-SYMPTOM     0.8504    0.8852    0.8675       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9868    0.9773    0.9821      2604\n",
      "\n",
      "    accuracy                         0.9655      3445\n",
      "   macro avg     0.9126    0.9245    0.9168      3445\n",
      "weighted avg     0.9667    0.9655    0.9658      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 28:\n",
      "Counter({'SYMPTOM': 2184, 'BODY_PART': 1483, 'TOPONYM': 1414, 'MEDICINE': 772, 'ALLERGEN': 616})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1450\n",
      "После итерации 29 осталось 2593 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d30226b84154a25abb6d94d69c69e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1450 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='910' max='1820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 910/1820 07:49 < 07:50, 1.94 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138046</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.895349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127756</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.899119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.126492</td>\n",
       "      <td>0.879541</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.901077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.127054</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.899316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.129944</td>\n",
       "      <td>0.875236</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.901655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9017\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8293    0.9855    0.9007        69\n",
      " B-BODY_PART     0.9605    0.9481    0.9542        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8491    0.8911    0.8696       101\n",
      "   B-TOPONYM     0.9697    0.9796    0.9746       196\n",
      "  I-ALLERGEN     0.9359    0.9125    0.9241        80\n",
      " I-BODY_PART     0.9333    0.8235    0.8750        17\n",
      "  I-MEDICINE     0.8652    0.9167    0.8902        84\n",
      "   I-SYMPTOM     0.8583    0.8934    0.8755       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9883    0.9766    0.9824      2604\n",
      "\n",
      "    accuracy                         0.9660      3445\n",
      "   macro avg     0.9052    0.9276    0.9151      3445\n",
      "weighted avg     0.9673    0.9660    0.9664      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 29:\n",
      "Counter({'SYMPTOM': 2254, 'BODY_PART': 1527, 'TOPONYM': 1479, 'MEDICINE': 788, 'ALLERGEN': 633})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1500\n",
      "После итерации 30 осталось 2543 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3476342b6af74f87a0fa64854ca16208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1500 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='1880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 564/1880 04:49 < 11:17, 1.94 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142410</td>\n",
       "      <td>0.856611</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>0.847300</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.879227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.141991</td>\n",
       "      <td>0.854717</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.881323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8889\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8313    1.0000    0.9079        69\n",
      " B-BODY_PART     0.9481    0.9481    0.9481        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.7845    0.9010    0.8387       101\n",
      "   B-TOPONYM     0.9796    0.9796    0.9796       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.6471    0.7857        17\n",
      "  I-MEDICINE     0.8851    0.9167    0.9006        84\n",
      "   I-SYMPTOM     0.8120    0.8852    0.8471       122\n",
      "   I-TOPONYM     0.9111    0.9318    0.9213        44\n",
      "           O     0.9879    0.9731    0.9805      2604\n",
      "\n",
      "    accuracy                         0.9626      3445\n",
      "   macro avg     0.9038    0.9106    0.9024      3445\n",
      "weighted avg     0.9649    0.9626    0.9631      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, внос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 30:\n",
      "Counter({'SYMPTOM': 2323, 'BODY_PART': 1587, 'TOPONYM': 1534, 'MEDICINE': 831, 'ALLERGEN': 645})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1550\n",
      "После итерации 31 осталось 2493 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa967054703453a9301f7181c5c98a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1550 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1550 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='582' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 582/1940 04:58 < 11:39, 1.94 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137705</td>\n",
       "      <td>0.849906</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.878758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137654</td>\n",
       "      <td>0.848030</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.876819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.144650</td>\n",
       "      <td>0.847170</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.873541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8788\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8415    1.0000    0.9139        69\n",
      " B-BODY_PART     0.8750    0.9091    0.8917        77\n",
      "  B-MEDICINE     0.8393    0.9216    0.8785        51\n",
      "   B-SYMPTOM     0.8544    0.8713    0.8627       101\n",
      "   B-TOPONYM     0.9697    0.9796    0.9746       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.3529    0.5217        17\n",
      "  I-MEDICINE     0.8556    0.9167    0.8851        84\n",
      "   I-SYMPTOM     0.8640    0.8852    0.8745       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9861    0.9777    0.9819      2604\n",
      "\n",
      "    accuracy                         0.9631      3445\n",
      "   macro avg     0.9042    0.8801    0.8771      3445\n",
      "weighted avg     0.9645    0.9631    0.9628      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 31:\n",
      "Counter({'SYMPTOM': 2370, 'BODY_PART': 1613, 'TOPONYM': 1577, 'MEDICINE': 858, 'ALLERGEN': 682})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1600\n",
      "После итерации 32 осталось 2443 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc27d7eb9f9a4a84b2138a2759b2b23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1600 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/2000 08:34 < 08:35, 1.94 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143563</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.874879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.144273</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.140537</td>\n",
       "      <td>0.855513</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.878906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.143152</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8828\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8415    1.0000    0.9139        69\n",
      " B-BODY_PART     0.8289    0.8182    0.8235        77\n",
      "  B-MEDICINE     0.8727    0.9412    0.9057        51\n",
      "   B-SYMPTOM     0.8558    0.8812    0.8683       101\n",
      "   B-TOPONYM     0.9796    0.9796    0.9796       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.1765    0.3000        17\n",
      "  I-MEDICINE     0.8851    0.9167    0.9006        84\n",
      "   I-SYMPTOM     0.8583    0.8934    0.8755       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9846    0.9800    0.9823      2604\n",
      "\n",
      "    accuracy                         0.9628      3445\n",
      "   macro avg     0.9061    0.8594    0.8557      3445\n",
      "weighted avg     0.9639    0.9628    0.9618      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 32:\n",
      "Counter({'SYMPTOM': 2415, 'BODY_PART': 1642, 'TOPONYM': 1634, 'MEDICINE': 892, 'ALLERGEN': 739})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1650\n",
      "После итерации 33 осталось 2393 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab022f600f04b24b37343e5a568b7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1650 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1650 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1449' max='2070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1449/2070 12:22 < 05:18, 1.95 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149388</td>\n",
       "      <td>0.852552</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.878286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146988</td>\n",
       "      <td>0.850662</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.876339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.144732</td>\n",
       "      <td>0.857685</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.881951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.143516</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.146373</td>\n",
       "      <td>0.861217</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.884766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.146468</td>\n",
       "      <td>0.856604</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.883268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>0.859848</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.884990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8850\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8313    1.0000    0.9079        69\n",
      " B-BODY_PART     0.8158    0.8052    0.8105        77\n",
      "  B-MEDICINE     0.8136    0.9412    0.8727        51\n",
      "   B-SYMPTOM     0.8318    0.8812    0.8558       101\n",
      "   B-TOPONYM     0.9897    0.9847    0.9872       196\n",
      "  I-ALLERGEN     0.9481    0.9125    0.9299        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8778    0.9405    0.9080        84\n",
      "   I-SYMPTOM     0.8720    0.8934    0.8826       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9857    0.9789    0.9823      2604\n",
      "\n",
      "    accuracy                         0.9620      3445\n",
      "   macro avg     0.8981    0.8501    0.8347      3445\n",
      "weighted avg     0.9636    0.9620    0.9604      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 33:\n",
      "Counter({'SYMPTOM': 2481, 'TOPONYM': 1689, 'BODY_PART': 1678, 'MEDICINE': 925, 'ALLERGEN': 784})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1700\n",
      "После итерации 34 осталось 2343 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d02254f11647b19dc92350a84ec3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1700 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='639' max='2130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 639/2130 05:26 < 12:43, 1.95 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143737</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.884540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.864245</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.885406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.147555</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.885854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8859\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8313    1.0000    0.9079        69\n",
      " B-BODY_PART     0.8052    0.8052    0.8052        77\n",
      "  B-MEDICINE     0.8545    0.9216    0.8868        51\n",
      "   B-SYMPTOM     0.8476    0.8812    0.8641       101\n",
      "   B-TOPONYM     0.9948    0.9847    0.9897       196\n",
      "  I-ALLERGEN     0.9241    0.9125    0.9182        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8667    0.9286    0.8966        84\n",
      "   I-SYMPTOM     0.8321    0.8934    0.8617       122\n",
      "   I-TOPONYM     0.9130    0.9545    0.9333        44\n",
      "           O     0.9865    0.9789    0.9827      2604\n",
      "\n",
      "    accuracy                         0.9614      3445\n",
      "   macro avg     0.8960    0.8472    0.8325      3445\n",
      "weighted avg     0.9630    0.9614    0.9599      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцу, березы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 34:\n",
      "Counter({'SYMPTOM': 2550, 'TOPONYM': 1726, 'BODY_PART': 1722, 'MEDICINE': 960, 'ALLERGEN': 811})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1750\n",
      "После итерации 35 осталось 2293 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc11d0dd4c44feae01022773c4c1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1750 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1533' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1533/2190 13:05 < 05:37, 1.95 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>0.865019</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.888672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142781</td>\n",
       "      <td>0.872832</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.890855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.149390</td>\n",
       "      <td>0.863378</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.887805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.142591</td>\n",
       "      <td>0.873321</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.893032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.143313</td>\n",
       "      <td>0.873805</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.895201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.145770</td>\n",
       "      <td>0.870476</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.893451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.145840</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.895610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.8956\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8415    1.0000    0.9139        69\n",
      " B-BODY_PART     0.8052    0.8052    0.8052        77\n",
      "  B-MEDICINE     0.8276    0.9412    0.8807        51\n",
      "   B-SYMPTOM     0.8349    0.9010    0.8667       101\n",
      "   B-TOPONYM     1.0000    0.9847    0.9923       196\n",
      "  I-ALLERGEN     0.9367    0.9250    0.9308        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8778    0.9405    0.9080        84\n",
      "   I-SYMPTOM     0.8516    0.8934    0.8720       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9876    0.9789    0.9832      2604\n",
      "\n",
      "    accuracy                         0.9631      3445\n",
      "   macro avg     0.8980    0.8551    0.8372      3445\n",
      "weighted avg     0.9649    0.9631    0.9617      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 35:\n",
      "Counter({'SYMPTOM': 2638, 'TOPONYM': 1774, 'BODY_PART': 1770, 'MEDICINE': 1026, 'ALLERGEN': 851})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1800\n",
      "После итерации 36 осталось 2243 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44a7e87f4a14e998fdb74f7b3112cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1800 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1125' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1125/2250 09:36 < 09:37, 1.95 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144466</td>\n",
       "      <td>0.875954</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.898239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149202</td>\n",
       "      <td>0.865784</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.891918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.143093</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.902344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>0.140341</td>\n",
       "      <td>0.882692</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.901768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9023\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8519    1.0000    0.9200        69\n",
      " B-BODY_PART     0.7949    0.8052    0.8000        77\n",
      "  B-MEDICINE     0.8571    0.9412    0.8972        51\n",
      "   B-SYMPTOM     0.8505    0.9010    0.8750       101\n",
      "   B-TOPONYM     1.0000    0.9898    0.9949       196\n",
      "  I-ALLERGEN     0.9375    0.9375    0.9375        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8778    0.9405    0.9080        84\n",
      "   I-SYMPTOM     0.8594    0.9016    0.8800       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9880    0.9800    0.9840      2604\n",
      "\n",
      "    accuracy                         0.9649      3445\n",
      "   macro avg     0.9029    0.8575    0.8412      3445\n",
      "weighted avg     0.9664    0.9649    0.9633      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 36:\n",
      "Counter({'SYMPTOM': 2694, 'TOPONYM': 1837, 'BODY_PART': 1801, 'MEDICINE': 1069, 'ALLERGEN': 889})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1850\n",
      "После итерации 37 осталось 2193 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c9af0f9fa649c69c0b2f0eca97e35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1850 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='928' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 928/2320 07:54 < 11:53, 1.95 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141376</td>\n",
       "      <td>0.877395</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.898039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141483</td>\n",
       "      <td>0.890385</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.909627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.141872</td>\n",
       "      <td>0.881226</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.140953</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.897361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9096\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8734    1.0000    0.9324        69\n",
      " B-BODY_PART     0.7949    0.8052    0.8000        77\n",
      "  B-MEDICINE     0.8596    0.9608    0.9074        51\n",
      "   B-SYMPTOM     0.8900    0.8812    0.8856       101\n",
      "   B-TOPONYM     1.0000    0.9898    0.9949       196\n",
      "  I-ALLERGEN     0.9390    0.9625    0.9506        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8778    0.9405    0.9080        84\n",
      "   I-SYMPTOM     0.8527    0.9016    0.8765       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9876    0.9816    0.9846      2604\n",
      "\n",
      "    accuracy                         0.9663      3445\n",
      "   macro avg     0.9082    0.8599    0.8451      3445\n",
      "weighted avg     0.9675    0.9663    0.9647      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 37:\n",
      "Counter({'SYMPTOM': 2755, 'TOPONYM': 1892, 'BODY_PART': 1842, 'MEDICINE': 1103, 'ALLERGEN': 932})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1900\n",
      "После итерации 38 осталось 2143 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b98e06e1b2641e5879ef3ab3030f8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1900 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='952' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 952/2380 08:07 < 12:12, 1.95 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140734</td>\n",
       "      <td>0.883142</td>\n",
       "      <td>0.925703</td>\n",
       "      <td>0.903922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142046</td>\n",
       "      <td>0.886756</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.906771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.145201</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.905882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.143789</td>\n",
       "      <td>0.883588</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.906067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9068\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8846    1.0000    0.9388        69\n",
      " B-BODY_PART     0.7949    0.8052    0.8000        77\n",
      "  B-MEDICINE     0.8727    0.9412    0.9057        51\n",
      "   B-SYMPTOM     0.8571    0.8911    0.8738       101\n",
      "   B-TOPONYM     1.0000    0.9898    0.9949       196\n",
      "  I-ALLERGEN     0.9506    0.9625    0.9565        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8778    0.9405    0.9080        84\n",
      "   I-SYMPTOM     0.8583    0.8934    0.8755       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9876    0.9820    0.9848      2604\n",
      "\n",
      "    accuracy                         0.9663      3445\n",
      "   macro avg     0.9090    0.8583    0.8449      3445\n",
      "weighted avg     0.9675    0.9663    0.9647      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 38:\n",
      "Counter({'SYMPTOM': 2817, 'TOPONYM': 1935, 'BODY_PART': 1879, 'MEDICINE': 1125, 'ALLERGEN': 958})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 1950\n",
      "После итерации 39 осталось 2093 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ab51f452f4a0cb7f492174b6cf92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 1950 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1464' max='2440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1464/2440 12:29 < 08:20, 1.95 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140295</td>\n",
       "      <td>0.883142</td>\n",
       "      <td>0.925703</td>\n",
       "      <td>0.903922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144397</td>\n",
       "      <td>0.883810</td>\n",
       "      <td>0.931727</td>\n",
       "      <td>0.907136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.140341</td>\n",
       "      <td>0.883365</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.904995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.141844</td>\n",
       "      <td>0.890385</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.909627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.143037</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.139096</td>\n",
       "      <td>0.886756</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.906771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9096\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8961    1.0000    0.9452        69\n",
      " B-BODY_PART     0.7949    0.8052    0.8000        77\n",
      "  B-MEDICINE     0.8727    0.9412    0.9057        51\n",
      "   B-SYMPTOM     0.8738    0.8911    0.8824       101\n",
      "   B-TOPONYM     1.0000    0.9898    0.9949       196\n",
      "  I-ALLERGEN     0.9390    0.9625    0.9506        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8681    0.9405    0.9029        84\n",
      "   I-SYMPTOM     0.8800    0.9016    0.8907       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9877    0.9831    0.9854      2604\n",
      "\n",
      "    accuracy                         0.9675      3445\n",
      "   macro avg     0.9116    0.8592    0.8467      3445\n",
      "weighted avg     0.9684    0.9675    0.9658      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 39:\n",
      "Counter({'SYMPTOM': 2908, 'TOPONYM': 1982, 'BODY_PART': 1937, 'MEDICINE': 1167, 'ALLERGEN': 996})\n",
      "\n",
      "[NER] Начинаем итерацию с размером выборки 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найден существующий размеченный проект для размера 2000\n",
      "После итерации 40 осталось 2043 сообщений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef87f56db8a4794bd6a584856a691c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Обучение на 2000 примерах\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/2500 12:47 < 08:32, 1.95 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137823</td>\n",
       "      <td>0.885880</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>0.902463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.140158</td>\n",
       "      <td>0.891683</td>\n",
       "      <td>0.925703</td>\n",
       "      <td>0.908374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.139458</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.141133</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.910345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.142022</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.931727</td>\n",
       "      <td>0.909804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.142894</td>\n",
       "      <td>0.883588</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.906067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Результаты: F1 = 0.9103\n",
      "\n",
      "[NER] Подробный отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-ALLERGEN     0.8961    1.0000    0.9452        69\n",
      " B-BODY_PART     0.7949    0.8052    0.8000        77\n",
      "  B-MEDICINE     0.8727    0.9412    0.9057        51\n",
      "   B-SYMPTOM     0.8725    0.8812    0.8768       101\n",
      "   B-TOPONYM     1.0000    0.9898    0.9949       196\n",
      "  I-ALLERGEN     0.9625    0.9625    0.9625        80\n",
      " I-BODY_PART     1.0000    0.0588    0.1111        17\n",
      "  I-MEDICINE     0.8681    0.9405    0.9029        84\n",
      "   I-SYMPTOM     0.8790    0.8934    0.8862       122\n",
      "   I-TOPONYM     0.9149    0.9773    0.9451        44\n",
      "           O     0.9869    0.9839    0.9854      2604\n",
      "\n",
      "    accuracy                         0.9675      3445\n",
      "   macro avg     0.9134    0.8576    0.8469      3445\n",
      "weighted avg     0.9684    0.9675    0.9657      3445\n",
      "\n",
      "[NER] Модель сохранена в models/pollen_ner_2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NER] Лучшая модель за все итерации сохранена в models/pollen_ner_best\n",
      "\n",
      "[NER] Тестирование модели после обучения:\n",
      "\n",
      "Тестовый пример:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "[NER] Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: потекли, чешутся, течет, слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n",
      "BODY_PART: глаза, нос, глаза, уши, нос, нос, глаза\n",
      "Модель перемещена на cuda\n",
      "\n",
      "Статистика распределения классов в тренировочном датасете после итерации 40:\n",
      "Counter({'SYMPTOM': 2989, 'TOPONYM': 2027, 'BODY_PART': 1988, 'MEDICINE': 1200, 'ALLERGEN': 1043})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanm\\anaconda3\\envs\\project\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Финальный оставшийся датасет сохранен в remaining_dataset_final.csv\n",
      "Размер финального датасета: 2043 сообщений\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER-модель обучена успешно!\n",
      "\n",
      "=== Начинаем обучение RE-модели ===\n",
      "\n",
      "[RE] Этап 1: Подготовка данных\n",
      "[RE] Используется тренировочный json: PollenNER_TRAIN_2000.json\n",
      "\n",
      "[RE] Этап 2: Подготовка датасетов\n",
      "\n",
      "[RE] Статистика распределения классов:\n",
      "Train (после сэмплирования): Counter({'has_symptom': 1811, 'no_relation': 1468, 'has_medicine': 96})\n",
      "Test: Counter({'has_symptom': 56, 'no_relation': 41, 'has_medicine': 4})\n",
      "\n",
      "[RE] Этап 3: Токенизация\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f8d4270cf4fcba29fa706bd532c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5813e0e14ce4740982e60dccbfe4df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RE] Этап 4: Обучение модели\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2110' max='2110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2110/2110 12:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.468768</td>\n",
       "      <td>0.896511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.504780</td>\n",
       "      <td>0.878992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.454169</td>\n",
       "      <td>0.921702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.261700</td>\n",
       "      <td>0.509117</td>\n",
       "      <td>0.929094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>0.526457</td>\n",
       "      <td>0.929094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RE-модель: Macro F1 = 0.9291\n",
      "RE-модель сохранена в models/pollen_re_model\n",
      "\n",
      "[RE] Результаты обучения:\n",
      "Macro F1 на тесте: 0.9291\n",
      "\n",
      "[RE] Этап 5: Детальный анализ результатов\n",
      "\n",
      "[RE] Подробный отчет по целевым классам:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " has_symptom     0.8966    0.9286    0.9123        56\n",
      "has_medicine     1.0000    1.0000    1.0000         4\n",
      "\n",
      "   micro avg     0.9032    0.9333    0.9180        60\n",
      "   macro avg     0.9483    0.9643    0.9561        60\n",
      "weighted avg     0.9034    0.9333    0.9181        60\n",
      "\n",
      "\n",
      "=== Финальное тестирование на тестовых примерах ===\n",
      "\n",
      "Тестовый пример 1:\n",
      "Текст: В Московской области у меня началась аллергия на пыльцу березы, потекли глаза, нос, принимаю Зиртек и Назонекс. У ребенка в Новокузнецке чешутся глаза, уши и течет нос, врач прописал Кромогексал, Назонекс в нос. В Санкт-Петербурге началось цветение ольхи, сильная реакция, принимаю Эриус, но глаза все равно слезятся.\n",
      "\n",
      "Результаты анализа:\n",
      "TOPONYM: Московскойобласти, Новокузнецке, Санкт-Петербурге\n",
      "MEDICINE: Зиртек, Назонекс, Кромогексал, Назонекс, Эриус\n",
      "SYMPTOM: глаза потекли, нос потекли, глаза чешутся, уши чешутся, нос течет, глаза слезятся\n",
      "ALLERGEN: пыльцуберезы, ольхи\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Основной блок выполнения программы.\n",
    "    Последовательно запускаем все этапы обработки данных и обучения моделей.\n",
    "    \"\"\"\n",
    "    # ===============================\n",
    "    # 1. Обучение NER-модели\n",
    "    # ===============================\n",
    "    print(\"\\n=== Начинаем обучение NER-модели ===\")\n",
    "    # Запускаем цикл обучения NER с активным обучением\n",
    "    last_ner_model = run_cycle('dataset_v1.csv', sizes)\n",
    "    print(\"\\nNER-модель обучена успешно!\")\n",
    "\n",
    "    # ===============================\n",
    "    # 2. Обучение RE-модели\n",
    "    # ===============================\n",
    "    print(\"\\n=== Начинаем обучение RE-модели ===\")\n",
    "\n",
    "    # 2.1. Подготовка данных\n",
    "    print('\\n[RE] Этап 1: Подготовка данных')\n",
    "    # Ищем последний существующий TRAIN json для обучения\n",
    "    last_train_json = None\n",
    "    for size in reversed(sizes):\n",
    "        candidate = f'PollenNER_TRAIN_{size}.json'\n",
    "        if os.path.exists(candidate):\n",
    "            last_train_json = candidate\n",
    "            break\n",
    "    if last_train_json is None:\n",
    "        raise FileNotFoundError('Не найден ни один TRAIN json для RE!')\n",
    "    print(f'[RE] Используется тренировочный json: {last_train_json}')\n",
    "\n",
    "    # Парсим разметку из JSON файлов\n",
    "    train_parsed = parse_labelstudio_json(last_train_json)\n",
    "    test_parsed = parse_labelstudio_json('PollenNER_TEST.json')\n",
    "\n",
    "    # 2.2. Подготовка датасетов\n",
    "    print('\\n[RE] Этап 2: Подготовка датасетов')\n",
    "    # Балансируем классы и применяем oversampling для has_medicine\n",
    "    re_train, rel_labels = prepare_re_dataset(\n",
    "        train_parsed,\n",
    "        relation_labels=RE_RELATION_LABELS,\n",
    "        max_no_relation_ratio=1,\n",
    "        oversample_medicine=True\n",
    "    )\n",
    "    re_test, _ = prepare_re_dataset(\n",
    "        test_parsed,\n",
    "        relation_labels=RE_RELATION_LABELS + ['no_relation'],\n",
    "        max_no_relation_ratio=1,\n",
    "        oversample_medicine=False\n",
    "    )\n",
    "\n",
    "    # Выводим статистику распределения классов\n",
    "    print('\\n[RE] Статистика распределения классов:')\n",
    "    print('Train (после сэмплирования):', Counter([ex['relation'] for ex in re_train]))\n",
    "    print('Test:', Counter([ex['relation'] for ex in re_test]))\n",
    "\n",
    "    # Создаем словари для преобразования меток\n",
    "    rel_label2id = {l: i for i, l in enumerate(rel_labels)}\n",
    "    rel_id2label = {i: l for l, i in rel_label2id.items()}\n",
    "\n",
    "    # 2.3. Токенизация\n",
    "    print('\\n[RE] Этап 3: Токенизация')\n",
    "    re_train_ds = prepare_hf_re_dataset(re_train,\n",
    "                                        TOKENIZER,\n",
    "                                        rel_label2id)\n",
    "    re_test_ds = prepare_hf_re_dataset(re_test,\n",
    "                                       TOKENIZER,\n",
    "                                       rel_label2id)\n",
    "\n",
    "    # 2.4. Обучение модели\n",
    "    print('\\n[RE] Этап 4: Обучение модели')\n",
    "    trainer_re, eval_results_re = train_and_eval_re_model(\n",
    "        train_ds=re_train_ds,\n",
    "        test_ds=re_test_ds,\n",
    "        num_labels=len(rel_labels),\n",
    "        label2id=rel_label2id,\n",
    "        id2label=rel_id2label,\n",
    "        tokenizer=TOKENIZER,\n",
    "        hf_token=HF_TOKEN,\n",
    "        output_dir='models/pollen_re_model',\n",
    "        epochs=5\n",
    "    )\n",
    "    print(f\"\\n[RE] Результаты обучения:\")\n",
    "    print(f\"Macro F1 на тесте: {eval_results_re['eval_f1']:.4f}\")\n",
    "\n",
    "    # 2.5. Детальный анализ результатов\n",
    "    print('\\n[RE] Этап 5: Детальный анализ результатов')\n",
    "    # Получаем предсказания для тестового набора\n",
    "    re_test_preds = trainer_re.predict(re_test_ds)\n",
    "    y_true = re_test_preds.label_ids\n",
    "    y_pred = re_test_preds.predictions.argmax(-1)\n",
    "\n",
    "    # Преобразуем индексы в метки\n",
    "    y_true_labels = [rel_id2label[i] for i in y_true]\n",
    "    y_pred_labels = [rel_id2label[i] for i in y_pred]\n",
    "\n",
    "    # Выводим подробный отчет по целевым классам\n",
    "    target_labels = [l for l in rel_labels if l != 'no_relation']\n",
    "    print(\"\\n[RE] Подробный отчет по целевым классам:\")\n",
    "    print(classification_report(y_true_labels,\n",
    "                                y_pred_labels,\n",
    "                                labels=target_labels,\n",
    "                                digits=4,\n",
    "                                zero_division=0))\n",
    "\n",
    "\n",
    "    # ===============================\n",
    "    # 3. Финальное тестирование\n",
    "    # ===============================\n",
    "    print('\\n=== Финальное тестирование на тестовых примерах ===')\n",
    "    for i, text in enumerate(TEST_EXAMPLES, 1):\n",
    "        print(f'\\nТестовый пример {i}:')\n",
    "        print(f'Текст: {text}')\n",
    "\n",
    "        # Извлекаем сущности и отношения\n",
    "        entities, relations = infer_ner_re_on_text(text,\n",
    "                                                   last_ner_model,\n",
    "                                                   trainer_re.model,\n",
    "                                                   TOKENIZER,\n",
    "                                                   ID2LABEL,\n",
    "                                                   rel_id2label)\n",
    "\n",
    "        # Собираем симптомы из отношений has_symptom\n",
    "        symptoms_from_relations = []\n",
    "        for rel in relations:\n",
    "            if rel['relation'] == 'has_symptom':\n",
    "                head = rel['head']['text']\n",
    "                tail = rel['tail']['text']\n",
    "                symptoms_from_relations.append(f'{head} {tail}')\n",
    "\n",
    "        # Группируем сущности по типу (исключая BODY_PART)\n",
    "        ent_by_type = {label: [] for label in LABELS if label != 'BODY_PART'}\n",
    "        for ent in entities:\n",
    "            if ent['label'] in ent_by_type:\n",
    "                if ent['label'] != 'SYMPTOM':\n",
    "                    # Для остальных сущностей используем все найденные\n",
    "                    ent_by_type[ent['label']].append(ent['text'])\n",
    "\n",
    "        # Для SYMPTOM записываем данные из has_symptom\n",
    "        for symptom in symptoms_from_relations:\n",
    "            ent_by_type['SYMPTOM'].append(symptom)\n",
    "\n",
    "        # Выводим результаты\n",
    "        print('\\nРезультаты анализа:')\n",
    "        for label in ent_by_type.keys():\n",
    "            if ent_by_type[label]:\n",
    "                ents_str = ', '.join(ent_by_type[label])\n",
    "                print(f'{label}: {ents_str}')\n",
    "            else:\n",
    "                print(f'{label}: не найдено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiv5i_R4vFd7"
   },
   "source": [
    "## Вывод\n",
    "\n",
    "Проведённые эксперименты показали, что внедрение отдельного модуля для оценки отношений (RE) существенно повысило точность выделения и классификации симптомов, устранив ложные срабатывания на упоминания частей тела. Уже с 400 размеченными сообщениями наблюдался заметный рост F1‑метрики, а к 2000 примерам модель достигла стабильного уровня в 0.91, демонстрируя зрелость и надёжность алгоритма.\n",
    "\n",
    "Интеграция NER и RE модулей в единую NLP‑конвейерную архитектуру позволяет в реальном времени автоматически обрабатывать пользовательские сообщения Пыльца Club, извлекая топонимы, симптомы, препараты и аллергены и устанавливая между ними семантические связи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:project]",
   "language": "python",
   "name": "conda-env-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
